{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:17pt;}\n",
    "div.output {font-size:17pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:17pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=\"6\" color=\"red\">ch4. RNN(순환신경망)</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 문맥을 이용하여 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5, 6, 1, 7, 8, 1, 9, 10, 1, 11]\n",
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "encoded = t.texts_to_sequences([text])[0]\n",
    "print(encoded)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 4, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['경마장에 있는 말이 뛰고 있다'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 문장 : 경마장에 있는 말이 뛰고 있다\n",
      "encoed 문장 : [2, 3, 1, 4, 5]\n",
      "원래 문장 : 그의 말이 법이다\n",
      "encoed 문장 : [6, 1, 7]\n",
      "원래 문장 : 가는 말이 고와야 오는 말이 곱다\n",
      "encoed 문장 : [8, 1, 9, 10, 1, 11]\n",
      "원래 문장 : \n",
      "encoed 문장 : []\n",
      "\n",
      "[2:경마장에  3:있는  ]\n",
      "[2:경마장에  3:있는  1:말이  ]\n",
      "[2:경마장에  3:있는  1:말이  4:뛰고  ]\n",
      "[2:경마장에  3:있는  1:말이  4:뛰고  5:있다  ]\n",
      "[3:있는  1:말이  ]\n",
      "[3:있는  1:말이  4:뛰고  ]\n",
      "[3:있는  1:말이  4:뛰고  5:있다  ]\n",
      "[1:말이  4:뛰고  ]\n",
      "[1:말이  4:뛰고  5:있다  ]\n",
      "[4:뛰고  5:있다  ]\n",
      "[6:그의  1:말이  ]\n",
      "[6:그의  1:말이  7:법이다  ]\n",
      "[1:말이  7:법이다  ]\n",
      "[8:가는  1:말이  ]\n",
      "[8:가는  1:말이  9:고와야  ]\n",
      "[8:가는  1:말이  9:고와야  10:오는  ]\n",
      "[8:가는  1:말이  9:고와야  10:오는  1:말이  ]\n",
      "[8:가는  1:말이  9:고와야  10:오는  1:말이  11:곱다  ]\n",
      "[1:말이  9:고와야  ]\n",
      "[1:말이  9:고와야  10:오는  ]\n",
      "[1:말이  9:고와야  10:오는  1:말이  ]\n",
      "[1:말이  9:고와야  10:오는  1:말이  11:곱다  ]\n",
      "[9:고와야  10:오는  ]\n",
      "[9:고와야  10:오는  1:말이  ]\n",
      "[9:고와야  10:오는  1:말이  11:곱다  ]\n",
      "[10:오는  1:말이  ]\n",
      "[10:오는  1:말이  11:곱다  ]\n",
      "[1:말이  11:곱다  ]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    print('원래 문장 :',line)\n",
    "    print('encoed 문장 :', encoded)\n",
    "    for i in range(0, len(encoded)-1):\n",
    "        for j in range(i+2, len(encoded)+1):\n",
    "            sequences.append(encoded[i:j])\n",
    "print()\n",
    "for sequence in sequences:\n",
    "    print('[', end='')\n",
    "    for word_seq in sequence:\n",
    "        for key, value in t.word_index.items():\n",
    "            if value==word_seq:\n",
    "                print(\"{}:{}\".format(value, key), end='  ')\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [3, 1],\n",
       " [3, 1, 4],\n",
       " [3, 1, 4, 5],\n",
       " [1, 4],\n",
       " [1, 4, 5],\n",
       " [4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11],\n",
       " [1, 9],\n",
       " [1, 9, 10],\n",
       " [1, 9, 10, 1],\n",
       " [1, 9, 10, 1, 11],\n",
       " [9, 10],\n",
       " [9, 10, 1],\n",
       " [9, 10, 1, 11],\n",
       " [10, 1],\n",
       " [10, 1, 11],\n",
       " [1, 11]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 2, 3, 2, 2, 3, 2, 2, 3, 4, 5, 6, 2, 3, 4, 5, 2, 3, 4, 2, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print([len(s) for s in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequences에 제일 많은 단어가 들어 있는 갯수# sequences에 제일 많은 단어가 들어 있는 갯수\n",
    "maxlen = max([len(s) for s in sequences])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences), len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " 28,\n",
       " array([[ 0,  0,  0,  0,  2,  3],\n",
       "        [ 0,  0,  0,  2,  3,  1],\n",
       "        [ 0,  0,  2,  3,  1,  4],\n",
       "        [ 0,  2,  3,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  3,  1],\n",
       "        [ 0,  0,  0,  3,  1,  4],\n",
       "        [ 0,  0,  3,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  1,  4],\n",
       "        [ 0,  0,  0,  1,  4,  5],\n",
       "        [ 0,  0,  0,  0,  4,  5],\n",
       "        [ 0,  0,  0,  0,  6,  1],\n",
       "        [ 0,  0,  0,  6,  1,  7],\n",
       "        [ 0,  0,  0,  0,  1,  7],\n",
       "        [ 0,  0,  0,  0,  8,  1],\n",
       "        [ 0,  0,  0,  8,  1,  9],\n",
       "        [ 0,  0,  8,  1,  9, 10],\n",
       "        [ 0,  8,  1,  9, 10,  1],\n",
       "        [ 8,  1,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  1,  9],\n",
       "        [ 0,  0,  0,  1,  9, 10],\n",
       "        [ 0,  0,  1,  9, 10,  1],\n",
       "        [ 0,  1,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  9, 10],\n",
       "        [ 0,  0,  0,  9, 10,  1],\n",
       "        [ 0,  0,  9, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0, 10,  1],\n",
       "        [ 0,  0,  0, 10,  1, 11],\n",
       "        [ 0,  0,  0,  0,  1, 11]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequences를 훈련가능한 데이터로 만들기\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences=sequences, \n",
    "                         maxlen=maxlen, \n",
    "                         padding='pre')\n",
    "type(sequences), len(sequences), sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  5,  1,  4,  5,  4,  5,  5,  1,  7,  7,  1,  9, 10,  1,\n",
       "       11,  9, 10,  1, 11, 10,  1, 11,  1, 11, 11])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 독립변수(X)와 종속변수(Y) 분리\n",
    "X = sequences[:, :-1]\n",
    "Y = sequences[:, -1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(t.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y 원핫인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 - 1s - loss: 2.4904 - accuracy: 0.1429\n",
      "Epoch 2/300\n",
      "1/1 - 0s - loss: 2.4785 - accuracy: 0.2143\n",
      "Epoch 3/300\n",
      "1/1 - 0s - loss: 2.4665 - accuracy: 0.2857\n",
      "Epoch 4/300\n",
      "1/1 - 0s - loss: 2.4544 - accuracy: 0.2857\n",
      "Epoch 5/300\n",
      "1/1 - 0s - loss: 2.4419 - accuracy: 0.3214\n",
      "Epoch 6/300\n",
      "1/1 - 0s - loss: 2.4291 - accuracy: 0.3214\n",
      "Epoch 7/300\n",
      "1/1 - 0s - loss: 2.4159 - accuracy: 0.2857\n",
      "Epoch 8/300\n",
      "1/1 - 0s - loss: 2.4022 - accuracy: 0.2857\n",
      "Epoch 9/300\n",
      "1/1 - 0s - loss: 2.3879 - accuracy: 0.3214\n",
      "Epoch 10/300\n",
      "1/1 - 0s - loss: 2.3730 - accuracy: 0.3214\n",
      "Epoch 11/300\n",
      "1/1 - 0s - loss: 2.3574 - accuracy: 0.3214\n",
      "Epoch 12/300\n",
      "1/1 - 0s - loss: 2.3410 - accuracy: 0.3214\n",
      "Epoch 13/300\n",
      "1/1 - 0s - loss: 2.3238 - accuracy: 0.3214\n",
      "Epoch 14/300\n",
      "1/1 - 0s - loss: 2.3058 - accuracy: 0.3214\n",
      "Epoch 15/300\n",
      "1/1 - 0s - loss: 2.2871 - accuracy: 0.3214\n",
      "Epoch 16/300\n",
      "1/1 - 0s - loss: 2.2675 - accuracy: 0.2857\n",
      "Epoch 17/300\n",
      "1/1 - 0s - loss: 2.2473 - accuracy: 0.2857\n",
      "Epoch 18/300\n",
      "1/1 - 0s - loss: 2.2266 - accuracy: 0.2857\n",
      "Epoch 19/300\n",
      "1/1 - 0s - loss: 2.2054 - accuracy: 0.2857\n",
      "Epoch 20/300\n",
      "1/1 - 0s - loss: 2.1841 - accuracy: 0.2857\n",
      "Epoch 21/300\n",
      "1/1 - 0s - loss: 2.1629 - accuracy: 0.2857\n",
      "Epoch 22/300\n",
      "1/1 - 0s - loss: 2.1421 - accuracy: 0.2857\n",
      "Epoch 23/300\n",
      "1/1 - 0s - loss: 2.1219 - accuracy: 0.2857\n",
      "Epoch 24/300\n",
      "1/1 - 0s - loss: 2.1027 - accuracy: 0.2857\n",
      "Epoch 25/300\n",
      "1/1 - 0s - loss: 2.0848 - accuracy: 0.2857\n",
      "Epoch 26/300\n",
      "1/1 - 0s - loss: 2.0682 - accuracy: 0.2857\n",
      "Epoch 27/300\n",
      "1/1 - 0s - loss: 2.0528 - accuracy: 0.2857\n",
      "Epoch 28/300\n",
      "1/1 - 0s - loss: 2.0385 - accuracy: 0.2857\n",
      "Epoch 29/300\n",
      "1/1 - 0s - loss: 2.0250 - accuracy: 0.2857\n",
      "Epoch 30/300\n",
      "1/1 - 0s - loss: 2.0117 - accuracy: 0.2857\n",
      "Epoch 31/300\n",
      "1/1 - 0s - loss: 1.9984 - accuracy: 0.2857\n",
      "Epoch 32/300\n",
      "1/1 - 0s - loss: 1.9849 - accuracy: 0.2857\n",
      "Epoch 33/300\n",
      "1/1 - 0s - loss: 1.9711 - accuracy: 0.2857\n",
      "Epoch 34/300\n",
      "1/1 - 0s - loss: 1.9570 - accuracy: 0.2857\n",
      "Epoch 35/300\n",
      "1/1 - 0s - loss: 1.9428 - accuracy: 0.2857\n",
      "Epoch 36/300\n",
      "1/1 - 0s - loss: 1.9289 - accuracy: 0.2857\n",
      "Epoch 37/300\n",
      "1/1 - 0s - loss: 1.9153 - accuracy: 0.2857\n",
      "Epoch 38/300\n",
      "1/1 - 0s - loss: 1.9022 - accuracy: 0.3571\n",
      "Epoch 39/300\n",
      "1/1 - 0s - loss: 1.8897 - accuracy: 0.3571\n",
      "Epoch 40/300\n",
      "1/1 - 0s - loss: 1.8777 - accuracy: 0.3571\n",
      "Epoch 41/300\n",
      "1/1 - 0s - loss: 1.8663 - accuracy: 0.3571\n",
      "Epoch 42/300\n",
      "1/1 - 0s - loss: 1.8551 - accuracy: 0.3571\n",
      "Epoch 43/300\n",
      "1/1 - 0s - loss: 1.8441 - accuracy: 0.4286\n",
      "Epoch 44/300\n",
      "1/1 - 0s - loss: 1.8332 - accuracy: 0.4286\n",
      "Epoch 45/300\n",
      "1/1 - 0s - loss: 1.8223 - accuracy: 0.4286\n",
      "Epoch 46/300\n",
      "1/1 - 0s - loss: 1.8114 - accuracy: 0.4286\n",
      "Epoch 47/300\n",
      "1/1 - 0s - loss: 1.8004 - accuracy: 0.4286\n",
      "Epoch 48/300\n",
      "1/1 - 0s - loss: 1.7894 - accuracy: 0.4286\n",
      "Epoch 49/300\n",
      "1/1 - 0s - loss: 1.7785 - accuracy: 0.4286\n",
      "Epoch 50/300\n",
      "1/1 - 0s - loss: 1.7676 - accuracy: 0.4286\n",
      "Epoch 51/300\n",
      "1/1 - 0s - loss: 1.7569 - accuracy: 0.4286\n",
      "Epoch 52/300\n",
      "1/1 - 0s - loss: 1.7464 - accuracy: 0.4286\n",
      "Epoch 53/300\n",
      "1/1 - 0s - loss: 1.7359 - accuracy: 0.4286\n",
      "Epoch 54/300\n",
      "1/1 - 0s - loss: 1.7256 - accuracy: 0.4286\n",
      "Epoch 55/300\n",
      "1/1 - 0s - loss: 1.7152 - accuracy: 0.4286\n",
      "Epoch 56/300\n",
      "1/1 - 0s - loss: 1.7048 - accuracy: 0.4286\n",
      "Epoch 57/300\n",
      "1/1 - 0s - loss: 1.6943 - accuracy: 0.4643\n",
      "Epoch 58/300\n",
      "1/1 - 0s - loss: 1.6836 - accuracy: 0.4643\n",
      "Epoch 59/300\n",
      "1/1 - 0s - loss: 1.6726 - accuracy: 0.4643\n",
      "Epoch 60/300\n",
      "1/1 - 0s - loss: 1.6614 - accuracy: 0.4643\n",
      "Epoch 61/300\n",
      "1/1 - 0s - loss: 1.6501 - accuracy: 0.4643\n",
      "Epoch 62/300\n",
      "1/1 - 0s - loss: 1.6385 - accuracy: 0.4643\n",
      "Epoch 63/300\n",
      "1/1 - 0s - loss: 1.6268 - accuracy: 0.4643\n",
      "Epoch 64/300\n",
      "1/1 - 0s - loss: 1.6149 - accuracy: 0.4643\n",
      "Epoch 65/300\n",
      "1/1 - 0s - loss: 1.6029 - accuracy: 0.5000\n",
      "Epoch 66/300\n",
      "1/1 - 0s - loss: 1.5909 - accuracy: 0.5000\n",
      "Epoch 67/300\n",
      "1/1 - 0s - loss: 1.5787 - accuracy: 0.5000\n",
      "Epoch 68/300\n",
      "1/1 - 0s - loss: 1.5664 - accuracy: 0.5000\n",
      "Epoch 69/300\n",
      "1/1 - 0s - loss: 1.5540 - accuracy: 0.5000\n",
      "Epoch 70/300\n",
      "1/1 - 0s - loss: 1.5414 - accuracy: 0.5000\n",
      "Epoch 71/300\n",
      "1/1 - 0s - loss: 1.5288 - accuracy: 0.5000\n",
      "Epoch 72/300\n",
      "1/1 - 0s - loss: 1.5160 - accuracy: 0.5000\n",
      "Epoch 73/300\n",
      "1/1 - 0s - loss: 1.5032 - accuracy: 0.5000\n",
      "Epoch 74/300\n",
      "1/1 - 0s - loss: 1.4903 - accuracy: 0.5000\n",
      "Epoch 75/300\n",
      "1/1 - 0s - loss: 1.4773 - accuracy: 0.5000\n",
      "Epoch 76/300\n",
      "1/1 - 0s - loss: 1.4643 - accuracy: 0.5000\n",
      "Epoch 77/300\n",
      "1/1 - 0s - loss: 1.4513 - accuracy: 0.5000\n",
      "Epoch 78/300\n",
      "1/1 - 0s - loss: 1.4382 - accuracy: 0.5000\n",
      "Epoch 79/300\n",
      "1/1 - 0s - loss: 1.4251 - accuracy: 0.5357\n",
      "Epoch 80/300\n",
      "1/1 - 0s - loss: 1.4121 - accuracy: 0.5357\n",
      "Epoch 81/300\n",
      "1/1 - 0s - loss: 1.3990 - accuracy: 0.5357\n",
      "Epoch 82/300\n",
      "1/1 - 0s - loss: 1.3860 - accuracy: 0.5357\n",
      "Epoch 83/300\n",
      "1/1 - 0s - loss: 1.3729 - accuracy: 0.5357\n",
      "Epoch 84/300\n",
      "1/1 - 0s - loss: 1.3599 - accuracy: 0.5357\n",
      "Epoch 85/300\n",
      "1/1 - 0s - loss: 1.3469 - accuracy: 0.5714\n",
      "Epoch 86/300\n",
      "1/1 - 0s - loss: 1.3340 - accuracy: 0.5714\n",
      "Epoch 87/300\n",
      "1/1 - 0s - loss: 1.3212 - accuracy: 0.5714\n",
      "Epoch 88/300\n",
      "1/1 - 0s - loss: 1.3084 - accuracy: 0.6071\n",
      "Epoch 89/300\n",
      "1/1 - 0s - loss: 1.2957 - accuracy: 0.6429\n",
      "Epoch 90/300\n",
      "1/1 - 0s - loss: 1.2831 - accuracy: 0.6429\n",
      "Epoch 91/300\n",
      "1/1 - 0s - loss: 1.2706 - accuracy: 0.6429\n",
      "Epoch 92/300\n",
      "1/1 - 0s - loss: 1.2582 - accuracy: 0.6429\n",
      "Epoch 93/300\n",
      "1/1 - 0s - loss: 1.2459 - accuracy: 0.6429\n",
      "Epoch 94/300\n",
      "1/1 - 0s - loss: 1.2337 - accuracy: 0.6429\n",
      "Epoch 95/300\n",
      "1/1 - 0s - loss: 1.2216 - accuracy: 0.6429\n",
      "Epoch 96/300\n",
      "1/1 - 0s - loss: 1.2097 - accuracy: 0.6429\n",
      "Epoch 97/300\n",
      "1/1 - 0s - loss: 1.1979 - accuracy: 0.6429\n",
      "Epoch 98/300\n",
      "1/1 - 0s - loss: 1.1862 - accuracy: 0.6429\n",
      "Epoch 99/300\n",
      "1/1 - 0s - loss: 1.1746 - accuracy: 0.6429\n",
      "Epoch 100/300\n",
      "1/1 - 0s - loss: 1.1632 - accuracy: 0.6786\n",
      "Epoch 101/300\n",
      "1/1 - 0s - loss: 1.1519 - accuracy: 0.6786\n",
      "Epoch 102/300\n",
      "1/1 - 0s - loss: 1.1408 - accuracy: 0.6786\n",
      "Epoch 103/300\n",
      "1/1 - 0s - loss: 1.1298 - accuracy: 0.6786\n",
      "Epoch 104/300\n",
      "1/1 - 0s - loss: 1.1189 - accuracy: 0.6786\n",
      "Epoch 105/300\n",
      "1/1 - 0s - loss: 1.1082 - accuracy: 0.6786\n",
      "Epoch 106/300\n",
      "1/1 - 0s - loss: 1.0976 - accuracy: 0.6786\n",
      "Epoch 107/300\n",
      "1/1 - 0s - loss: 1.0872 - accuracy: 0.6786\n",
      "Epoch 108/300\n",
      "1/1 - 0s - loss: 1.0768 - accuracy: 0.6786\n",
      "Epoch 109/300\n",
      "1/1 - 0s - loss: 1.0667 - accuracy: 0.6786\n",
      "Epoch 110/300\n",
      "1/1 - 0s - loss: 1.0566 - accuracy: 0.6786\n",
      "Epoch 111/300\n",
      "1/1 - 0s - loss: 1.0467 - accuracy: 0.6786\n",
      "Epoch 112/300\n",
      "1/1 - 0s - loss: 1.0369 - accuracy: 0.6786\n",
      "Epoch 113/300\n",
      "1/1 - 0s - loss: 1.0272 - accuracy: 0.6786\n",
      "Epoch 114/300\n",
      "1/1 - 0s - loss: 1.0177 - accuracy: 0.6786\n",
      "Epoch 115/300\n",
      "1/1 - 0s - loss: 1.0083 - accuracy: 0.6786\n",
      "Epoch 116/300\n",
      "1/1 - 0s - loss: 0.9990 - accuracy: 0.6786\n",
      "Epoch 117/300\n",
      "1/1 - 0s - loss: 0.9899 - accuracy: 0.6786\n",
      "Epoch 118/300\n",
      "1/1 - 0s - loss: 0.9808 - accuracy: 0.6786\n",
      "Epoch 119/300\n",
      "1/1 - 0s - loss: 0.9719 - accuracy: 0.6786\n",
      "Epoch 120/300\n",
      "1/1 - 0s - loss: 0.9631 - accuracy: 0.6786\n",
      "Epoch 121/300\n",
      "1/1 - 0s - loss: 0.9544 - accuracy: 0.6786\n",
      "Epoch 122/300\n",
      "1/1 - 0s - loss: 0.9459 - accuracy: 0.6786\n",
      "Epoch 123/300\n",
      "1/1 - 0s - loss: 0.9374 - accuracy: 0.7143\n",
      "Epoch 124/300\n",
      "1/1 - 0s - loss: 0.9291 - accuracy: 0.7143\n",
      "Epoch 125/300\n",
      "1/1 - 0s - loss: 0.9208 - accuracy: 0.7143\n",
      "Epoch 126/300\n",
      "1/1 - 0s - loss: 0.9127 - accuracy: 0.7143\n",
      "Epoch 127/300\n",
      "1/1 - 0s - loss: 0.9047 - accuracy: 0.7143\n",
      "Epoch 128/300\n",
      "1/1 - 0s - loss: 0.8967 - accuracy: 0.7143\n",
      "Epoch 129/300\n",
      "1/1 - 0s - loss: 0.8889 - accuracy: 0.7143\n",
      "Epoch 130/300\n",
      "1/1 - 0s - loss: 0.8812 - accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "1/1 - 0s - loss: 0.8736 - accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "1/1 - 0s - loss: 0.8660 - accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "1/1 - 0s - loss: 0.8586 - accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "1/1 - 0s - loss: 0.8513 - accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "1/1 - 0s - loss: 0.8440 - accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "1/1 - 0s - loss: 0.8368 - accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "1/1 - 0s - loss: 0.8298 - accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "1/1 - 0s - loss: 0.8228 - accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "1/1 - 0s - loss: 0.8159 - accuracy: 0.7857\n",
      "Epoch 140/300\n",
      "1/1 - 0s - loss: 0.8090 - accuracy: 0.7857\n",
      "Epoch 141/300\n",
      "1/1 - 0s - loss: 0.8023 - accuracy: 0.7857\n",
      "Epoch 142/300\n",
      "1/1 - 0s - loss: 0.7956 - accuracy: 0.7857\n",
      "Epoch 143/300\n",
      "1/1 - 0s - loss: 0.7890 - accuracy: 0.7857\n",
      "Epoch 144/300\n",
      "1/1 - 0s - loss: 0.7825 - accuracy: 0.8214\n",
      "Epoch 145/300\n",
      "1/1 - 0s - loss: 0.7761 - accuracy: 0.8214\n",
      "Epoch 146/300\n",
      "1/1 - 0s - loss: 0.7697 - accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/300\n",
      "1/1 - 0s - loss: 0.7634 - accuracy: 0.8214\n",
      "Epoch 148/300\n",
      "1/1 - 0s - loss: 0.7572 - accuracy: 0.8214\n",
      "Epoch 149/300\n",
      "1/1 - 0s - loss: 0.7510 - accuracy: 0.8214\n",
      "Epoch 150/300\n",
      "1/1 - 0s - loss: 0.7449 - accuracy: 0.8214\n",
      "Epoch 151/300\n",
      "1/1 - 0s - loss: 0.7389 - accuracy: 0.8214\n",
      "Epoch 152/300\n",
      "1/1 - 0s - loss: 0.7330 - accuracy: 0.8214\n",
      "Epoch 153/300\n",
      "1/1 - 0s - loss: 0.7271 - accuracy: 0.8214\n",
      "Epoch 154/300\n",
      "1/1 - 0s - loss: 0.7212 - accuracy: 0.8214\n",
      "Epoch 155/300\n",
      "1/1 - 0s - loss: 0.7155 - accuracy: 0.8214\n",
      "Epoch 156/300\n",
      "1/1 - 0s - loss: 0.7098 - accuracy: 0.8214\n",
      "Epoch 157/300\n",
      "1/1 - 0s - loss: 0.7041 - accuracy: 0.8214\n",
      "Epoch 158/300\n",
      "1/1 - 0s - loss: 0.6985 - accuracy: 0.8214\n",
      "Epoch 159/300\n",
      "1/1 - 0s - loss: 0.6930 - accuracy: 0.8214\n",
      "Epoch 160/300\n",
      "1/1 - 0s - loss: 0.6875 - accuracy: 0.8214\n",
      "Epoch 161/300\n",
      "1/1 - 0s - loss: 0.6821 - accuracy: 0.8214\n",
      "Epoch 162/300\n",
      "1/1 - 0s - loss: 0.6767 - accuracy: 0.8214\n",
      "Epoch 163/300\n",
      "1/1 - 0s - loss: 0.6714 - accuracy: 0.8214\n",
      "Epoch 164/300\n",
      "1/1 - 0s - loss: 0.6662 - accuracy: 0.8214\n",
      "Epoch 165/300\n",
      "1/1 - 0s - loss: 0.6610 - accuracy: 0.8214\n",
      "Epoch 166/300\n",
      "1/1 - 0s - loss: 0.6559 - accuracy: 0.8214\n",
      "Epoch 167/300\n",
      "1/1 - 0s - loss: 0.6508 - accuracy: 0.8214\n",
      "Epoch 168/300\n",
      "1/1 - 0s - loss: 0.6457 - accuracy: 0.8214\n",
      "Epoch 169/300\n",
      "1/1 - 0s - loss: 0.6407 - accuracy: 0.8214\n",
      "Epoch 170/300\n",
      "1/1 - 0s - loss: 0.6358 - accuracy: 0.8214\n",
      "Epoch 171/300\n",
      "1/1 - 0s - loss: 0.6309 - accuracy: 0.8214\n",
      "Epoch 172/300\n",
      "1/1 - 0s - loss: 0.6261 - accuracy: 0.8214\n",
      "Epoch 173/300\n",
      "1/1 - 0s - loss: 0.6213 - accuracy: 0.8214\n",
      "Epoch 174/300\n",
      "1/1 - 0s - loss: 0.6165 - accuracy: 0.8214\n",
      "Epoch 175/300\n",
      "1/1 - 0s - loss: 0.6119 - accuracy: 0.8214\n",
      "Epoch 176/300\n",
      "1/1 - 0s - loss: 0.6072 - accuracy: 0.8214\n",
      "Epoch 177/300\n",
      "1/1 - 0s - loss: 0.6026 - accuracy: 0.8214\n",
      "Epoch 178/300\n",
      "1/1 - 0s - loss: 0.5981 - accuracy: 0.8214\n",
      "Epoch 179/300\n",
      "1/1 - 0s - loss: 0.5936 - accuracy: 0.8214\n",
      "Epoch 180/300\n",
      "1/1 - 0s - loss: 0.5891 - accuracy: 0.8214\n",
      "Epoch 181/300\n",
      "1/1 - 0s - loss: 0.5847 - accuracy: 0.8214\n",
      "Epoch 182/300\n",
      "1/1 - 0s - loss: 0.5803 - accuracy: 0.8214\n",
      "Epoch 183/300\n",
      "1/1 - 0s - loss: 0.5760 - accuracy: 0.8214\n",
      "Epoch 184/300\n",
      "1/1 - 0s - loss: 0.5717 - accuracy: 0.8214\n",
      "Epoch 185/300\n",
      "1/1 - 0s - loss: 0.5675 - accuracy: 0.8214\n",
      "Epoch 186/300\n",
      "1/1 - 0s - loss: 0.5633 - accuracy: 0.8214\n",
      "Epoch 187/300\n",
      "1/1 - 0s - loss: 0.5592 - accuracy: 0.8214\n",
      "Epoch 188/300\n",
      "1/1 - 0s - loss: 0.5551 - accuracy: 0.8571\n",
      "Epoch 189/300\n",
      "1/1 - 0s - loss: 0.5511 - accuracy: 0.8571\n",
      "Epoch 190/300\n",
      "1/1 - 0s - loss: 0.5470 - accuracy: 0.8571\n",
      "Epoch 191/300\n",
      "1/1 - 0s - loss: 0.5431 - accuracy: 0.8571\n",
      "Epoch 192/300\n",
      "1/1 - 0s - loss: 0.5392 - accuracy: 0.8571\n",
      "Epoch 193/300\n",
      "1/1 - 0s - loss: 0.5353 - accuracy: 0.8571\n",
      "Epoch 194/300\n",
      "1/1 - 0s - loss: 0.5315 - accuracy: 0.8571\n",
      "Epoch 195/300\n",
      "1/1 - 0s - loss: 0.5277 - accuracy: 0.8571\n",
      "Epoch 196/300\n",
      "1/1 - 0s - loss: 0.5239 - accuracy: 0.8571\n",
      "Epoch 197/300\n",
      "1/1 - 0s - loss: 0.5202 - accuracy: 0.8571\n",
      "Epoch 198/300\n",
      "1/1 - 0s - loss: 0.5166 - accuracy: 0.8571\n",
      "Epoch 199/300\n",
      "1/1 - 0s - loss: 0.5129 - accuracy: 0.8571\n",
      "Epoch 200/300\n",
      "1/1 - 0s - loss: 0.5094 - accuracy: 0.8571\n",
      "Epoch 201/300\n",
      "1/1 - 0s - loss: 0.5058 - accuracy: 0.8571\n",
      "Epoch 202/300\n",
      "1/1 - 0s - loss: 0.5023 - accuracy: 0.8571\n",
      "Epoch 203/300\n",
      "1/1 - 0s - loss: 0.4989 - accuracy: 0.8571\n",
      "Epoch 204/300\n",
      "1/1 - 0s - loss: 0.4955 - accuracy: 0.8571\n",
      "Epoch 205/300\n",
      "1/1 - 0s - loss: 0.4921 - accuracy: 0.8571\n",
      "Epoch 206/300\n",
      "1/1 - 0s - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 207/300\n",
      "1/1 - 0s - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 208/300\n",
      "1/1 - 0s - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 209/300\n",
      "1/1 - 0s - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 210/300\n",
      "1/1 - 0s - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 211/300\n",
      "1/1 - 0s - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 212/300\n",
      "1/1 - 0s - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 213/300\n",
      "1/1 - 0s - loss: 0.4666 - accuracy: 0.8929\n",
      "Epoch 214/300\n",
      "1/1 - 0s - loss: 0.4636 - accuracy: 0.8929\n",
      "Epoch 215/300\n",
      "1/1 - 0s - loss: 0.4606 - accuracy: 0.8929\n",
      "Epoch 216/300\n",
      "1/1 - 0s - loss: 0.4576 - accuracy: 0.8929\n",
      "Epoch 217/300\n",
      "1/1 - 0s - loss: 0.4547 - accuracy: 0.8929\n",
      "Epoch 218/300\n",
      "1/1 - 0s - loss: 0.4519 - accuracy: 0.8929\n",
      "Epoch 219/300\n",
      "1/1 - 0s - loss: 0.4490 - accuracy: 0.8929\n",
      "Epoch 220/300\n",
      "1/1 - 0s - loss: 0.4462 - accuracy: 0.8929\n",
      "Epoch 221/300\n",
      "1/1 - 0s - loss: 0.4435 - accuracy: 0.8929\n",
      "Epoch 222/300\n",
      "1/1 - 0s - loss: 0.4407 - accuracy: 0.8929\n",
      "Epoch 223/300\n",
      "1/1 - 0s - loss: 0.4380 - accuracy: 0.8929\n",
      "Epoch 224/300\n",
      "1/1 - 0s - loss: 0.4354 - accuracy: 0.8929\n",
      "Epoch 225/300\n",
      "1/1 - 0s - loss: 0.4328 - accuracy: 0.8929\n",
      "Epoch 226/300\n",
      "1/1 - 0s - loss: 0.4302 - accuracy: 0.8929\n",
      "Epoch 227/300\n",
      "1/1 - 0s - loss: 0.4276 - accuracy: 0.8929\n",
      "Epoch 228/300\n",
      "1/1 - 0s - loss: 0.4251 - accuracy: 0.8929\n",
      "Epoch 229/300\n",
      "1/1 - 0s - loss: 0.4226 - accuracy: 0.8929\n",
      "Epoch 230/300\n",
      "1/1 - 0s - loss: 0.4201 - accuracy: 0.8929\n",
      "Epoch 231/300\n",
      "1/1 - 0s - loss: 0.4177 - accuracy: 0.8929\n",
      "Epoch 232/300\n",
      "1/1 - 0s - loss: 0.4153 - accuracy: 0.8929\n",
      "Epoch 233/300\n",
      "1/1 - 0s - loss: 0.4129 - accuracy: 0.8929\n",
      "Epoch 234/300\n",
      "1/1 - 0s - loss: 0.4106 - accuracy: 0.8929\n",
      "Epoch 235/300\n",
      "1/1 - 0s - loss: 0.4083 - accuracy: 0.8929\n",
      "Epoch 236/300\n",
      "1/1 - 0s - loss: 0.4060 - accuracy: 0.8929\n",
      "Epoch 237/300\n",
      "1/1 - 0s - loss: 0.4037 - accuracy: 0.8929\n",
      "Epoch 238/300\n",
      "1/1 - 0s - loss: 0.4015 - accuracy: 0.8929\n",
      "Epoch 239/300\n",
      "1/1 - 0s - loss: 0.3993 - accuracy: 0.8929\n",
      "Epoch 240/300\n",
      "1/1 - 0s - loss: 0.3971 - accuracy: 0.8929\n",
      "Epoch 241/300\n",
      "1/1 - 0s - loss: 0.3950 - accuracy: 0.8929\n",
      "Epoch 242/300\n",
      "1/1 - 0s - loss: 0.3929 - accuracy: 0.8929\n",
      "Epoch 243/300\n",
      "1/1 - 0s - loss: 0.3908 - accuracy: 0.8929\n",
      "Epoch 244/300\n",
      "1/1 - 0s - loss: 0.3887 - accuracy: 0.8929\n",
      "Epoch 245/300\n",
      "1/1 - 0s - loss: 0.3867 - accuracy: 0.8929\n",
      "Epoch 246/300\n",
      "1/1 - 0s - loss: 0.3847 - accuracy: 0.8929\n",
      "Epoch 247/300\n",
      "1/1 - 0s - loss: 0.3827 - accuracy: 0.8929\n",
      "Epoch 248/300\n",
      "1/1 - 0s - loss: 0.3807 - accuracy: 0.8929\n",
      "Epoch 249/300\n",
      "1/1 - 0s - loss: 0.3788 - accuracy: 0.8929\n",
      "Epoch 250/300\n",
      "1/1 - 0s - loss: 0.3769 - accuracy: 0.8929\n",
      "Epoch 251/300\n",
      "1/1 - 0s - loss: 0.3750 - accuracy: 0.8929\n",
      "Epoch 252/300\n",
      "1/1 - 0s - loss: 0.3731 - accuracy: 0.8929\n",
      "Epoch 253/300\n",
      "1/1 - 0s - loss: 0.3713 - accuracy: 0.8929\n",
      "Epoch 254/300\n",
      "1/1 - 0s - loss: 0.3695 - accuracy: 0.8929\n",
      "Epoch 255/300\n",
      "1/1 - 0s - loss: 0.3677 - accuracy: 0.8929\n",
      "Epoch 256/300\n",
      "1/1 - 0s - loss: 0.3659 - accuracy: 0.8929\n",
      "Epoch 257/300\n",
      "1/1 - 0s - loss: 0.3641 - accuracy: 0.8929\n",
      "Epoch 258/300\n",
      "1/1 - 0s - loss: 0.3624 - accuracy: 0.8929\n",
      "Epoch 259/300\n",
      "1/1 - 0s - loss: 0.3607 - accuracy: 0.8929\n",
      "Epoch 260/300\n",
      "1/1 - 0s - loss: 0.3590 - accuracy: 0.8929\n",
      "Epoch 261/300\n",
      "1/1 - 0s - loss: 0.3573 - accuracy: 0.8929\n",
      "Epoch 262/300\n",
      "1/1 - 0s - loss: 0.3557 - accuracy: 0.8929\n",
      "Epoch 263/300\n",
      "1/1 - 0s - loss: 0.3540 - accuracy: 0.8929\n",
      "Epoch 264/300\n",
      "1/1 - 0s - loss: 0.3524 - accuracy: 0.8929\n",
      "Epoch 265/300\n",
      "1/1 - 0s - loss: 0.3508 - accuracy: 0.8929\n",
      "Epoch 266/300\n",
      "1/1 - 0s - loss: 0.3492 - accuracy: 0.8929\n",
      "Epoch 267/300\n",
      "1/1 - 0s - loss: 0.3477 - accuracy: 0.8929\n",
      "Epoch 268/300\n",
      "1/1 - 0s - loss: 0.3461 - accuracy: 0.8929\n",
      "Epoch 269/300\n",
      "1/1 - 0s - loss: 0.3446 - accuracy: 0.8929\n",
      "Epoch 270/300\n",
      "1/1 - 0s - loss: 0.3431 - accuracy: 0.8929\n",
      "Epoch 271/300\n",
      "1/1 - 0s - loss: 0.3416 - accuracy: 0.8929\n",
      "Epoch 272/300\n",
      "1/1 - 0s - loss: 0.3401 - accuracy: 0.8929\n",
      "Epoch 273/300\n",
      "1/1 - 0s - loss: 0.3387 - accuracy: 0.8929\n",
      "Epoch 274/300\n",
      "1/1 - 0s - loss: 0.3373 - accuracy: 0.8929\n",
      "Epoch 275/300\n",
      "1/1 - 0s - loss: 0.3358 - accuracy: 0.8929\n",
      "Epoch 276/300\n",
      "1/1 - 0s - loss: 0.3344 - accuracy: 0.8929\n",
      "Epoch 277/300\n",
      "1/1 - 0s - loss: 0.3331 - accuracy: 0.8929\n",
      "Epoch 278/300\n",
      "1/1 - 0s - loss: 0.3317 - accuracy: 0.8929\n",
      "Epoch 279/300\n",
      "1/1 - 0s - loss: 0.3303 - accuracy: 0.8929\n",
      "Epoch 280/300\n",
      "1/1 - 0s - loss: 0.3290 - accuracy: 0.8929\n",
      "Epoch 281/300\n",
      "1/1 - 0s - loss: 0.3277 - accuracy: 0.8929\n",
      "Epoch 282/300\n",
      "1/1 - 0s - loss: 0.3264 - accuracy: 0.8929\n",
      "Epoch 283/300\n",
      "1/1 - 0s - loss: 0.3251 - accuracy: 0.8929\n",
      "Epoch 284/300\n",
      "1/1 - 0s - loss: 0.3238 - accuracy: 0.8929\n",
      "Epoch 285/300\n",
      "1/1 - 0s - loss: 0.3225 - accuracy: 0.8929\n",
      "Epoch 286/300\n",
      "1/1 - 0s - loss: 0.3213 - accuracy: 0.8929\n",
      "Epoch 287/300\n",
      "1/1 - 0s - loss: 0.3200 - accuracy: 0.8929\n",
      "Epoch 288/300\n",
      "1/1 - 0s - loss: 0.3188 - accuracy: 0.8929\n",
      "Epoch 289/300\n",
      "1/1 - 0s - loss: 0.3176 - accuracy: 0.8929\n",
      "Epoch 290/300\n",
      "1/1 - 0s - loss: 0.3164 - accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "1/1 - 0s - loss: 0.3152 - accuracy: 0.8929\n",
      "Epoch 292/300\n",
      "1/1 - 0s - loss: 0.3141 - accuracy: 0.8929\n",
      "Epoch 293/300\n",
      "1/1 - 0s - loss: 0.3129 - accuracy: 0.8929\n",
      "Epoch 294/300\n",
      "1/1 - 0s - loss: 0.3118 - accuracy: 0.8929\n",
      "Epoch 295/300\n",
      "1/1 - 0s - loss: 0.3106 - accuracy: 0.8929\n",
      "Epoch 296/300\n",
      "1/1 - 0s - loss: 0.3095 - accuracy: 0.8929\n",
      "Epoch 297/300\n",
      "1/1 - 0s - loss: 0.3084 - accuracy: 0.8929\n",
      "Epoch 298/300\n",
      "1/1 - 0s - loss: 0.3073 - accuracy: 0.8929\n",
      "Epoch 299/300\n",
      "1/1 - 0s - loss: 0.3063 - accuracy: 0.8929\n",
      "Epoch 300/300\n",
      "1/1 - 0s - loss: 0.3052 - accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "\n",
    "# RNN 모델 생성\n",
    "model = Sequential()\n",
    "# 희소행렬로 변환 (10:벡터)\n",
    "model.add(Embedding(vocab_size, 10, input_length=X.shape[1]))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "# 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 학습시키기\n",
    "hist = model.fit(X, Y, epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3041 - accuracy: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30412811040878296, 0.8928571343421936]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15b3f1544f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습과정 보기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'], color='r', label=\"loss\")\n",
    "plt.plot(hist.history['accuracy'], color='g', label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측결과값 : 3\n",
      "예측된 단어 : 있는\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# '경마장에' 뒤에 나오는 단어를 model에 의해 추측\n",
    "encoded = t.texts_to_sequences(['경마장에'])[0]\n",
    "encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "result = model.predict_classes(encoded)\n",
    "print('예측결과값 :',result[0])\n",
    "for key, value in t.word_index.items():\n",
    "    if value==result[0]:\n",
    "        print(\"예측된 단어 :\", key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 :말이\n",
      "예측결과값 : 9\n",
      "예측된 단어 : 고와야\n"
     ]
    }
   ],
   "source": [
    "# 입력받은 다음 단어 추측하기\n",
    "word = input(\"입력 단어 :\")\n",
    "encoded = t.texts_to_sequences([word])[0]\n",
    "encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "result = np.argmax(model.predict(encoded))\n",
    "print('예측결과값 :',result)\n",
    "for key, value in t.word_index.items():\n",
    "    if value==result:\n",
    "        print(\"예측된 단어 :\", key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 다음 문맥 예측해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"경마장에\" 이후에 올 단어  4개 예측 => 경마장에 있는 말이 뛰고\n",
    "#  -----                   --\n",
    "def sentence_generation(model, t, current_word, n):\n",
    "    init_word = current_word\n",
    "    print(\"입력 단어 :\", init_word)\n",
    "    setence = \"\"\n",
    "    for i in range(1,n+1):\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        result = np.argmax(model.predict(encoded))\n",
    "        for word, index in t.word_index.items():\n",
    "            if index==result:\n",
    "                print(\"{}번째 : {}:{}\".format(i, word, result))\n",
    "                current_word = current_word + ' ' + word\n",
    "                break;\n",
    "    return current_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 : 경마장에\n",
      "1번째 : 있는:3\n",
      "2번째 : 말이:1\n",
      "3번째 : 뛰고:4\n",
      "4번째 : 있다:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'경마장에 있는 말이 뛰고 있다'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, \"경마장에\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 : 가는 말이\n",
      "1번째 : 고와야:9\n",
      "2번째 : 오는:10\n",
      "3번째 : 말이:1\n",
      "4번째 : 곱다:11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, \"가는 말이\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 - 2s - loss: 2.4835 - accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "1/1 - 0s - loss: 2.4787 - accuracy: 0.0357\n",
      "Epoch 3/300\n",
      "1/1 - 0s - loss: 2.4740 - accuracy: 0.0714\n",
      "Epoch 4/300\n",
      "1/1 - 0s - loss: 2.4692 - accuracy: 0.1429\n",
      "Epoch 5/300\n",
      "1/1 - 0s - loss: 2.4644 - accuracy: 0.1786\n",
      "Epoch 6/300\n",
      "1/1 - 0s - loss: 2.4595 - accuracy: 0.3929\n",
      "Epoch 7/300\n",
      "1/1 - 0s - loss: 2.4546 - accuracy: 0.3929\n",
      "Epoch 8/300\n",
      "1/1 - 0s - loss: 2.4495 - accuracy: 0.3929\n",
      "Epoch 9/300\n",
      "1/1 - 0s - loss: 2.4444 - accuracy: 0.4643\n",
      "Epoch 10/300\n",
      "1/1 - 0s - loss: 2.4391 - accuracy: 0.4643\n",
      "Epoch 11/300\n",
      "1/1 - 0s - loss: 2.4337 - accuracy: 0.4643\n",
      "Epoch 12/300\n",
      "1/1 - 0s - loss: 2.4282 - accuracy: 0.4643\n",
      "Epoch 13/300\n",
      "1/1 - 0s - loss: 2.4225 - accuracy: 0.3929\n",
      "Epoch 14/300\n",
      "1/1 - 0s - loss: 2.4166 - accuracy: 0.3214\n",
      "Epoch 15/300\n",
      "1/1 - 0s - loss: 2.4105 - accuracy: 0.3214\n",
      "Epoch 16/300\n",
      "1/1 - 0s - loss: 2.4042 - accuracy: 0.3214\n",
      "Epoch 17/300\n",
      "1/1 - 0s - loss: 2.3977 - accuracy: 0.3214\n",
      "Epoch 18/300\n",
      "1/1 - 0s - loss: 2.3909 - accuracy: 0.3214\n",
      "Epoch 19/300\n",
      "1/1 - 0s - loss: 2.3839 - accuracy: 0.3214\n",
      "Epoch 20/300\n",
      "1/1 - 0s - loss: 2.3765 - accuracy: 0.2857\n",
      "Epoch 21/300\n",
      "1/1 - 0s - loss: 2.3689 - accuracy: 0.2857\n",
      "Epoch 22/300\n",
      "1/1 - 0s - loss: 2.3610 - accuracy: 0.2857\n",
      "Epoch 23/300\n",
      "1/1 - 0s - loss: 2.3528 - accuracy: 0.2857\n",
      "Epoch 24/300\n",
      "1/1 - 0s - loss: 2.3442 - accuracy: 0.2857\n",
      "Epoch 25/300\n",
      "1/1 - 0s - loss: 2.3353 - accuracy: 0.2857\n",
      "Epoch 26/300\n",
      "1/1 - 0s - loss: 2.3260 - accuracy: 0.2857\n",
      "Epoch 27/300\n",
      "1/1 - 0s - loss: 2.3163 - accuracy: 0.2857\n",
      "Epoch 28/300\n",
      "1/1 - 0s - loss: 2.3062 - accuracy: 0.2857\n",
      "Epoch 29/300\n",
      "1/1 - 0s - loss: 2.2957 - accuracy: 0.2857\n",
      "Epoch 30/300\n",
      "1/1 - 0s - loss: 2.2848 - accuracy: 0.2857\n",
      "Epoch 31/300\n",
      "1/1 - 0s - loss: 2.2734 - accuracy: 0.2857\n",
      "Epoch 32/300\n",
      "1/1 - 0s - loss: 2.2616 - accuracy: 0.2857\n",
      "Epoch 33/300\n",
      "1/1 - 0s - loss: 2.2494 - accuracy: 0.2857\n",
      "Epoch 34/300\n",
      "1/1 - 0s - loss: 2.2367 - accuracy: 0.2857\n",
      "Epoch 35/300\n",
      "1/1 - 0s - loss: 2.2237 - accuracy: 0.2857\n",
      "Epoch 36/300\n",
      "1/1 - 0s - loss: 2.2102 - accuracy: 0.2857\n",
      "Epoch 37/300\n",
      "1/1 - 0s - loss: 2.1963 - accuracy: 0.2857\n",
      "Epoch 38/300\n",
      "1/1 - 0s - loss: 2.1822 - accuracy: 0.2857\n",
      "Epoch 39/300\n",
      "1/1 - 0s - loss: 2.1677 - accuracy: 0.2857\n",
      "Epoch 40/300\n",
      "1/1 - 0s - loss: 2.1531 - accuracy: 0.2857\n",
      "Epoch 41/300\n",
      "1/1 - 0s - loss: 2.1384 - accuracy: 0.2857\n",
      "Epoch 42/300\n",
      "1/1 - 0s - loss: 2.1238 - accuracy: 0.2857\n",
      "Epoch 43/300\n",
      "1/1 - 0s - loss: 2.1093 - accuracy: 0.2857\n",
      "Epoch 44/300\n",
      "1/1 - 0s - loss: 2.0953 - accuracy: 0.2857\n",
      "Epoch 45/300\n",
      "1/1 - 0s - loss: 2.0818 - accuracy: 0.2857\n",
      "Epoch 46/300\n",
      "1/1 - 0s - loss: 2.0691 - accuracy: 0.2857\n",
      "Epoch 47/300\n",
      "1/1 - 0s - loss: 2.0573 - accuracy: 0.2857\n",
      "Epoch 48/300\n",
      "1/1 - 0s - loss: 2.0465 - accuracy: 0.2857\n",
      "Epoch 49/300\n",
      "1/1 - 0s - loss: 2.0367 - accuracy: 0.2857\n",
      "Epoch 50/300\n",
      "1/1 - 0s - loss: 2.0278 - accuracy: 0.2857\n",
      "Epoch 51/300\n",
      "1/1 - 0s - loss: 2.0194 - accuracy: 0.2857\n",
      "Epoch 52/300\n",
      "1/1 - 0s - loss: 2.0115 - accuracy: 0.2857\n",
      "Epoch 53/300\n",
      "1/1 - 0s - loss: 2.0035 - accuracy: 0.2857\n",
      "Epoch 54/300\n",
      "1/1 - 0s - loss: 1.9955 - accuracy: 0.2857\n",
      "Epoch 55/300\n",
      "1/1 - 0s - loss: 1.9872 - accuracy: 0.2857\n",
      "Epoch 56/300\n",
      "1/1 - 0s - loss: 1.9786 - accuracy: 0.2857\n",
      "Epoch 57/300\n",
      "1/1 - 0s - loss: 1.9699 - accuracy: 0.2857\n",
      "Epoch 58/300\n",
      "1/1 - 0s - loss: 1.9611 - accuracy: 0.2857\n",
      "Epoch 59/300\n",
      "1/1 - 0s - loss: 1.9525 - accuracy: 0.2857\n",
      "Epoch 60/300\n",
      "1/1 - 0s - loss: 1.9441 - accuracy: 0.2857\n",
      "Epoch 61/300\n",
      "1/1 - 0s - loss: 1.9362 - accuracy: 0.2857\n",
      "Epoch 62/300\n",
      "1/1 - 0s - loss: 1.9287 - accuracy: 0.2857\n",
      "Epoch 63/300\n",
      "1/1 - 0s - loss: 1.9217 - accuracy: 0.2857\n",
      "Epoch 64/300\n",
      "1/1 - 0s - loss: 1.9152 - accuracy: 0.2857\n",
      "Epoch 65/300\n",
      "1/1 - 0s - loss: 1.9091 - accuracy: 0.2857\n",
      "Epoch 66/300\n",
      "1/1 - 0s - loss: 1.9033 - accuracy: 0.2857\n",
      "Epoch 67/300\n",
      "1/1 - 0s - loss: 1.8977 - accuracy: 0.2857\n",
      "Epoch 68/300\n",
      "1/1 - 0s - loss: 1.8921 - accuracy: 0.2857\n",
      "Epoch 69/300\n",
      "1/1 - 0s - loss: 1.8866 - accuracy: 0.2857\n",
      "Epoch 70/300\n",
      "1/1 - 0s - loss: 1.8809 - accuracy: 0.2857\n",
      "Epoch 71/300\n",
      "1/1 - 0s - loss: 1.8752 - accuracy: 0.2857\n",
      "Epoch 72/300\n",
      "1/1 - 0s - loss: 1.8693 - accuracy: 0.2857\n",
      "Epoch 73/300\n",
      "1/1 - 0s - loss: 1.8633 - accuracy: 0.2857\n",
      "Epoch 74/300\n",
      "1/1 - 0s - loss: 1.8572 - accuracy: 0.2857\n",
      "Epoch 75/300\n",
      "1/1 - 0s - loss: 1.8510 - accuracy: 0.2857\n",
      "Epoch 76/300\n",
      "1/1 - 0s - loss: 1.8447 - accuracy: 0.2857\n",
      "Epoch 77/300\n",
      "1/1 - 0s - loss: 1.8384 - accuracy: 0.2857\n",
      "Epoch 78/300\n",
      "1/1 - 0s - loss: 1.8321 - accuracy: 0.2857\n",
      "Epoch 79/300\n",
      "1/1 - 0s - loss: 1.8257 - accuracy: 0.2857\n",
      "Epoch 80/300\n",
      "1/1 - 0s - loss: 1.8193 - accuracy: 0.2857\n",
      "Epoch 81/300\n",
      "1/1 - 0s - loss: 1.8129 - accuracy: 0.2857\n",
      "Epoch 82/300\n",
      "1/1 - 0s - loss: 1.8064 - accuracy: 0.2857\n",
      "Epoch 83/300\n",
      "1/1 - 0s - loss: 1.7997 - accuracy: 0.2857\n",
      "Epoch 84/300\n",
      "1/1 - 0s - loss: 1.7930 - accuracy: 0.2857\n",
      "Epoch 85/300\n",
      "1/1 - 0s - loss: 1.7861 - accuracy: 0.2857\n",
      "Epoch 86/300\n",
      "1/1 - 0s - loss: 1.7791 - accuracy: 0.2857\n",
      "Epoch 87/300\n",
      "1/1 - 0s - loss: 1.7720 - accuracy: 0.2857\n",
      "Epoch 88/300\n",
      "1/1 - 0s - loss: 1.7647 - accuracy: 0.2857\n",
      "Epoch 89/300\n",
      "1/1 - 0s - loss: 1.7573 - accuracy: 0.2857\n",
      "Epoch 90/300\n",
      "1/1 - 0s - loss: 1.7497 - accuracy: 0.2857\n",
      "Epoch 91/300\n",
      "1/1 - 0s - loss: 1.7420 - accuracy: 0.2857\n",
      "Epoch 92/300\n",
      "1/1 - 0s - loss: 1.7341 - accuracy: 0.3214\n",
      "Epoch 93/300\n",
      "1/1 - 0s - loss: 1.7260 - accuracy: 0.3214\n",
      "Epoch 94/300\n",
      "1/1 - 0s - loss: 1.7178 - accuracy: 0.3214\n",
      "Epoch 95/300\n",
      "1/1 - 0s - loss: 1.7093 - accuracy: 0.3214\n",
      "Epoch 96/300\n",
      "1/1 - 0s - loss: 1.7006 - accuracy: 0.3571\n",
      "Epoch 97/300\n",
      "1/1 - 0s - loss: 1.6916 - accuracy: 0.3571\n",
      "Epoch 98/300\n",
      "1/1 - 0s - loss: 1.6824 - accuracy: 0.3571\n",
      "Epoch 99/300\n",
      "1/1 - 0s - loss: 1.6729 - accuracy: 0.3571\n",
      "Epoch 100/300\n",
      "1/1 - 0s - loss: 1.6631 - accuracy: 0.3929\n",
      "Epoch 101/300\n",
      "1/1 - 0s - loss: 1.6531 - accuracy: 0.3929\n",
      "Epoch 102/300\n",
      "1/1 - 0s - loss: 1.6428 - accuracy: 0.3929\n",
      "Epoch 103/300\n",
      "1/1 - 0s - loss: 1.6323 - accuracy: 0.3929\n",
      "Epoch 104/300\n",
      "1/1 - 0s - loss: 1.6214 - accuracy: 0.3929\n",
      "Epoch 105/300\n",
      "1/1 - 0s - loss: 1.6103 - accuracy: 0.3929\n",
      "Epoch 106/300\n",
      "1/1 - 0s - loss: 1.5988 - accuracy: 0.3929\n",
      "Epoch 107/300\n",
      "1/1 - 0s - loss: 1.5871 - accuracy: 0.3929\n",
      "Epoch 108/300\n",
      "1/1 - 0s - loss: 1.5750 - accuracy: 0.4286\n",
      "Epoch 109/300\n",
      "1/1 - 0s - loss: 1.5627 - accuracy: 0.4643\n",
      "Epoch 110/300\n",
      "1/1 - 0s - loss: 1.5500 - accuracy: 0.5714\n",
      "Epoch 111/300\n",
      "1/1 - 0s - loss: 1.5371 - accuracy: 0.5714\n",
      "Epoch 112/300\n",
      "1/1 - 0s - loss: 1.5238 - accuracy: 0.5714\n",
      "Epoch 113/300\n",
      "1/1 - 0s - loss: 1.5103 - accuracy: 0.6786\n",
      "Epoch 114/300\n",
      "1/1 - 0s - loss: 1.4964 - accuracy: 0.6786\n",
      "Epoch 115/300\n",
      "1/1 - 0s - loss: 1.4822 - accuracy: 0.6786\n",
      "Epoch 116/300\n",
      "1/1 - 0s - loss: 1.4677 - accuracy: 0.6786\n",
      "Epoch 117/300\n",
      "1/1 - 0s - loss: 1.4530 - accuracy: 0.6786\n",
      "Epoch 118/300\n",
      "1/1 - 0s - loss: 1.4379 - accuracy: 0.6786\n",
      "Epoch 119/300\n",
      "1/1 - 0s - loss: 1.4226 - accuracy: 0.6786\n",
      "Epoch 120/300\n",
      "1/1 - 0s - loss: 1.4070 - accuracy: 0.6786\n",
      "Epoch 121/300\n",
      "1/1 - 0s - loss: 1.3912 - accuracy: 0.6786\n",
      "Epoch 122/300\n",
      "1/1 - 0s - loss: 1.3751 - accuracy: 0.7143\n",
      "Epoch 123/300\n",
      "1/1 - 0s - loss: 1.3587 - accuracy: 0.7500\n",
      "Epoch 124/300\n",
      "1/1 - 0s - loss: 1.3422 - accuracy: 0.7500\n",
      "Epoch 125/300\n",
      "1/1 - 0s - loss: 1.3254 - accuracy: 0.7500\n",
      "Epoch 126/300\n",
      "1/1 - 0s - loss: 1.3085 - accuracy: 0.7500\n",
      "Epoch 127/300\n",
      "1/1 - 0s - loss: 1.2915 - accuracy: 0.7500\n",
      "Epoch 128/300\n",
      "1/1 - 0s - loss: 1.2743 - accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "1/1 - 0s - loss: 1.2570 - accuracy: 0.7500\n",
      "Epoch 130/300\n",
      "1/1 - 0s - loss: 1.2396 - accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "1/1 - 0s - loss: 1.2221 - accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "1/1 - 0s - loss: 1.2047 - accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "1/1 - 0s - loss: 1.1872 - accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "1/1 - 0s - loss: 1.1698 - accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "1/1 - 0s - loss: 1.1525 - accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "1/1 - 0s - loss: 1.1352 - accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "1/1 - 0s - loss: 1.1181 - accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "1/1 - 0s - loss: 1.1011 - accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "1/1 - 0s - loss: 1.0844 - accuracy: 0.7500\n",
      "Epoch 140/300\n",
      "1/1 - 0s - loss: 1.0678 - accuracy: 0.7500\n",
      "Epoch 141/300\n",
      "1/1 - 0s - loss: 1.0514 - accuracy: 0.7500\n",
      "Epoch 142/300\n",
      "1/1 - 0s - loss: 1.0352 - accuracy: 0.7500\n",
      "Epoch 143/300\n",
      "1/1 - 0s - loss: 1.0194 - accuracy: 0.7500\n",
      "Epoch 144/300\n",
      "1/1 - 0s - loss: 1.0037 - accuracy: 0.7500\n",
      "Epoch 145/300\n",
      "1/1 - 0s - loss: 0.9884 - accuracy: 0.7500\n",
      "Epoch 146/300\n",
      "1/1 - 0s - loss: 0.9734 - accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/300\n",
      "1/1 - 0s - loss: 0.9586 - accuracy: 0.7500\n",
      "Epoch 148/300\n",
      "1/1 - 0s - loss: 0.9442 - accuracy: 0.7857\n",
      "Epoch 149/300\n",
      "1/1 - 0s - loss: 0.9301 - accuracy: 0.7857\n",
      "Epoch 150/300\n",
      "1/1 - 0s - loss: 0.9162 - accuracy: 0.7857\n",
      "Epoch 151/300\n",
      "1/1 - 0s - loss: 0.9027 - accuracy: 0.7857\n",
      "Epoch 152/300\n",
      "1/1 - 0s - loss: 0.8895 - accuracy: 0.7857\n",
      "Epoch 153/300\n",
      "1/1 - 0s - loss: 0.8766 - accuracy: 0.7857\n",
      "Epoch 154/300\n",
      "1/1 - 0s - loss: 0.8639 - accuracy: 0.7857\n",
      "Epoch 155/300\n",
      "1/1 - 0s - loss: 0.8516 - accuracy: 0.7857\n",
      "Epoch 156/300\n",
      "1/1 - 0s - loss: 0.8395 - accuracy: 0.7857\n",
      "Epoch 157/300\n",
      "1/1 - 0s - loss: 0.8277 - accuracy: 0.7857\n",
      "Epoch 158/300\n",
      "1/1 - 0s - loss: 0.8162 - accuracy: 0.7857\n",
      "Epoch 159/300\n",
      "1/1 - 0s - loss: 0.8050 - accuracy: 0.7857\n",
      "Epoch 160/300\n",
      "1/1 - 0s - loss: 0.7940 - accuracy: 0.7857\n",
      "Epoch 161/300\n",
      "1/1 - 0s - loss: 0.7833 - accuracy: 0.7857\n",
      "Epoch 162/300\n",
      "1/1 - 0s - loss: 0.7728 - accuracy: 0.7857\n",
      "Epoch 163/300\n",
      "1/1 - 0s - loss: 0.7625 - accuracy: 0.7857\n",
      "Epoch 164/300\n",
      "1/1 - 0s - loss: 0.7525 - accuracy: 0.7857\n",
      "Epoch 165/300\n",
      "1/1 - 0s - loss: 0.7427 - accuracy: 0.7857\n",
      "Epoch 166/300\n",
      "1/1 - 0s - loss: 0.7332 - accuracy: 0.7857\n",
      "Epoch 167/300\n",
      "1/1 - 0s - loss: 0.7238 - accuracy: 0.7857\n",
      "Epoch 168/300\n",
      "1/1 - 0s - loss: 0.7147 - accuracy: 0.7857\n",
      "Epoch 169/300\n",
      "1/1 - 0s - loss: 0.7058 - accuracy: 0.7857\n",
      "Epoch 170/300\n",
      "1/1 - 0s - loss: 0.6971 - accuracy: 0.7857\n",
      "Epoch 171/300\n",
      "1/1 - 0s - loss: 0.6886 - accuracy: 0.7857\n",
      "Epoch 172/300\n",
      "1/1 - 0s - loss: 0.6803 - accuracy: 0.7857\n",
      "Epoch 173/300\n",
      "1/1 - 0s - loss: 0.6722 - accuracy: 0.7857\n",
      "Epoch 174/300\n",
      "1/1 - 0s - loss: 0.6643 - accuracy: 0.7857\n",
      "Epoch 175/300\n",
      "1/1 - 0s - loss: 0.6566 - accuracy: 0.7857\n",
      "Epoch 176/300\n",
      "1/1 - 0s - loss: 0.6490 - accuracy: 0.7857\n",
      "Epoch 177/300\n",
      "1/1 - 0s - loss: 0.6416 - accuracy: 0.7857\n",
      "Epoch 178/300\n",
      "1/1 - 0s - loss: 0.6344 - accuracy: 0.8214\n",
      "Epoch 179/300\n",
      "1/1 - 0s - loss: 0.6274 - accuracy: 0.8214\n",
      "Epoch 180/300\n",
      "1/1 - 0s - loss: 0.6206 - accuracy: 0.8214\n",
      "Epoch 181/300\n",
      "1/1 - 0s - loss: 0.6139 - accuracy: 0.8214\n",
      "Epoch 182/300\n",
      "1/1 - 0s - loss: 0.6073 - accuracy: 0.8214\n",
      "Epoch 183/300\n",
      "1/1 - 0s - loss: 0.6010 - accuracy: 0.8214\n",
      "Epoch 184/300\n",
      "1/1 - 0s - loss: 0.5947 - accuracy: 0.8214\n",
      "Epoch 185/300\n",
      "1/1 - 0s - loss: 0.5887 - accuracy: 0.8214\n",
      "Epoch 186/300\n",
      "1/1 - 0s - loss: 0.5827 - accuracy: 0.8214\n",
      "Epoch 187/300\n",
      "1/1 - 0s - loss: 0.5769 - accuracy: 0.8214\n",
      "Epoch 188/300\n",
      "1/1 - 0s - loss: 0.5713 - accuracy: 0.8214\n",
      "Epoch 189/300\n",
      "1/1 - 0s - loss: 0.5658 - accuracy: 0.8214\n",
      "Epoch 190/300\n",
      "1/1 - 0s - loss: 0.5604 - accuracy: 0.8214\n",
      "Epoch 191/300\n",
      "1/1 - 0s - loss: 0.5551 - accuracy: 0.8214\n",
      "Epoch 192/300\n",
      "1/1 - 0s - loss: 0.5500 - accuracy: 0.8214\n",
      "Epoch 193/300\n",
      "1/1 - 0s - loss: 0.5450 - accuracy: 0.8214\n",
      "Epoch 194/300\n",
      "1/1 - 0s - loss: 0.5401 - accuracy: 0.8214\n",
      "Epoch 195/300\n",
      "1/1 - 0s - loss: 0.5353 - accuracy: 0.8214\n",
      "Epoch 196/300\n",
      "1/1 - 0s - loss: 0.5306 - accuracy: 0.8214\n",
      "Epoch 197/300\n",
      "1/1 - 0s - loss: 0.5260 - accuracy: 0.8214\n",
      "Epoch 198/300\n",
      "1/1 - 0s - loss: 0.5215 - accuracy: 0.8214\n",
      "Epoch 199/300\n",
      "1/1 - 0s - loss: 0.5172 - accuracy: 0.8214\n",
      "Epoch 200/300\n",
      "1/1 - 0s - loss: 0.5129 - accuracy: 0.8214\n",
      "Epoch 201/300\n",
      "1/1 - 0s - loss: 0.5087 - accuracy: 0.8214\n",
      "Epoch 202/300\n",
      "1/1 - 0s - loss: 0.5046 - accuracy: 0.8214\n",
      "Epoch 203/300\n",
      "1/1 - 0s - loss: 0.5006 - accuracy: 0.8214\n",
      "Epoch 204/300\n",
      "1/1 - 0s - loss: 0.4967 - accuracy: 0.8214\n",
      "Epoch 205/300\n",
      "1/1 - 0s - loss: 0.4929 - accuracy: 0.8214\n",
      "Epoch 206/300\n",
      "1/1 - 0s - loss: 0.4891 - accuracy: 0.8214\n",
      "Epoch 207/300\n",
      "1/1 - 0s - loss: 0.4855 - accuracy: 0.8214\n",
      "Epoch 208/300\n",
      "1/1 - 0s - loss: 0.4819 - accuracy: 0.8214\n",
      "Epoch 209/300\n",
      "1/1 - 0s - loss: 0.4783 - accuracy: 0.8214\n",
      "Epoch 210/300\n",
      "1/1 - 0s - loss: 0.4749 - accuracy: 0.8214\n",
      "Epoch 211/300\n",
      "1/1 - 0s - loss: 0.4715 - accuracy: 0.8214\n",
      "Epoch 212/300\n",
      "1/1 - 0s - loss: 0.4682 - accuracy: 0.8214\n",
      "Epoch 213/300\n",
      "1/1 - 0s - loss: 0.4649 - accuracy: 0.8214\n",
      "Epoch 214/300\n",
      "1/1 - 0s - loss: 0.4617 - accuracy: 0.8214\n",
      "Epoch 215/300\n",
      "1/1 - 0s - loss: 0.4586 - accuracy: 0.8214\n",
      "Epoch 216/300\n",
      "1/1 - 0s - loss: 0.4555 - accuracy: 0.8214\n",
      "Epoch 217/300\n",
      "1/1 - 0s - loss: 0.4525 - accuracy: 0.8214\n",
      "Epoch 218/300\n",
      "1/1 - 0s - loss: 0.4495 - accuracy: 0.8214\n",
      "Epoch 219/300\n",
      "1/1 - 0s - loss: 0.4466 - accuracy: 0.8214\n",
      "Epoch 220/300\n",
      "1/1 - 0s - loss: 0.4437 - accuracy: 0.8214\n",
      "Epoch 221/300\n",
      "1/1 - 0s - loss: 0.4409 - accuracy: 0.8214\n",
      "Epoch 222/300\n",
      "1/1 - 0s - loss: 0.4381 - accuracy: 0.8214\n",
      "Epoch 223/300\n",
      "1/1 - 0s - loss: 0.4353 - accuracy: 0.8214\n",
      "Epoch 224/300\n",
      "1/1 - 0s - loss: 0.4326 - accuracy: 0.8214\n",
      "Epoch 225/300\n",
      "1/1 - 0s - loss: 0.4300 - accuracy: 0.8214\n",
      "Epoch 226/300\n",
      "1/1 - 0s - loss: 0.4274 - accuracy: 0.8571\n",
      "Epoch 227/300\n",
      "1/1 - 0s - loss: 0.4248 - accuracy: 0.8571\n",
      "Epoch 228/300\n",
      "1/1 - 0s - loss: 0.4222 - accuracy: 0.8571\n",
      "Epoch 229/300\n",
      "1/1 - 0s - loss: 0.4197 - accuracy: 0.8571\n",
      "Epoch 230/300\n",
      "1/1 - 0s - loss: 0.4172 - accuracy: 0.8571\n",
      "Epoch 231/300\n",
      "1/1 - 0s - loss: 0.4148 - accuracy: 0.8571\n",
      "Epoch 232/300\n",
      "1/1 - 0s - loss: 0.4124 - accuracy: 0.8571\n",
      "Epoch 233/300\n",
      "1/1 - 0s - loss: 0.4100 - accuracy: 0.8571\n",
      "Epoch 234/300\n",
      "1/1 - 0s - loss: 0.4076 - accuracy: 0.8571\n",
      "Epoch 235/300\n",
      "1/1 - 0s - loss: 0.4053 - accuracy: 0.8571\n",
      "Epoch 236/300\n",
      "1/1 - 0s - loss: 0.4030 - accuracy: 0.8571\n",
      "Epoch 237/300\n",
      "1/1 - 0s - loss: 0.4007 - accuracy: 0.8571\n",
      "Epoch 238/300\n",
      "1/1 - 0s - loss: 0.3985 - accuracy: 0.8571\n",
      "Epoch 239/300\n",
      "1/1 - 0s - loss: 0.3962 - accuracy: 0.8571\n",
      "Epoch 240/300\n",
      "1/1 - 0s - loss: 0.3940 - accuracy: 0.8571\n",
      "Epoch 241/300\n",
      "1/1 - 0s - loss: 0.3918 - accuracy: 0.8571\n",
      "Epoch 242/300\n",
      "1/1 - 0s - loss: 0.3896 - accuracy: 0.8571\n",
      "Epoch 243/300\n",
      "1/1 - 0s - loss: 0.3875 - accuracy: 0.8571\n",
      "Epoch 244/300\n",
      "1/1 - 0s - loss: 0.3853 - accuracy: 0.8571\n",
      "Epoch 245/300\n",
      "1/1 - 0s - loss: 0.3832 - accuracy: 0.8571\n",
      "Epoch 246/300\n",
      "1/1 - 0s - loss: 0.3811 - accuracy: 0.8571\n",
      "Epoch 247/300\n",
      "1/1 - 0s - loss: 0.3790 - accuracy: 0.8571\n",
      "Epoch 248/300\n",
      "1/1 - 0s - loss: 0.3769 - accuracy: 0.8571\n",
      "Epoch 249/300\n",
      "1/1 - 0s - loss: 0.3749 - accuracy: 0.8571\n",
      "Epoch 250/300\n",
      "1/1 - 0s - loss: 0.3728 - accuracy: 0.8571\n",
      "Epoch 251/300\n",
      "1/1 - 0s - loss: 0.3708 - accuracy: 0.8571\n",
      "Epoch 252/300\n",
      "1/1 - 0s - loss: 0.3688 - accuracy: 0.8571\n",
      "Epoch 253/300\n",
      "1/1 - 0s - loss: 0.3667 - accuracy: 0.8571\n",
      "Epoch 254/300\n",
      "1/1 - 0s - loss: 0.3647 - accuracy: 0.8571\n",
      "Epoch 255/300\n",
      "1/1 - 0s - loss: 0.3628 - accuracy: 0.8571\n",
      "Epoch 256/300\n",
      "1/1 - 0s - loss: 0.3608 - accuracy: 0.8571\n",
      "Epoch 257/300\n",
      "1/1 - 0s - loss: 0.3588 - accuracy: 0.8571\n",
      "Epoch 258/300\n",
      "1/1 - 0s - loss: 0.3569 - accuracy: 0.8571\n",
      "Epoch 259/300\n",
      "1/1 - 0s - loss: 0.3549 - accuracy: 0.8571\n",
      "Epoch 260/300\n",
      "1/1 - 0s - loss: 0.3530 - accuracy: 0.8571\n",
      "Epoch 261/300\n",
      "1/1 - 0s - loss: 0.3510 - accuracy: 0.8929\n",
      "Epoch 262/300\n",
      "1/1 - 0s - loss: 0.3491 - accuracy: 0.8929\n",
      "Epoch 263/300\n",
      "1/1 - 0s - loss: 0.3472 - accuracy: 0.8929\n",
      "Epoch 264/300\n",
      "1/1 - 0s - loss: 0.3453 - accuracy: 0.8929\n",
      "Epoch 265/300\n",
      "1/1 - 0s - loss: 0.3434 - accuracy: 0.8929\n",
      "Epoch 266/300\n",
      "1/1 - 0s - loss: 0.3415 - accuracy: 0.8929\n",
      "Epoch 267/300\n",
      "1/1 - 0s - loss: 0.3396 - accuracy: 0.8929\n",
      "Epoch 268/300\n",
      "1/1 - 0s - loss: 0.3378 - accuracy: 0.8929\n",
      "Epoch 269/300\n",
      "1/1 - 0s - loss: 0.3359 - accuracy: 0.8929\n",
      "Epoch 270/300\n",
      "1/1 - 0s - loss: 0.3341 - accuracy: 0.8929\n",
      "Epoch 271/300\n",
      "1/1 - 0s - loss: 0.3322 - accuracy: 0.8929\n",
      "Epoch 272/300\n",
      "1/1 - 0s - loss: 0.3304 - accuracy: 0.8929\n",
      "Epoch 273/300\n",
      "1/1 - 0s - loss: 0.3286 - accuracy: 0.8929\n",
      "Epoch 274/300\n",
      "1/1 - 0s - loss: 0.3268 - accuracy: 0.8929\n",
      "Epoch 275/300\n",
      "1/1 - 0s - loss: 0.3250 - accuracy: 0.8929\n",
      "Epoch 276/300\n",
      "1/1 - 0s - loss: 0.3232 - accuracy: 0.8929\n",
      "Epoch 277/300\n",
      "1/1 - 0s - loss: 0.3214 - accuracy: 0.8929\n",
      "Epoch 278/300\n",
      "1/1 - 0s - loss: 0.3196 - accuracy: 0.8929\n",
      "Epoch 279/300\n",
      "1/1 - 0s - loss: 0.3179 - accuracy: 0.8929\n",
      "Epoch 280/300\n",
      "1/1 - 0s - loss: 0.3161 - accuracy: 0.8929\n",
      "Epoch 281/300\n",
      "1/1 - 0s - loss: 0.3144 - accuracy: 0.8929\n",
      "Epoch 282/300\n",
      "1/1 - 0s - loss: 0.3127 - accuracy: 0.8929\n",
      "Epoch 283/300\n",
      "1/1 - 0s - loss: 0.3110 - accuracy: 0.8929\n",
      "Epoch 284/300\n",
      "1/1 - 0s - loss: 0.3093 - accuracy: 0.8929\n",
      "Epoch 285/300\n",
      "1/1 - 0s - loss: 0.3076 - accuracy: 0.8929\n",
      "Epoch 286/300\n",
      "1/1 - 0s - loss: 0.3060 - accuracy: 0.8929\n",
      "Epoch 287/300\n",
      "1/1 - 0s - loss: 0.3043 - accuracy: 0.8929\n",
      "Epoch 288/300\n",
      "1/1 - 0s - loss: 0.3027 - accuracy: 0.8929\n",
      "Epoch 289/300\n",
      "1/1 - 0s - loss: 0.3011 - accuracy: 0.8929\n",
      "Epoch 290/300\n",
      "1/1 - 0s - loss: 0.2995 - accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "1/1 - 0s - loss: 0.2980 - accuracy: 0.8929\n",
      "Epoch 292/300\n",
      "1/1 - 0s - loss: 0.2964 - accuracy: 0.8929\n",
      "Epoch 293/300\n",
      "1/1 - 0s - loss: 0.2949 - accuracy: 0.8929\n",
      "Epoch 294/300\n",
      "1/1 - 0s - loss: 0.2933 - accuracy: 0.8929\n",
      "Epoch 295/300\n",
      "1/1 - 0s - loss: 0.2919 - accuracy: 0.8929\n",
      "Epoch 296/300\n",
      "1/1 - 0s - loss: 0.2904 - accuracy: 0.8929\n",
      "Epoch 297/300\n",
      "1/1 - 0s - loss: 0.2889 - accuracy: 0.8929\n",
      "Epoch 298/300\n",
      "1/1 - 0s - loss: 0.2875 - accuracy: 0.8929\n",
      "Epoch 299/300\n",
      "1/1 - 0s - loss: 0.2861 - accuracy: 0.8929\n",
      "Epoch 300/300\n",
      "1/1 - 0s - loss: 0.2847 - accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
    "\n",
    "# RNN 모델 생성\n",
    "model = Sequential()\n",
    "# 희소행렬로 변환 (10:벡터)\n",
    "model.add(Embedding(vocab_size, 10, input_length=X.shape[1]))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "# 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 학습시키기\n",
    "hist = model.fit(X, Y, epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
