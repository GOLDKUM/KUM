{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.container{width:99% !important;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:18pt;}\n",
       "div.output{font-size:18pt; font-weight:bold;}\n",
       "div.input{font-family:Consolas; font-size:18pt;}\n",
       "div.prompt{min-width:100px;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\n",
    "\"\"\"<style>\n",
    "div.container{width:99% !important;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:18pt;}\n",
    "div.output{font-size:18pt; font-weight:bold;}\n",
    "div.input{font-family:Consolas; font-size:18pt;}\n",
    "div.prompt{min-width:100px;}\n",
    "</style>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. tensorflow v2.x에서 v1 버전 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# v1로 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow'\n",
      "Hello, TensorFlow\n"
     ]
    }
   ],
   "source": [
    "# tensor=data(상수, 변수), 연산\n",
    "# node1 상수 tensor 선언\n",
    "node1 = tf.constant('Hello, TensorFlow') \n",
    "# graph(computational grahp를 생성)\n",
    "sess = tf.Session()\n",
    "# print(node1)\n",
    "print(sess.run(node1)) # b가 의미하는 것은 byte literals\n",
    "# http://stackoverflow.com/questions/6269765\n",
    "print(sess.run(node1).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 30.0]\n"
     ]
    }
   ],
   "source": [
    "# 간단한 수학 연산 수행(computational graph)\n",
    "node1 = tf.constant(10, dtype=tf.float32)\n",
    "node2 = tf.constant(20, dtype=tf.float32)\n",
    "# node3 = node1 + node2\n",
    "node3 = tf.add(node1, node2)\n",
    "# computational graph 실행\n",
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2, node3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow \n",
    "<ol>\n",
    "    <li>그래프 정의</li>\n",
    "    <li>sess = tf.Session()를 실행</li>\n",
    "    <li>sess.run()을 통해 값을 확인할 수 있음</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "node1 = tf.constant(np.array([1,2,3]), dtype=tf.int16)\n",
    "node2 = tf.cast(node1, dtype=tf.float32)\n",
    "sess = tf.Session()\n",
    "print(sess.run(node1))\n",
    "print(sess.run(node2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "data = [1.,2.,3.,4.]\n",
    "m = tf.reduce_mean(data) # reduce_mean 평균값 연산\n",
    "sess = tf.Session()\n",
    "print(sess.run(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. tensorflow v1을 이용한 linear regression을 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 독립변수 x가 한개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째 cost:0.02034815587103367, W값:[0.8347227], b값:[0.3757142]\n",
      "400번째 cost:0.007769936695694923, W값:[0.8978686], b값:[0.23216864]\n",
      "600번째 cost:0.0029669369105249643, W값:[0.93688905], b값:[0.14346603]\n",
      "800번째 cost:0.0011329210828989744, W값:[0.96100134], b값:[0.08865321]\n",
      "1000번째 cost:0.0004326040216255933, W값:[0.9759012], b값:[0.05478227]\n",
      "1200번째 cost:0.0001651893398957327, W값:[0.98510844], b값:[0.0338521]\n",
      "1400번째 cost:6.307666626526043e-05, W값:[0.990798], b값:[0.02091847]\n",
      "1600번째 cost:2.4085305994958617e-05, W값:[0.9943137], b값:[0.0129263]\n",
      "1800번째 cost:9.197224244417157e-06, W값:[0.9964861], b값:[0.00798776]\n",
      "2000번째 cost:3.5120513075526105e-06, W값:[0.9978286], b값:[0.00493609]\n",
      "2200번째 cost:1.3411639656624175e-06, W값:[0.9986581], b값:[0.00305028]\n",
      "2400번째 cost:5.1229693553978e-07, W값:[0.9991708], b값:[0.00188511]\n",
      "2600번째 cost:1.9572318876726058e-07, W값:[0.9994874], b값:[0.00116518]\n",
      "2800번째 cost:7.483316011303032e-08, W값:[0.99968296], b값:[0.00072048]\n",
      "3000번째 cost:2.8660439355121525e-08, W값:[0.9998037], b값:[0.00044579]\n",
      "3200번째 cost:1.0983458587077166e-08, W값:[0.99987847], b값:[0.00027599]\n",
      "3400번째 cost:4.217520555016563e-09, W값:[0.9999246], b값:[0.00017099]\n",
      "3600번째 cost:1.6260548463264968e-09, W값:[0.9999532], b값:[0.00010623]\n",
      "3800번째 cost:6.276885122780129e-10, W값:[0.99997085], b값:[6.5831184e-05]\n",
      "4000번째 cost:2.3800142412433445e-10, W값:[0.9999822], b값:[4.0712614e-05]\n",
      "4200번째 cost:9.012449814216339e-11, W값:[0.99998903], b값:[2.4951594e-05]\n",
      "4400번째 cost:3.6879221898544756e-11, W값:[0.99999285], b값:[1.5937094e-05]\n",
      "4600번째 cost:1.7022166662328253e-11, W값:[0.99999505], b값:[1.0805003e-05]\n",
      "4800번째 cost:9.104835808904088e-12, W값:[0.9999963], b값:[7.8798475e-06]\n",
      "5000번째 cost:5.945106820032242e-12, W값:[0.9999971], b값:[6.229832e-06]\n",
      "5200번째 cost:4.31082036386754e-12, W값:[0.99999744], b값:[5.282977e-06]\n",
      "5400번째 cost:3.5272143279058144e-12, W값:[0.9999977], b값:[4.7545795e-06]\n",
      "5600번째 cost:3.2435783659662265e-12, W값:[0.99999774], b값:[4.5084325e-06]\n",
      "5800번째 cost:3.2432329391540726e-12, W값:[0.99999774], b값:[4.4905373e-06]\n",
      "6000번째 cost:3.243232722313638e-12, W값:[0.99999774], b값:[4.4902276e-06]\n"
     ]
    }
   ],
   "source": [
    "# tensor graph 정의\n",
    "\n",
    "# train data set\n",
    "# x = np.array([1,2,3])\n",
    "# y = np.array([1,2,3])\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "#Weight & Bias (처음에는 랜덤값을 셋팅했다가 학습과정에서 변경)\n",
    "W = tf.Variable(tf.random.normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function(최소제곱법)\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 우리의 목적은 cost함수가 최소가 되는 W와 b를 찾는 것\n",
    "'''\n",
    "cost함수는 제곱의 평균인 2차 함수이므로 곡선. 곡선위 미분값이 줄어드는 방향으로 학습\n",
    "'''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session \n",
    "sess = tf.Session()\n",
    "\n",
    "# Variable 노드 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 6000번 학습 (tensorflow v2. fit()함수)\n",
    "'''\n",
    "for step in range(1, 6001):\n",
    "    sess.run(train)\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step, \n",
    "                        sess.run(cost), sess.run(W), sess.run(b)))\n",
    "'''\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val, b_val = sess.run([train, cost, W, b])\n",
    "    if step%200 == 0:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step,\n",
    "                        cost_val, W_val, b_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.99999774], dtype=float32), array([4.4902276e-06], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_, b_ = sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종적으로 나온 회귀식 : H=0.9999977350234985*x + 4.490227638598299e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"최종적으로 나온 회귀식 : H={}*x + {}\".format(w_[0], b_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 cost:3.243232722313638e-12, W값:100.0, b값:1.9055131673812866\n",
      "201번째 cost:3.243232722313638e-12, W값:10.484940528869629, b값:-21.561498641967773\n",
      "401번째 cost:3.243232722313638e-12, W값:6.861116886138916, b값:-13.323695182800293\n",
      "601번째 cost:3.243232722313638e-12, W값:4.6218132972717285, b값:-8.233232498168945\n",
      "801번째 cost:3.243232722313638e-12, W값:3.2380611896514893, b값:-5.0876383781433105\n",
      "1001번째 cost:3.243232722313638e-12, W값:2.3829853534698486, b값:-3.143850803375244\n",
      "1201번째 cost:3.243232722313638e-12, W값:1.8546011447906494, b값:-1.942708969116211\n",
      "1401번째 cost:3.243232722313638e-12, W값:1.528091549873352, b값:-1.2004761695861816\n",
      "1601번째 cost:3.243232722313638e-12, W값:1.3263286352157593, b값:-0.7418213486671448\n",
      "1801번째 cost:3.243232722313638e-12, W값:1.2016510963439941, b값:-0.45840057730674744\n",
      "2001번째 cost:3.243232722313638e-12, W값:1.1246082782745361, b값:-0.28326380252838135\n",
      "2201번째 cost:3.243232722313638e-12, W값:1.0770002603530884, b값:-0.17503969371318817\n",
      "2401번째 cost:3.243232722313638e-12, W값:1.047581434249878, b값:-0.10816369205713272\n",
      "2601번째 cost:3.243232722313638e-12, W값:1.0294023752212524, b값:-0.06683849543333054\n",
      "2801번째 cost:3.243232722313638e-12, W값:1.0181689262390137, b값:-0.04130229353904724\n",
      "3001번째 cost:3.243232722313638e-12, W값:1.0112272500991821, b값:-0.025522125884890556\n",
      "3201번째 cost:3.243232722313638e-12, W값:1.0069377422332764, b값:-0.015771053731441498\n",
      "3401번째 cost:3.243232722313638e-12, W값:1.0042870044708252, b값:-0.009745407849550247\n",
      "3601번째 cost:3.243232722313638e-12, W값:1.002649188041687, b값:-0.006022319663316011\n",
      "3801번째 cost:3.243232722313638e-12, W값:1.00163733959198, b값:-0.0037218225188553333\n"
     ]
    }
   ],
   "source": [
    "# tensor graph 정의\n",
    "\n",
    "# train data set\n",
    "# x = np.array([1,2,3])\n",
    "# y = np.array([1,2,3])\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "#Weight & Bias (처음에는 랜덤값을 셋팅했다가 학습과정에서 변경)\n",
    "W = tf.Variable(100.0, name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function(최소제곱법)\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 우리의 목적은 cost함수가 최소가 되는 W와 b를 찾는 것\n",
    "'''\n",
    "cost함수는 제곱의 평균인 2차 함수이므로 곡선. 곡선위 미분값이 줄어드는 방향으로 학습\n",
    "'''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session \n",
    "sess = tf.Session()\n",
    "\n",
    "# Variable 노드 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 4000번 학습 (tensorflow v2. fit()함수)\n",
    "for step in range(1, 4001):\n",
    "    W_val, b_val = sess.run([W, b])\n",
    "    if step%200 == 1:\n",
    "        print(\"{}번째 cost:{}, W값:{}, b값:{}\".format(step,\n",
    "                        cost_val, W_val, b_val[0]))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 predict를 하기 위한 placeholder 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder 이용\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "#ab = tf.add(a+b)\n",
    "ab = a + b\n",
    "sess = tf.Session()\n",
    "sess.run(ab, feed_dict={a:10, b:20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12., 13.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ab, feed_dict={a : [1,2,3],\n",
    "                        b : [10,10,10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12., 13.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ab, feed_dict={a : np.array([1,2,3]),\n",
    "                        b : np.array([10,10,10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1값은 10\n",
      "node2값은 20\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# 그래프 실행 단계에서 값을 던져줌\n",
    "node1 = tf.placeholder(tf.float32)\n",
    "node2 = tf.placeholder(tf.float32)\n",
    "adder_node = node1 + node2\n",
    "sess = tf.Session()\n",
    "result = sess.run(adder_node, feed_dict={node1: input(\"node1값은 \"),\n",
    "                                         node2: input(\"node2값은 \")})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째:cost-0.4143863618373871, W-[2.7458534], b-[1.3045001]\n",
      "400번째:cost-0.15823297202587128, W-[2.4608922], b-[1.9522841]\n",
      "600번째:cost-0.06042104586958885, W-[2.2848032], b-[2.3525755]\n",
      "800번째:cost-0.02307167463004589, W-[2.1759908], b-[2.5999315]\n",
      "1000번째:cost-0.008809849619865417, W-[2.1087515], b-[2.7527826]\n",
      "1200번째:cost-0.0033639955800026655, W-[2.0672016], b-[2.847235]\n",
      "1400번째:cost-0.0012845421442762017, W-[2.0415266], b-[2.9056]\n",
      "1600번째:cost-0.000490499020088464, W-[2.0256605], b-[2.9416676]\n",
      "1800번째:cost-0.0001872936263680458, W-[2.0158567], b-[2.963954]\n",
      "2000번째:cost-7.151949830586091e-05, W-[2.0097985], b-[2.977726]\n",
      "2200번째:cost-2.731233871600125e-05, W-[2.006055], b-[2.9862354]\n",
      "2400번째:cost-1.0431122063891962e-05, W-[2.0037422], b-[2.9914935]\n",
      "2600번째:cost-3.985328476119321e-06, W-[2.0023131], b-[2.9947422]\n",
      "2800번째:cost-1.5233372323564254e-06, W-[2.0014303], b-[2.9967487]\n",
      "3000번째:cost-5.837588901158597e-07, W-[2.0008855], b-[2.9979882]\n",
      "3200번째:cost-2.236000256061743e-07, W-[2.0005481], b-[2.9987543]\n",
      "3400번째:cost-8.58335624798201e-08, W-[2.0003395], b-[2.9992282]\n",
      "3600번째:cost-3.3403694033040665e-08, W-[2.0002124], b-[2.9995189]\n",
      "3800번째:cost-1.3078306437819265e-08, W-[2.0001328], b-[2.9996989]\n",
      "4000번째:cost-5.2757513913093135e-09, W-[2.0000834], b-[2.9998085]\n",
      "4200번째:cost-2.064704629489711e-09, W-[2.0000525], b-[2.9998806]\n",
      "4400번째:cost-7.591249295835212e-10, W-[2.000032], b-[2.9999282]\n",
      "4600번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "4800번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5000번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5200번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5400번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5600번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "5800번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n",
      "6000번째:cost-4.848364487664014e-10, W-[2.000026], b-[2.999942]\n"
     ]
    }
   ],
   "source": [
    "# training data set (H = 2x + 3)\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [5, 7, 9]\n",
    "\n",
    "# placeholder 설정\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "y = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "# Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# 경사하강법\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 학습\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val, b_val = sess.run([train, cost, W, b], \n",
    "                                feed_dict={x:x_data, y:y_data})\n",
    "    if step%200==0:\n",
    "        print(\"{}번째:cost-{}, W-{}, b-{}\".format(step, \n",
    "                                                cost_val, W_val, b_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.000026], dtype=float32), array([2.999942], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.000072], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측해보기(predict)\n",
    "sess.run(H, feed_dict={x:5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.999968, 23.000202, 43.00046 ], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(H, feed_dict={x: np.array([1,10,20])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 scale이 다른 데이터들의 linear regression을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200번째 cost-79.30921936035156, W-[10.059395]\n",
      "400번째 cost-79.15502166748047, W-[10.129433]\n",
      "600번째 cost-79.1408920288086, W-[10.150646]\n",
      "800번째 cost-79.13957977294922, W-[10.157072]\n",
      "1000번째 cost-79.13948822021484, W-[10.1590185]\n",
      "1200번째 cost-79.13945770263672, W-[10.159608]\n",
      "1400번째 cost-79.13945007324219, W-[10.159786]\n",
      "1600번째 cost-79.13945007324219, W-[10.159841]\n",
      "1800번째 cost-79.13945007324219, W-[10.159857]\n",
      "2000번째 cost-79.13948059082031, W-[10.159862]\n",
      "2200번째 cost-79.13945007324219, W-[10.1598625]\n",
      "2400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "2600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "2800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "3800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "4800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5000번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5200번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5400번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5600번째 cost-79.13945770263672, W-[10.1598625]\n",
      "5800번째 cost-79.13945770263672, W-[10.1598625]\n",
      "6000번째 cost-79.13945770263672, W-[10.1598625]\n"
     ]
    }
   ],
   "source": [
    "# training data set (datadml scale이 다르면 학습 결과가 ?)\n",
    "x_data = [1, 2, 5, 8,10]\n",
    "y_data = [5,15,68,80,95]\n",
    "\n",
    "# placeholder를 설정\n",
    "x = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "y = tf.placeholder(dtype=tf.float32, shape=None)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "H = W * x + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train     = optimizer.minimize(cost)\n",
    "\n",
    "# session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val, W_val = sess.run([train, cost, W], feed_dict={x:x_data,\n",
    "                                                              y:y_data})\n",
    "    if step%200 == 0 :\n",
    "        print(\"{}번째 cost-{}, W-{}\".format(step, cost_val, W_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([10.1598625], dtype=float32), array([-0.23128414], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.36734], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측을 할 수 있으나 cost가 너무 큰 값이라 믿을 수 없음\n",
    "sess.run(H, feed_dict={x:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측이 제대로 안 되는 이유 : GradientDescentOptimizer에서 local최소값을 만나면\n",
    "# global 최소값이 따로 있어도 멈춤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 독립변수 x 가  여러개인 linear regression\n",
    "- scale이 다른 x, y값(교안 pt.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000번째 cost:12.403375625610352\n",
      "6000번째 cost:2.7397029399871826\n",
      "9000번째 cost:0.820421576499939\n",
      "12000번째 cost:0.42711812257766724\n",
      "15000번째 cost:0.3361228108406067\n",
      "18000번째 cost:0.30645254254341125\n",
      "21000번째 cost:0.2904375493526459\n",
      "24000번째 cost:0.2784835994243622\n",
      "27000번째 cost:0.2684950530529022\n",
      "30000번째 cost:0.25995779037475586\n",
      "33000번째 cost:0.2525762915611267\n",
      "36000번째 cost:0.2461874932050705\n",
      "39000번째 cost:0.24065783619880676\n",
      "42000번째 cost:0.2358899861574173\n",
      "45000번째 cost:0.23174957931041718\n",
      "48000번째 cost:0.2281590700149536\n",
      "51000번째 cost:0.2250383198261261\n",
      "54000번째 cost:0.22236569225788116\n",
      "57000번째 cost:0.22004151344299316\n",
      "60000번째 cost:0.21802644431591034\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "# x_data = [[73,80,75],\n",
    "#           [93,88,93],\n",
    "#           [89,91,90],\n",
    "#           [96,98,100],\n",
    "#           [73,66,70]]\n",
    "# y_data = [[152],[185],[180],[196],[142]]\n",
    "x_data = np.array([[73,80,75],\n",
    "                   [93,88,93],\n",
    "                   [89,91,90],\n",
    "                   [96,98,100],\n",
    "                   [73,66,70]])\n",
    "y_data = np.array([[152],\n",
    "                   [185],\n",
    "                   [180],\n",
    "                   [196],\n",
    "                   [142]])\n",
    "\n",
    "# placeholder \n",
    "X = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# session & Variable 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, \n",
    "                                                    Y : y_data})\n",
    "    if step%3000 == 0 :\n",
    "        print(\"{}번째 cost:{}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ozone량 예측 예제\n",
    "- 독립변수 x가 3 => Multi-variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000번째 cost 504.4783630371094\n",
      "6000번째 cost 469.5782775878906\n",
      "9000번째 cost 465.4649963378906\n",
      "12000번째 cost 464.9571228027344\n",
      "15000번째 cost 464.8715515136719\n",
      "18000번째 cost 464.8354797363281\n",
      "21000번째 cost 464.8051452636719\n",
      "24000번째 cost 464.77557373046875\n",
      "27000번째 cost 464.7461242675781\n",
      "30000번째 cost 464.71673583984375\n",
      "33000번째 cost 464.6874084472656\n",
      "36000번째 cost 464.6579895019531\n",
      "39000번째 cost 464.6286315917969\n",
      "42000번째 cost 464.5992736816406\n",
      "45000번째 cost 464.5699157714844\n",
      "48000번째 cost 464.54052734375\n",
      "51000번째 cost 464.5112609863281\n",
      "54000번째 cost 464.4820251464844\n",
      "57000번째 cost 464.452880859375\n",
      "60000번째 cost 464.42376708984375\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "x_data.shape, y_data.shape\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp\n",
       "1   36.0    118.0   8.0    72"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.639595]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(H, feed_dict={X:np.array([[118,8,72]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale 맞추는 방법 : normalization(많이 씀), standardization(표준화)\n",
    "#                   X - Xmin\n",
    "# normalization = ──────────────\n",
    "#                  Xmax - Xmin\n",
    "# 위의 식을 써도 되지만 라이브러리를 씀(sklearn.preprocessing.MinMaxScaler 이용)\n",
    "#                    x - Xmean(평균)\n",
    "# standardization = ────────────────\n",
    "#                     Xstd(표준편차)\n",
    "# 의 식을 써도 되지만 라이브러리 씀(sklearn.preprocessing.StandardScaler 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3000번째 cost 12.220887184143066\n",
      " 6000번째 cost 10.340862274169922\n",
      " 9000번째 cost 8.773386001586914\n",
      "12000번째 cost 7.46511697769165\n",
      "15000번째 cost 6.371936798095703\n",
      "18000번째 cost 5.4573845863342285\n",
      "21000번째 cost 4.691285610198975\n",
      "24000번째 cost 4.04865837097168\n",
      "27000번째 cost 3.508819580078125\n",
      "30000번째 cost 3.054633378982544\n",
      "33000번째 cost 2.6718876361846924\n",
      "36000번째 cost 2.3487956523895264\n",
      "39000번째 cost 2.075575351715088\n",
      "42000번째 cost 1.8440885543823242\n",
      "45000번째 cost 1.6475787162780762\n",
      "48000번째 cost 1.4804233312606812\n",
      "51000번째 cost 1.3379405736923218\n",
      "54000번째 cost 1.2162208557128906\n",
      "57000번째 cost 1.112007737159729\n",
      "60000번째 cost 1.022579312324524\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# scale 조정(standardization)\n",
    "#                    x - Xmean(평균)\n",
    "# standardization = ────────────────\n",
    "#                     Xstd(표준편차)\n",
    "data['Ozone'] = (data['Ozone']- data['Ozone'].mean())/data['Ozone'].std()\n",
    "data['Solar.R'] = (data['Solar.R']- data['Solar.R'].mean()) / data['Solar.R'].std()\n",
    "data['Wind'] = (data['Wind']- data['Wind'].mean())/data['Wind'].std()\n",
    "data['Temp'] = (data['Temp']- data['Temp'].mean())/data['Temp'].std()\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "x_data.shape, y_data.shape\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 하려면 scale이 맞춰진 데이터로 predict를 하고 결과를 다시 scale조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 조정 전 데이터 : \n",
      " [[190.    7.4  67.   41. ]\n",
      " [118.    8.   72.   36. ]\n",
      " [149.   12.6  74.   12. ]]\n",
      "scale 조정된 데이터 :\n",
      " [[0.55963303 0.27717391 0.25       0.23952096]\n",
      " [0.33944954 0.30978261 0.375      0.20958084]\n",
      " [0.43425076 0.55978261 0.425      0.06586826]]\n",
      " 3000번째 cost 0.07073533535003662\n",
      " 6000번째 cost 0.06718307733535767\n",
      " 9000번째 cost 0.06425295770168304\n",
      "12000번째 cost 0.06182699650526047\n",
      "15000번째 cost 0.05980963632464409\n",
      "18000번째 cost 0.05812251195311546\n",
      "21000번째 cost 0.05670461431145668\n",
      "24000번째 cost 0.055504001677036285\n",
      "27000번째 cost 0.05447942763566971\n",
      "30000번째 cost 0.053599122911691666\n",
      "33000번째 cost 0.052834492176771164\n",
      "36000번째 cost 0.05216507986187935\n",
      "39000번째 cost 0.05157206952571869\n",
      "42000번째 cost 0.051041774451732635\n",
      "45000번째 cost 0.050562936812639236\n",
      "48000번째 cost 0.05012625455856323\n",
      "51000번째 cost 0.049724020063877106\n",
      "54000번째 cost 0.049349721521139145\n",
      "57000번째 cost 0.048997651785612106\n",
      "60000번째 cost 0.04866626113653183\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "\n",
    "print('scale 조정 전 데이터 : \\n', np.c_[x_data[:3], y_data[:3]])\n",
    "# scale 조정(1) sklearn.preprocessing.MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale_x = MinMaxScaler() # scale_x : x_data를 scale조정할 객체\n",
    "# x_data에 대한 설정을 잡는 부분 ; x_data 3개 컬럼에 대한 max, min 설정\n",
    "scale_x.fit(x_data) \n",
    "x_data = scale_x.transform(x_data) # scale 조정된 x_data\n",
    "\n",
    "scale_y = MinMaxScaler()\n",
    "scale_y.fit(y_data)\n",
    "y_data = scale_y.transform(y_data) # scale 조정된 y_data\n",
    "print('scale 조정된 데이터 :\\n', np.c_[x_data[:3], y_data[:3]])\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. prediction\n",
    "input_data = np.array([[118., 8.,72.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 데이터 :  [[118.   8.  72.]]\n",
      "scale 조정된 데이터 : [[0.33944954 0.30978261 0.375     ]]\n"
     ]
    }
   ],
   "source": [
    "scale_input_data = scale_x.transform(input_data)\n",
    "print('원 데이터 : ', input_data)\n",
    "print('scale 조정된 데이터 :', scale_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32.24009]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_value = sess.run(H, feed_dict={X:scale_input_data})\n",
    "scale_y.inverse_transform(predict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조정전\n",
      " [[190.    7.4  67.   41. ]\n",
      " [118.    8.   72.   36. ]]\n",
      "조정후\n",
      " [[ 0.05728624 -0.71707784 -1.13764691 -0.03317961]\n",
      " [-0.73618283 -0.54766534 -0.61060682 -0.18411965]]\n",
      " 3000번째 cost 1.0834715366363525\n",
      " 6000번째 cost 1.006762146949768\n",
      " 9000번째 cost 0.9393858313560486\n",
      "12000번째 cost 0.8801088929176331\n",
      "15000번째 cost 0.8278818726539612\n",
      "18000번째 cost 0.781794011592865\n",
      "21000번째 cost 0.7410663962364197\n",
      "24000번째 cost 0.7050274610519409\n",
      "27000번째 cost 0.6730825304985046\n",
      "30000번째 cost 0.6447523236274719\n",
      "33000번째 cost 0.6195509433746338\n",
      "36000번째 cost 0.5971232652664185\n",
      "39000번째 cost 0.5771740078926086\n",
      "42000번째 cost 0.5593790411949158\n",
      "45000번째 cost 0.543472945690155\n",
      "48000번째 cost 0.5292603969573975\n",
      "51000번째 cost 0.5165302753448486\n",
      "54000번째 cost 0.5051326155662537\n",
      "57000번째 cost 0.4949003756046295\n",
      "60000번째 cost 0.48570775985717773\n"
     ]
    }
   ],
   "source": [
    "# training data set 생성\n",
    "# data load -> 결측치 처리 -> 독립변수, 종속변수 분리\n",
    "data = pd.read_csv('./data/ozone.csv', sep=\",\")\n",
    "\n",
    "# data를 바로 학습할 수 없음. 데이터 정제 작업 필요.\n",
    "data = data.dropna(how='any') # 결측치가 한열이라도 있는 행 모두 제거\n",
    "\n",
    "# 필요한 columns만 추출\n",
    "data = data[['Ozone','Solar.R','Wind','Temp']]\n",
    "\n",
    "# scale 조정 : data를 한꺼번에 scale 조정 시 prediction 힘듦\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data)\n",
    "# data = pd.DataFrame(scaler.transform(data),\n",
    "#                     columns=['Ozone','Solar.R','Wind','Temp'])\n",
    "\n",
    "# training data set\n",
    "x_data = data[['Solar.R','Wind','Temp']].values # DataFrame을 numpy 배열로\n",
    "y_data = data[['Ozone']].values.reshape(-1, 1)\n",
    "\n",
    "print('조정전\\n', np.c_[x_data[:2], y_data[:2]])\n",
    "# scale 조정 : x_data, y_data scale을 따로 따로 - prediction 가능\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_data)\n",
    "x_data = scaler_x.transform(x_data)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(y_data)\n",
    "y_data = scaler_y.transform(y_data)\n",
    "print('조정후\\n', np.c_[x_data[:2], y_data[:2]])\n",
    "\n",
    "# tensorflow 구현\n",
    "# 1.placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight & bias 설정\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# 3. Hypothesis\n",
    "# H = X @ W + b\n",
    "H = tf.matmul(X, W) + b\n",
    "\n",
    "# 4. cost 함수\n",
    "cost = tf.reduce_mean(tf.square(H - Y))\n",
    "\n",
    "# 5. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# 6. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 7. 학습\n",
    "for step in range(1, 60001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step%3000 == 0:\n",
    "        print(\"{:5d}번째 cost {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.43286]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.array([[118.,8.,72.]])\n",
    "scaled_input_data = scale_x.transform(input_data)\n",
    "scaler_y.inverse_transform(sess.run(H, feed_dict={X:scaled_input_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07578928],\n",
       "        [-0.581177  ],\n",
       "        [ 0.26848835]], dtype=float32),\n",
       " array([-0.17779972], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([W, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. logistic Regression = Binary classification(2개 그룹 그룹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w값은  0.12925170068027214 ,b값은  -0.27210884353741516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ad7925f5b0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic Regression이 필요한 이유(기존의 linear regression으로는 안 되는 이유)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "x = np.array([1,2,5,8,10])\n",
    "y = np.array([0,0,0,1,1])\n",
    "lm = stats.linregress(x, y)\n",
    "print('w값은 ', lm[0], ',b값은 ', lm[1])\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, x*lm[0]+lm[1], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w값은  0.03500583430571762 ,b값은  0.1732788798133022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ad785599d0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic Regression이 필요한 이유(기존의 linear regression으로는 안 되는 이유)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "x = np.array([1,2,5,8,10,30])\n",
    "y = np.array([0,0,0,1,1,1])\n",
    "lm = stats.linregress(x, y)\n",
    "print('w값은 ', lm[0], ',b값은 ', lm[1])\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, x*lm[0]+lm[1], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300번째 cost : 0.2797684371471405\n",
      "600번째 cost : 0.226466104388237\n",
      "900번째 cost : 0.19984284043312073\n",
      "1200번째 cost : 0.18191489577293396\n",
      "1500번째 cost : 0.16815365850925446\n",
      "1800번째 cost : 0.15684954822063446\n",
      "2100번째 cost : 0.1471954882144928\n",
      "2400번째 cost : 0.13875049352645874\n",
      "2700번째 cost : 0.1312459409236908\n",
      "3000번째 cost : 0.12450401484966278\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 교안 pt.51부터\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "# training data set\n",
    "x_data = np.array([[10,0],\n",
    "                   [8,1],\n",
    "                   [3,3],\n",
    "                   [2,3],\n",
    "                   [5,1],\n",
    "                   [2,0],\n",
    "                   [1,0]])\n",
    "y_data = np.array([[1],[1],[1],[1],[0],[0],[0]])\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight(2행1열) & bias(1개)\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# logits = X @ W + b\n",
    "logits = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# cost function\n",
    "# cost = tf.reduce_mean(tf.square(H - Y))\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                        labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost : {}\".format(step, cost_val))\n",
    "# 학습이 잘 되었는지 확인\n",
    "# Accuracy\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) # True True True True False True True\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print('정확도 :',sess.run(accuracy, feed_dict={X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H결과 : [[0.9650091]]\n",
      "predict 결과 : [[1.]]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print('H결과 :',sess.run(H, feed_dict={X:[[3,3]]} ))\n",
    "print('predict 결과 :',sess.run(predict, feed_dict={X:[[3,3]]} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. multinomial classification(3개이상 그룹)\n",
    "- 퀴즈 1,2,3 성적과 출석에 따른 A, B, C 등급 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300번째 cost : 1.1712361574172974\n",
      "600번째 cost : 0.9021403193473816\n",
      "900번째 cost : 0.6666759848594666\n",
      "1200번째 cost : 0.5538122057914734\n",
      "1500번째 cost : 0.49668893218040466\n",
      "1800번째 cost : 0.05605877563357353\n",
      "2100번째 cost : 0.0490470826625824\n",
      "2400번째 cost : 0.04476248845458031\n",
      "2700번째 cost : 0.041569553315639496\n",
      "3000번째 cost : 0.03900107741355896\n",
      "3300번째 cost : 0.03683843836188316\n",
      "3600번째 cost : 0.0349636971950531\n",
      "3900번째 cost : 0.03330614045262337\n",
      "4200번째 cost : 0.031820397824048996\n",
      "4500번째 cost : 0.030475158244371414\n",
      "4800번째 cost : 0.0292478296905756\n",
      "5100번째 cost : 0.02812121994793415\n",
      "5400번째 cost : 0.02708197757601738\n",
      "5700번째 cost : 0.026119273155927658\n",
      "6000번째 cost : 0.02522439882159233\n"
     ]
    }
   ],
   "source": [
    "# training data set(교안 pt.54)\n",
    "x_data = [[10,7,8,5],\n",
    "          [8,8,9,4],\n",
    "          [7,8,2,3],\n",
    "          [6,3,9,3],\n",
    "          [7,5,7,4],\n",
    "          [3,5,6,2],\n",
    "          [2,4,3,1]]\n",
    "# 종속변수는 multinomial classification에서는 원핫인코딩(교안pt.58)\n",
    "y_data =[[1, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 1, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 1]]\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "# Weight(4x3행렬) , bias(3개)\n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3])  , name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "# logits = X @ W + b\n",
    "logits = tf.matmul(X, W) + b\n",
    "# H = tf.nn.sigmoid(logits)\n",
    "H = tf.nn.softmax(logits) # softmax분류분석 최종단계에서 결과의 합이 1이 되도록\n",
    "\n",
    "# cost function\n",
    "# cost = tf.reduce_mean(tf.square(H - Y))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                        labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(1, 6001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost : {}\".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97769713 0.01968048 0.00262235]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "result = sess.run(H, feed_dict={X:[[8,8,9,4]]})\n",
    "print(result)\n",
    "print(result.argmax(axis=1)) # 0번째 열만 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "# accuracy 측정.\n",
    "# H => 0.97 0.19 0.002을 경우 H.argmax => 0\n",
    "# Y -> 1    0    0    을 경우 Y.argmax => 0\n",
    "predict = tf.argmax(H, axis=1) # 어떤 열의 값이 제일 큰지 index반환\n",
    "correct = tf.equal(predict, tf.argmax(Y, 1))\n",
    "# print(sess.run(correct, feed_dict={X:x_data, Y:y_data}))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. XOR(교안 pt.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300번째 cost : 0.7475399971008301\n",
      "600번째 cost : 0.7239876389503479\n",
      "900번째 cost : 0.7162603735923767\n",
      "1200번째 cost : 0.711338996887207\n",
      "1500번째 cost : 0.7075478434562683\n",
      "1800번째 cost : 0.7045468091964722\n",
      "2100번째 cost : 0.7021661996841431\n",
      "2400번째 cost : 0.7002792358398438\n",
      "2700번째 cost : 0.6987850666046143\n",
      "3000번째 cost : 0.6976026296615601\n",
      "정확도 : 0.25\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "x_data = [[0,0], [0,1], [1,0], [1,1]]\n",
    "y_data = [[0],   [1],   [1],   [0]]\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "# Hypothesis\n",
    "# H = X@W + b\n",
    "logits = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 학습\n",
    "for step in range(1, 3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost : {}\".format(step, cost_val))\n",
    "# accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) # False True False True\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print('정확도 :', sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "print(sess.run(predict, feed_dict={X:x_data} ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Deep Learning XOR 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300번째 cost : 0.7120675444602966\n",
      "600번째 cost : 0.7056372761726379\n",
      "900번째 cost : 0.7015881538391113\n",
      "1200번째 cost : 0.6981494426727295\n",
      "1500번째 cost : 0.695100724697113\n",
      "1800번째 cost : 0.6923468112945557\n",
      "2100번째 cost : 0.6898166537284851\n",
      "2400번째 cost : 0.6874524354934692\n",
      "2700번째 cost : 0.6852058172225952\n",
      "3000번째 cost : 0.6830363273620605\n",
      "정확도 : 0.5\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "x_data = [[0,0], [0,1], [1,0], [1,1]]\n",
    "y_data = [[0],   [1],   [1],   [0]]\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# layer 추가\n",
    "# Weight & bias(layer1= 입력2개 출력 4)\n",
    "W1 = tf.Variable(tf.random_normal([2,4]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([4]), name=\"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "# Weight & bias(layer2 = 입력4개, 출력1개)\n",
    "W2 = tf.Variable(tf.random_normal([4,1]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), name=\"bias2\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer1, W2) + b2\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 학습\n",
    "for step in range(1, 3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost : {}\".format(step, cost_val))\n",
    "# accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) # False True False True\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print('정확도 :', sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300번째 cost : 0.020221572369337082\n",
      "600번째 cost : 0.007499051745980978\n",
      "900번째 cost : 0.0043118176981806755\n",
      "1200번째 cost : 0.002976219402626157\n",
      "1500번째 cost : 0.002234631683677435\n",
      "1800번째 cost : 0.0017726717051118612\n",
      "2100번째 cost : 0.0014617728302255273\n",
      "2400번째 cost : 0.0012394721852615476\n",
      "2700번째 cost : 0.001072373823262751\n",
      "3000번째 cost : 0.0009424936142750084\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# training data set\n",
    "x_data = [[0,0], [0,1], [1,0], [1,1]]\n",
    "y_data = [[0],   [1],   [1],   [0]]\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# layer 추가\n",
    "# Weight & bias(layer1= 입력2개 출력 10)\n",
    "W1 = tf.Variable(tf.random_normal([2,10]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), name=\"bias1\")\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# Weight & bias(layer2 = 입력10개, 출력20개)\n",
    "W2 = tf.Variable(tf.random_normal([10,20]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([20]), name=\"bias2\")\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# Weight & bias(layer3 = 입력20개, 출력 10)\n",
    "W3 = tf.Variable(tf.random_normal([20,10]), name=\"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "layer3 = tf.nn.relu(tf.matmul(layer2, W3)+b3)\n",
    "\n",
    "# Weight & bias(output layer = 입력10개, 출력1)\n",
    "W4 = tf.Variable(tf.random_normal([10,1]), name=\"weight4\")\n",
    "b4 = tf.Variable(tf.random_normal([1]), name=\"bias4\")\n",
    "\n",
    "# Hypothesis\n",
    "logits = tf.matmul(layer3, W4) + b4\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# Session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 학습\n",
    "for step in range(1, 3001):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%300 == 0:\n",
    "        print(\"{}번째 cost : {}\".format(step, cost_val))\n",
    "# accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y) # False True False True\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print('정확도 :', sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
