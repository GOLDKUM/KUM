{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:100% !important;}\n",
       "div.CodeMirror{font-family:Consolas; font-size:17pt;}\n",
       "div.output{font-size:17pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:17pt;}\n",
       "div.prompt{min-width:70px;}\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:100% !important;}\n",
    "div.CodeMirror{font-family:Consolas; font-size:17pt;}\n",
    "div.output{font-size:17pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:17pt;}\n",
    "div.prompt{min-width:70px;}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist # mnist 데이터셋\n",
    "import tensorflow.keras.utils as utils # 원핫인코딩\n",
    "from tensorflow.keras.models import Sequential # 모델\n",
    "from tensorflow.keras.layers import Dense, Activation # model.add시\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 셋 준비하기\n",
    "# 훈련셋, 검증 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25f27a5c310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋과 검증셋 분리(X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28), (50000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋 - 학습할 때 사용\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증셋 - 학습할 때 사용\n",
    "len(X_val), len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋 - 모델 평가할 때 사용모델 평가할 때 사용\n",
    "len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28), (10000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32') / 255.0\n",
    "X_val   = X_val.reshape(10000,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴\n",
    "train_rand_idxs = np.random.choice(50000,700)\n",
    "val_rand_idxs   = np.random.choice(10000,300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25f27d95130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700,), (300,), (10000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "# 0 => 1 0 0 0 0 0 0 0 0 0 \n",
    "# 3 => 0 0 0 1 0 0 0 0 0 0 \n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val   = utils.to_categorical(Y_val)\n",
    "Y_test  = utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 10), (300, 10), (10000, 10))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]\n",
    "# 귀찮은 데이터 전처리 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 2.2990 - accuracy: 0.1211 - val_loss: 2.2047 - val_accuracy: 0.1933\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1828 - accuracy: 0.2158 - val_loss: 2.1075 - val_accuracy: 0.2367\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1150 - accuracy: 0.2028 - val_loss: 2.0406 - val_accuracy: 0.2633\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0286 - accuracy: 0.2367 - val_loss: 1.9757 - val_accuracy: 0.2833\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9541 - accuracy: 0.2434 - val_loss: 1.9309 - val_accuracy: 0.2467\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9085 - accuracy: 0.2381 - val_loss: 1.8908 - val_accuracy: 0.2700\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8851 - accuracy: 0.3010 - val_loss: 1.8584 - val_accuracy: 0.3067\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8184 - accuracy: 0.2922 - val_loss: 1.8221 - val_accuracy: 0.3267\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7796 - accuracy: 0.3584 - val_loss: 1.7993 - val_accuracy: 0.3367\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7264 - accuracy: 0.3810 - val_loss: 1.7681 - val_accuracy: 0.3533\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7653 - accuracy: 0.3508 - val_loss: 1.7451 - val_accuracy: 0.3467\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6521 - accuracy: 0.3829 - val_loss: 1.7246 - val_accuracy: 0.3633\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6132 - accuracy: 0.3619 - val_loss: 1.7124 - val_accuracy: 0.3667\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6543 - accuracy: 0.3671 - val_loss: 1.6915 - val_accuracy: 0.3600\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6512 - accuracy: 0.3389 - val_loss: 1.6794 - val_accuracy: 0.3667\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6193 - accuracy: 0.3809 - val_loss: 1.6645 - val_accuracy: 0.3900\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5917 - accuracy: 0.4135 - val_loss: 1.6493 - val_accuracy: 0.3967\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6144 - accuracy: 0.3794 - val_loss: 1.6422 - val_accuracy: 0.3800\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 1.5504 - accuracy: 0.4140 - val_loss: 1.6211 - val_accuracy: 0.3967\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5602 - accuracy: 0.4193 - val_loss: 1.6156 - val_accuracy: 0.4000\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5189 - accuracy: 0.4197 - val_loss: 1.5999 - val_accuracy: 0.4000\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5171 - accuracy: 0.4146 - val_loss: 1.5927 - val_accuracy: 0.4000\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4491 - accuracy: 0.4415 - val_loss: 1.5858 - val_accuracy: 0.4133\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4651 - accuracy: 0.4313 - val_loss: 1.5765 - val_accuracy: 0.4100\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5074 - accuracy: 0.4021 - val_loss: 1.5699 - val_accuracy: 0.4000\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4309 - accuracy: 0.4100 - val_loss: 1.5568 - val_accuracy: 0.4167\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4429 - accuracy: 0.4495 - val_loss: 1.5501 - val_accuracy: 0.4167\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4031 - accuracy: 0.4294 - val_loss: 1.5441 - val_accuracy: 0.4200\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4416 - accuracy: 0.4284 - val_loss: 1.5377 - val_accuracy: 0.4233\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4705 - accuracy: 0.4304 - val_loss: 1.5338 - val_accuracy: 0.4200\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3741 - accuracy: 0.4532 - val_loss: 1.5216 - val_accuracy: 0.4233\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4064 - accuracy: 0.4442 - val_loss: 1.5209 - val_accuracy: 0.4233\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3990 - accuracy: 0.4324 - val_loss: 1.5182 - val_accuracy: 0.4267\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3630 - accuracy: 0.4412 - val_loss: 1.5087 - val_accuracy: 0.4200\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3723 - accuracy: 0.4614 - val_loss: 1.5072 - val_accuracy: 0.4333\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3743 - accuracy: 0.4274 - val_loss: 1.5058 - val_accuracy: 0.4400\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3616 - accuracy: 0.4482 - val_loss: 1.4989 - val_accuracy: 0.4267\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3585 - accuracy: 0.4385 - val_loss: 1.4922 - val_accuracy: 0.4433\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3802 - accuracy: 0.4611 - val_loss: 1.4922 - val_accuracy: 0.4400\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3369 - accuracy: 0.4661 - val_loss: 1.4818 - val_accuracy: 0.4400\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3503 - accuracy: 0.4820 - val_loss: 1.4811 - val_accuracy: 0.4367\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3044 - accuracy: 0.4676 - val_loss: 1.4754 - val_accuracy: 0.4333\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3347 - accuracy: 0.4900 - val_loss: 1.4751 - val_accuracy: 0.4300\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3549 - accuracy: 0.4570 - val_loss: 1.4744 - val_accuracy: 0.4367\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3480 - accuracy: 0.4821 - val_loss: 1.4685 - val_accuracy: 0.4533\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3099 - accuracy: 0.4639 - val_loss: 1.4660 - val_accuracy: 0.4400\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2986 - accuracy: 0.4658 - val_loss: 1.4606 - val_accuracy: 0.4400\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2730 - accuracy: 0.5087 - val_loss: 1.4559 - val_accuracy: 0.4400\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2876 - accuracy: 0.4541 - val_loss: 1.4594 - val_accuracy: 0.4400\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2633 - accuracy: 0.4837 - val_loss: 1.4531 - val_accuracy: 0.4633\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2446 - accuracy: 0.4845 - val_loss: 1.4539 - val_accuracy: 0.4500\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2718 - accuracy: 0.4924 - val_loss: 1.4496 - val_accuracy: 0.4800\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2871 - accuracy: 0.5098 - val_loss: 1.4469 - val_accuracy: 0.4600\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2702 - accuracy: 0.4747 - val_loss: 1.4495 - val_accuracy: 0.4600\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2686 - accuracy: 0.4978 - val_loss: 1.4421 - val_accuracy: 0.4567\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2741 - accuracy: 0.5118 - val_loss: 1.4437 - val_accuracy: 0.4533\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2727 - accuracy: 0.5067 - val_loss: 1.4395 - val_accuracy: 0.4600\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2090 - accuracy: 0.5367 - val_loss: 1.4325 - val_accuracy: 0.4633\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2504 - accuracy: 0.5002 - val_loss: 1.4389 - val_accuracy: 0.4700\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2423 - accuracy: 0.5100 - val_loss: 1.4355 - val_accuracy: 0.4733\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2467 - accuracy: 0.5142 - val_loss: 1.4334 - val_accuracy: 0.4800\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2535 - accuracy: 0.5058 - val_loss: 1.4320 - val_accuracy: 0.4700\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1901 - accuracy: 0.5132 - val_loss: 1.4341 - val_accuracy: 0.4967\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2053 - accuracy: 0.5283 - val_loss: 1.4284 - val_accuracy: 0.4767\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2078 - accuracy: 0.5199 - val_loss: 1.4271 - val_accuracy: 0.4933\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2105 - accuracy: 0.5456 - val_loss: 1.4253 - val_accuracy: 0.4933\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2022 - accuracy: 0.5427 - val_loss: 1.4216 - val_accuracy: 0.4733\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1987 - accuracy: 0.5622 - val_loss: 1.4232 - val_accuracy: 0.4833\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1961 - accuracy: 0.5079 - val_loss: 1.4210 - val_accuracy: 0.5033\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1754 - accuracy: 0.5453 - val_loss: 1.4266 - val_accuracy: 0.4900\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2215 - accuracy: 0.5183 - val_loss: 1.4212 - val_accuracy: 0.4833\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2098 - accuracy: 0.5507 - val_loss: 1.4200 - val_accuracy: 0.4767\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1763 - accuracy: 0.5779 - val_loss: 1.4159 - val_accuracy: 0.4933\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1820 - accuracy: 0.5305 - val_loss: 1.4117 - val_accuracy: 0.4833\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1614 - accuracy: 0.5595 - val_loss: 1.4106 - val_accuracy: 0.4800\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1488 - accuracy: 0.5818 - val_loss: 1.4093 - val_accuracy: 0.4967\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1891 - accuracy: 0.5574 - val_loss: 1.4134 - val_accuracy: 0.5000\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1930 - accuracy: 0.5782 - val_loss: 1.4112 - val_accuracy: 0.4800\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1986 - accuracy: 0.5440 - val_loss: 1.4153 - val_accuracy: 0.4600\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1406 - accuracy: 0.5829 - val_loss: 1.4046 - val_accuracy: 0.4633\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1675 - accuracy: 0.5774 - val_loss: 1.4085 - val_accuracy: 0.4700\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1153 - accuracy: 0.6211 - val_loss: 1.4093 - val_accuracy: 0.4800\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1226 - accuracy: 0.5745 - val_loss: 1.4032 - val_accuracy: 0.4700\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1339 - accuracy: 0.5863 - val_loss: 1.4047 - val_accuracy: 0.4700\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1415 - accuracy: 0.6034 - val_loss: 1.4023 - val_accuracy: 0.4667\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1181 - accuracy: 0.6061 - val_loss: 1.4106 - val_accuracy: 0.4700\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1334 - accuracy: 0.5846 - val_loss: 1.4037 - val_accuracy: 0.4633\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1261 - accuracy: 0.5939 - val_loss: 1.3980 - val_accuracy: 0.4733\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1350 - accuracy: 0.6352 - val_loss: 1.3973 - val_accuracy: 0.4733\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1431 - accuracy: 0.5989 - val_loss: 1.4037 - val_accuracy: 0.4767\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1190 - accuracy: 0.6370 - val_loss: 1.4026 - val_accuracy: 0.4767\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1049 - accuracy: 0.6075 - val_loss: 1.4060 - val_accuracy: 0.4667\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1601 - accuracy: 0.5803 - val_loss: 1.4023 - val_accuracy: 0.4700\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1219 - accuracy: 0.6129 - val_loss: 1.3983 - val_accuracy: 0.4733\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0863 - accuracy: 0.5990 - val_loss: 1.4039 - val_accuracy: 0.4767\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0458 - accuracy: 0.6310 - val_loss: 1.3995 - val_accuracy: 0.4733\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0847 - accuracy: 0.6214 - val_loss: 1.3967 - val_accuracy: 0.4667\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1014 - accuracy: 0.6284 - val_loss: 1.3990 - val_accuracy: 0.4700\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1278 - accuracy: 0.5967 - val_loss: 1.3908 - val_accuracy: 0.4633\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1058 - accuracy: 0.6417 - val_loss: 1.4057 - val_accuracy: 0.4733\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1265 - accuracy: 0.5912 - val_loss: 1.4017 - val_accuracy: 0.4733\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0667 - accuracy: 0.6109 - val_loss: 1.3953 - val_accuracy: 0.4700\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1460 - accuracy: 0.5938 - val_loss: 1.3974 - val_accuracy: 0.4800\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1109 - accuracy: 0.6113 - val_loss: 1.4160 - val_accuracy: 0.4767\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0553 - accuracy: 0.6306 - val_loss: 1.3971 - val_accuracy: 0.4733\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0798 - accuracy: 0.6400 - val_loss: 1.3974 - val_accuracy: 0.4767\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1121 - accuracy: 0.6015 - val_loss: 1.3965 - val_accuracy: 0.4700\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0726 - accuracy: 0.6257 - val_loss: 1.4027 - val_accuracy: 0.4733\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0852 - accuracy: 0.6136 - val_loss: 1.4033 - val_accuracy: 0.4767\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0442 - accuracy: 0.6827 - val_loss: 1.3975 - val_accuracy: 0.4700\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1191 - accuracy: 0.5950 - val_loss: 1.3993 - val_accuracy: 0.4800\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0385 - accuracy: 0.6578 - val_loss: 1.3964 - val_accuracy: 0.4733\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0760 - accuracy: 0.6283 - val_loss: 1.3985 - val_accuracy: 0.4767\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1104 - accuracy: 0.6271 - val_loss: 1.4026 - val_accuracy: 0.4700\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0446 - accuracy: 0.6603 - val_loss: 1.4040 - val_accuracy: 0.4667\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0564 - accuracy: 0.6243 - val_loss: 1.4002 - val_accuracy: 0.4733\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0593 - accuracy: 0.6145 - val_loss: 1.4016 - val_accuracy: 0.4733\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0678 - accuracy: 0.6251 - val_loss: 1.4029 - val_accuracy: 0.4733\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0511 - accuracy: 0.6586 - val_loss: 1.4025 - val_accuracy: 0.4733\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0259 - accuracy: 0.6417 - val_loss: 1.3967 - val_accuracy: 0.4633\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0474 - accuracy: 0.6374 - val_loss: 1.3914 - val_accuracy: 0.4700\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0793 - accuracy: 0.6342 - val_loss: 1.3961 - val_accuracy: 0.4667\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0501 - accuracy: 0.6543 - val_loss: 1.4008 - val_accuracy: 0.4700\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0394 - accuracy: 0.6245 - val_loss: 1.4034 - val_accuracy: 0.4667\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0593 - accuracy: 0.6376 - val_loss: 1.4075 - val_accuracy: 0.4667\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.6538 - val_loss: 1.4086 - val_accuracy: 0.4800\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0781 - accuracy: 0.6328 - val_loss: 1.4063 - val_accuracy: 0.4633\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0183 - accuracy: 0.6409 - val_loss: 1.4101 - val_accuracy: 0.4700\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 912us/step - loss: 1.0414 - accuracy: 0.6495 - val_loss: 1.4108 - val_accuracy: 0.4667\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0194 - accuracy: 0.6616 - val_loss: 1.4033 - val_accuracy: 0.4667\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9860 - accuracy: 0.6655 - val_loss: 1.4029 - val_accuracy: 0.4600\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0344 - accuracy: 0.5997 - val_loss: 1.4141 - val_accuracy: 0.4767\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0437 - accuracy: 0.6440 - val_loss: 1.4090 - val_accuracy: 0.4733\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.6804 - val_loss: 1.4139 - val_accuracy: 0.4733\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0179 - accuracy: 0.6522 - val_loss: 1.4111 - val_accuracy: 0.4633\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0221 - accuracy: 0.6582 - val_loss: 1.4090 - val_accuracy: 0.4600\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0172 - accuracy: 0.6360 - val_loss: 1.4149 - val_accuracy: 0.4567\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0264 - accuracy: 0.6381 - val_loss: 1.4179 - val_accuracy: 0.4700\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0322 - accuracy: 0.6260 - val_loss: 1.4121 - val_accuracy: 0.4600\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0507 - accuracy: 0.6427 - val_loss: 1.4207 - val_accuracy: 0.4567\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9937 - accuracy: 0.6745 - val_loss: 1.4111 - val_accuracy: 0.4667\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 974us/step - loss: 1.0319 - accuracy: 0.6394 - val_loss: 1.4213 - val_accuracy: 0.4633\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0014 - accuracy: 0.6715 - val_loss: 1.4178 - val_accuracy: 0.4633\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9704 - accuracy: 0.6650 - val_loss: 1.4196 - val_accuracy: 0.4633\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0153 - accuracy: 0.6554 - val_loss: 1.4164 - val_accuracy: 0.4667\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0095 - accuracy: 0.6619 - val_loss: 1.4219 - val_accuracy: 0.4533\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0226 - accuracy: 0.6757 - val_loss: 1.4179 - val_accuracy: 0.4633\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.6360 - val_loss: 1.4185 - val_accuracy: 0.4600\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9886 - accuracy: 0.6712 - val_loss: 1.4201 - val_accuracy: 0.4667\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9886 - accuracy: 0.6574 - val_loss: 1.4278 - val_accuracy: 0.4667\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9941 - accuracy: 0.6694 - val_loss: 1.4241 - val_accuracy: 0.4667\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0008 - accuracy: 0.6759 - val_loss: 1.4294 - val_accuracy: 0.4633\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9398 - accuracy: 0.6824 - val_loss: 1.4250 - val_accuracy: 0.4667\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9791 - accuracy: 0.6442 - val_loss: 1.4218 - val_accuracy: 0.4700\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0109 - accuracy: 0.6380 - val_loss: 1.4323 - val_accuracy: 0.4633\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9922 - accuracy: 0.6538 - val_loss: 1.4309 - val_accuracy: 0.4667\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9526 - accuracy: 0.6561 - val_loss: 1.4208 - val_accuracy: 0.4633\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9583 - accuracy: 0.6851 - val_loss: 1.4249 - val_accuracy: 0.4633\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9821 - accuracy: 0.6465 - val_loss: 1.4354 - val_accuracy: 0.4700\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9824 - accuracy: 0.6556 - val_loss: 1.4287 - val_accuracy: 0.4700\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 978us/step - loss: 1.0483 - accuracy: 0.6528 - val_loss: 1.4453 - val_accuracy: 0.4700\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9885 - accuracy: 0.6846 - val_loss: 1.4372 - val_accuracy: 0.4700\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9794 - accuracy: 0.6425 - val_loss: 1.4352 - val_accuracy: 0.4633\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9530 - accuracy: 0.6670 - val_loss: 1.4305 - val_accuracy: 0.4633\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 987us/step - loss: 0.9471 - accuracy: 0.6724 - val_loss: 1.4348 - val_accuracy: 0.4633\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0382 - accuracy: 0.6611 - val_loss: 1.4386 - val_accuracy: 0.4700\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9718 - accuracy: 0.6803 - val_loss: 1.4395 - val_accuracy: 0.4633\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9535 - accuracy: 0.6934 - val_loss: 1.4390 - val_accuracy: 0.4667\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9631 - accuracy: 0.6520 - val_loss: 1.4518 - val_accuracy: 0.4733\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0409 - accuracy: 0.6422 - val_loss: 1.4421 - val_accuracy: 0.4700\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9664 - accuracy: 0.6648 - val_loss: 1.4406 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.6903 - val_loss: 1.4474 - val_accuracy: 0.4700\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0084 - accuracy: 0.6407 - val_loss: 1.4535 - val_accuracy: 0.4700\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0129 - accuracy: 0.6743 - val_loss: 1.4368 - val_accuracy: 0.4700\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9414 - accuracy: 0.6617 - val_loss: 1.4423 - val_accuracy: 0.4633\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9604 - accuracy: 0.6579 - val_loss: 1.4458 - val_accuracy: 0.4667\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.6416 - val_loss: 1.4475 - val_accuracy: 0.4667\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9704 - accuracy: 0.6720 - val_loss: 1.4474 - val_accuracy: 0.4700\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9716 - accuracy: 0.6680 - val_loss: 1.4439 - val_accuracy: 0.4667\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9406 - accuracy: 0.6697 - val_loss: 1.4566 - val_accuracy: 0.4633\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9329 - accuracy: 0.6670 - val_loss: 1.4460 - val_accuracy: 0.4667\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9346 - accuracy: 0.6621 - val_loss: 1.4517 - val_accuracy: 0.4633\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0067 - accuracy: 0.6335 - val_loss: 1.4672 - val_accuracy: 0.4767\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9492 - accuracy: 0.6744 - val_loss: 1.4540 - val_accuracy: 0.4633\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 0.9250 - accuracy: 0.6765 - val_loss: 1.4583 - val_accuracy: 0.4667\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.6897 - val_loss: 1.4530 - val_accuracy: 0.4733\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.6669 - val_loss: 1.4665 - val_accuracy: 0.4667\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9685 - accuracy: 0.6520 - val_loss: 1.4546 - val_accuracy: 0.4600\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.6441 - val_loss: 1.4580 - val_accuracy: 0.4667\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9649 - accuracy: 0.6661 - val_loss: 1.4708 - val_accuracy: 0.4733\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8755 - accuracy: 0.6838 - val_loss: 1.4669 - val_accuracy: 0.4667\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9432 - accuracy: 0.6848 - val_loss: 1.4656 - val_accuracy: 0.4667\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9231 - accuracy: 0.6892 - val_loss: 1.4689 - val_accuracy: 0.4667\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9719 - accuracy: 0.6535 - val_loss: 1.4757 - val_accuracy: 0.4700\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.6990 - val_loss: 1.4789 - val_accuracy: 0.4733\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9683 - accuracy: 0.6622 - val_loss: 1.4730 - val_accuracy: 0.4733\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 996us/step - loss: 0.9100 - accuracy: 0.7003 - val_loss: 1.4663 - val_accuracy: 0.4733\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.9496 - accuracy: 0.6623 - val_loss: 1.4766 - val_accuracy: 0.4733\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9627 - accuracy: 0.6386 - val_loss: 1.4720 - val_accuracy: 0.4700\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9178 - accuracy: 0.6807 - val_loss: 1.4788 - val_accuracy: 0.4767\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9132 - accuracy: 0.6734 - val_loss: 1.4843 - val_accuracy: 0.4833\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.6841 - val_loss: 1.4852 - val_accuracy: 0.4733\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9449 - accuracy: 0.6540 - val_loss: 1.4844 - val_accuracy: 0.4700\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9071 - accuracy: 0.6907 - val_loss: 1.4759 - val_accuracy: 0.4767\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9553 - accuracy: 0.6643 - val_loss: 1.4858 - val_accuracy: 0.4700\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.6777 - val_loss: 1.4800 - val_accuracy: 0.4633\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9365 - accuracy: 0.6570 - val_loss: 1.4902 - val_accuracy: 0.4700\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9056 - accuracy: 0.6749 - val_loss: 1.4861 - val_accuracy: 0.4733\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9215 - accuracy: 0.6675 - val_loss: 1.4955 - val_accuracy: 0.4767\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9318 - accuracy: 0.6857 - val_loss: 1.4942 - val_accuracy: 0.4700\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9025 - accuracy: 0.6894 - val_loss: 1.4973 - val_accuracy: 0.4767\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8939 - accuracy: 0.6894 - val_loss: 1.4974 - val_accuracy: 0.4767\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9244 - accuracy: 0.6829 - val_loss: 1.4997 - val_accuracy: 0.4767\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9196 - accuracy: 0.6745 - val_loss: 1.4998 - val_accuracy: 0.4700\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9391 - accuracy: 0.6889 - val_loss: 1.4960 - val_accuracy: 0.4700\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.6915 - val_loss: 1.5010 - val_accuracy: 0.4767\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.6682 - val_loss: 1.4941 - val_accuracy: 0.4733\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8660 - accuracy: 0.6626 - val_loss: 1.4968 - val_accuracy: 0.4800\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 952us/step - loss: 0.8951 - accuracy: 0.7138 - val_loss: 1.5047 - val_accuracy: 0.4767\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8983 - accuracy: 0.6815 - val_loss: 1.5109 - val_accuracy: 0.4767\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9231 - accuracy: 0.6798 - val_loss: 1.5005 - val_accuracy: 0.4767\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8816 - accuracy: 0.6874 - val_loss: 1.5038 - val_accuracy: 0.4767\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9229 - accuracy: 0.6823 - val_loss: 1.5050 - val_accuracy: 0.4800\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9360 - accuracy: 0.6815 - val_loss: 1.5110 - val_accuracy: 0.4700\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0184 - accuracy: 0.6830 - val_loss: 1.5032 - val_accuracy: 0.4733\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.7016 - val_loss: 1.5013 - val_accuracy: 0.4767\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9243 - accuracy: 0.7103 - val_loss: 1.5084 - val_accuracy: 0.4767\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9381 - accuracy: 0.6803 - val_loss: 1.5201 - val_accuracy: 0.4767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9587 - accuracy: 0.6680 - val_loss: 1.5203 - val_accuracy: 0.4767\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8598 - accuracy: 0.6976 - val_loss: 1.5355 - val_accuracy: 0.4767\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.9176 - accuracy: 0.6867 - val_loss: 1.5093 - val_accuracy: 0.4700\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9007 - accuracy: 0.7033 - val_loss: 1.5202 - val_accuracy: 0.4833\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9079 - accuracy: 0.7024 - val_loss: 1.5279 - val_accuracy: 0.4800\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8714 - accuracy: 0.6805 - val_loss: 1.5147 - val_accuracy: 0.4800\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9244 - accuracy: 0.6670 - val_loss: 1.5374 - val_accuracy: 0.4833\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.8943 - accuracy: 0.6714 - val_loss: 1.5208 - val_accuracy: 0.4767\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8793 - accuracy: 0.6924 - val_loss: 1.5265 - val_accuracy: 0.4767\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8658 - accuracy: 0.7011 - val_loss: 1.5111 - val_accuracy: 0.4700\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8837 - accuracy: 0.6916 - val_loss: 1.5357 - val_accuracy: 0.4800\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9182 - accuracy: 0.6506 - val_loss: 1.5152 - val_accuracy: 0.4667\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9219 - accuracy: 0.7008 - val_loss: 1.5378 - val_accuracy: 0.4767\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8453 - accuracy: 0.6789 - val_loss: 1.5225 - val_accuracy: 0.4800\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8872 - accuracy: 0.6977 - val_loss: 1.5261 - val_accuracy: 0.4767\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9001 - accuracy: 0.6935 - val_loss: 1.5362 - val_accuracy: 0.4767\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8694 - accuracy: 0.6918 - val_loss: 1.5392 - val_accuracy: 0.4833\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9030 - accuracy: 0.6853 - val_loss: 1.5507 - val_accuracy: 0.4700\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 0.8961 - accuracy: 0.6833 - val_loss: 1.5477 - val_accuracy: 0.4867\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.6614 - val_loss: 1.5403 - val_accuracy: 0.4767\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.6912 - val_loss: 1.5394 - val_accuracy: 0.4700\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.6785 - val_loss: 1.5418 - val_accuracy: 0.4800\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8876 - accuracy: 0.6815 - val_loss: 1.5414 - val_accuracy: 0.4700\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8821 - accuracy: 0.6554 - val_loss: 1.5631 - val_accuracy: 0.4667\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9214 - accuracy: 0.6921 - val_loss: 1.5510 - val_accuracy: 0.4700\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 990us/step - loss: 0.8756 - accuracy: 0.7056 - val_loss: 1.5655 - val_accuracy: 0.4700\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.8311 - accuracy: 0.7170 - val_loss: 1.5516 - val_accuracy: 0.4667\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.6981 - val_loss: 1.5525 - val_accuracy: 0.4733\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.6861 - val_loss: 1.5474 - val_accuracy: 0.4833\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8854 - accuracy: 0.6759 - val_loss: 1.5481 - val_accuracy: 0.4767\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9312 - accuracy: 0.6835 - val_loss: 1.5639 - val_accuracy: 0.4767\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8661 - accuracy: 0.6830 - val_loss: 1.5645 - val_accuracy: 0.4800\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8760 - accuracy: 0.7150 - val_loss: 1.5697 - val_accuracy: 0.4700\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8420 - accuracy: 0.7162 - val_loss: 1.5571 - val_accuracy: 0.4767\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8516 - accuracy: 0.7112 - val_loss: 1.5607 - val_accuracy: 0.4767\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8693 - accuracy: 0.7167 - val_loss: 1.5485 - val_accuracy: 0.4667\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8798 - accuracy: 0.6927 - val_loss: 1.5764 - val_accuracy: 0.4667\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.6844 - val_loss: 1.5710 - val_accuracy: 0.4867\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.6938 - val_loss: 1.5640 - val_accuracy: 0.4767\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9022 - accuracy: 0.6820 - val_loss: 1.5738 - val_accuracy: 0.4700\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9118 - accuracy: 0.6828 - val_loss: 1.5778 - val_accuracy: 0.4700\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8605 - accuracy: 0.7064 - val_loss: 1.5728 - val_accuracy: 0.4667\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.6917 - val_loss: 1.5808 - val_accuracy: 0.4733\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8831 - accuracy: 0.6908 - val_loss: 1.5695 - val_accuracy: 0.4900\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8700 - accuracy: 0.7107 - val_loss: 1.5733 - val_accuracy: 0.4833\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.6965 - val_loss: 1.5652 - val_accuracy: 0.4733\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8890 - accuracy: 0.6924 - val_loss: 1.5800 - val_accuracy: 0.4867\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8743 - accuracy: 0.7058 - val_loss: 1.5678 - val_accuracy: 0.4733\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8749 - accuracy: 0.6965 - val_loss: 1.5868 - val_accuracy: 0.4767\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8809 - accuracy: 0.7071 - val_loss: 1.5964 - val_accuracy: 0.4767\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8614 - accuracy: 0.6853 - val_loss: 1.5810 - val_accuracy: 0.4700\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8741 - accuracy: 0.6730 - val_loss: 1.5825 - val_accuracy: 0.4700\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8201 - accuracy: 0.7112 - val_loss: 1.5755 - val_accuracy: 0.4700\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8672 - accuracy: 0.6950 - val_loss: 1.5871 - val_accuracy: 0.4700\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8589 - accuracy: 0.6907 - val_loss: 1.5882 - val_accuracy: 0.4833\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8245 - accuracy: 0.7180 - val_loss: 1.5975 - val_accuracy: 0.4867\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8405 - accuracy: 0.6878 - val_loss: 1.5958 - val_accuracy: 0.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9548 - accuracy: 0.6797 - val_loss: 1.6023 - val_accuracy: 0.4667\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8924 - accuracy: 0.6769 - val_loss: 1.5891 - val_accuracy: 0.4800\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8682 - accuracy: 0.6903 - val_loss: 1.6035 - val_accuracy: 0.4767\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8721 - accuracy: 0.6823 - val_loss: 1.6025 - val_accuracy: 0.4767\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7913 - accuracy: 0.7293 - val_loss: 1.5912 - val_accuracy: 0.4667\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 990us/step - loss: 0.8845 - accuracy: 0.6958 - val_loss: 1.6091 - val_accuracy: 0.4633\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8580 - accuracy: 0.7221 - val_loss: 1.6015 - val_accuracy: 0.4600\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8449 - accuracy: 0.6777 - val_loss: 1.6070 - val_accuracy: 0.4767\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8310 - accuracy: 0.7179 - val_loss: 1.6172 - val_accuracy: 0.4667\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9205 - accuracy: 0.6914 - val_loss: 1.6119 - val_accuracy: 0.4600\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8755 - accuracy: 0.7150 - val_loss: 1.5957 - val_accuracy: 0.4733\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8733 - accuracy: 0.6971 - val_loss: 1.6148 - val_accuracy: 0.4633\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8564 - accuracy: 0.7165 - val_loss: 1.6141 - val_accuracy: 0.4800\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 942us/step - loss: 0.8478 - accuracy: 0.7154 - val_loss: 1.6290 - val_accuracy: 0.4567\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8652 - accuracy: 0.6889 - val_loss: 1.6231 - val_accuracy: 0.4800\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8851 - accuracy: 0.7007 - val_loss: 1.6119 - val_accuracy: 0.4733\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8367 - accuracy: 0.7075 - val_loss: 1.6147 - val_accuracy: 0.4700\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8692 - accuracy: 0.7199 - val_loss: 1.6198 - val_accuracy: 0.4833\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8165 - accuracy: 0.7123 - val_loss: 1.6128 - val_accuracy: 0.4667\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8894 - accuracy: 0.6905 - val_loss: 1.6230 - val_accuracy: 0.4733\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8220 - accuracy: 0.7039 - val_loss: 1.6263 - val_accuracy: 0.4700\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.6564 - val_loss: 1.6213 - val_accuracy: 0.4733\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8597 - accuracy: 0.6950 - val_loss: 1.6203 - val_accuracy: 0.4667\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8142 - accuracy: 0.7462 - val_loss: 1.6226 - val_accuracy: 0.4633\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8810 - accuracy: 0.6836 - val_loss: 1.6124 - val_accuracy: 0.4633\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8107 - accuracy: 0.7108 - val_loss: 1.6294 - val_accuracy: 0.4633\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7980 - accuracy: 0.7099 - val_loss: 1.6330 - val_accuracy: 0.4633\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8631 - accuracy: 0.6965 - val_loss: 1.6443 - val_accuracy: 0.4600\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8792 - accuracy: 0.7122 - val_loss: 1.6332 - val_accuracy: 0.4867\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8266 - accuracy: 0.7064 - val_loss: 1.6255 - val_accuracy: 0.4600\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.7193 - val_loss: 1.6381 - val_accuracy: 0.4767\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8349 - accuracy: 0.7281 - val_loss: 1.6418 - val_accuracy: 0.4700\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8451 - accuracy: 0.7222 - val_loss: 1.6396 - val_accuracy: 0.4700\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8060 - accuracy: 0.7171 - val_loss: 1.6306 - val_accuracy: 0.4667\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8603 - accuracy: 0.6945 - val_loss: 1.6463 - val_accuracy: 0.4633\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8273 - accuracy: 0.7220 - val_loss: 1.6535 - val_accuracy: 0.4667\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8529 - accuracy: 0.6863 - val_loss: 1.6394 - val_accuracy: 0.4600\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8110 - accuracy: 0.6958 - val_loss: 1.6383 - val_accuracy: 0.4667\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8539 - accuracy: 0.6940 - val_loss: 1.6623 - val_accuracy: 0.4700\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.6825 - val_loss: 1.6597 - val_accuracy: 0.4633\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8397 - accuracy: 0.7230 - val_loss: 1.6506 - val_accuracy: 0.4600\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7958 - accuracy: 0.7265 - val_loss: 1.6560 - val_accuracy: 0.4633\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8470 - accuracy: 0.7018 - val_loss: 1.6643 - val_accuracy: 0.4767\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8531 - accuracy: 0.7015 - val_loss: 1.6593 - val_accuracy: 0.4567\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7976 - accuracy: 0.6935 - val_loss: 1.6601 - val_accuracy: 0.4533\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9063 - accuracy: 0.6779 - val_loss: 1.6615 - val_accuracy: 0.4600\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8372 - accuracy: 0.7072 - val_loss: 1.6616 - val_accuracy: 0.4500\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7983 - accuracy: 0.7160 - val_loss: 1.6563 - val_accuracy: 0.4633\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8528 - accuracy: 0.7020 - val_loss: 1.6517 - val_accuracy: 0.4633\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.7194 - val_loss: 1.6603 - val_accuracy: 0.4567\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8163 - accuracy: 0.7261 - val_loss: 1.6726 - val_accuracy: 0.4667\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8432 - accuracy: 0.6965 - val_loss: 1.6685 - val_accuracy: 0.4567\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.6864 - val_loss: 1.6692 - val_accuracy: 0.4700\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7786 - accuracy: 0.7490 - val_loss: 1.6512 - val_accuracy: 0.4633\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7972 - accuracy: 0.7316 - val_loss: 1.6710 - val_accuracy: 0.4633\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7941 - accuracy: 0.7339 - val_loss: 1.6830 - val_accuracy: 0.4633\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8664 - accuracy: 0.6919 - val_loss: 1.6777 - val_accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8695 - accuracy: 0.6842 - val_loss: 1.6764 - val_accuracy: 0.4600\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8306 - accuracy: 0.7008 - val_loss: 1.6677 - val_accuracy: 0.4700\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8378 - accuracy: 0.7011 - val_loss: 1.6933 - val_accuracy: 0.4700\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7848 - accuracy: 0.7130 - val_loss: 1.6640 - val_accuracy: 0.4600\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8370 - accuracy: 0.7105 - val_loss: 1.6866 - val_accuracy: 0.4700\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8543 - accuracy: 0.6891 - val_loss: 1.6751 - val_accuracy: 0.4633\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8771 - accuracy: 0.6917 - val_loss: 1.6802 - val_accuracy: 0.4700\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8045 - accuracy: 0.7271 - val_loss: 1.6869 - val_accuracy: 0.4633\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8393 - accuracy: 0.7067 - val_loss: 1.6816 - val_accuracy: 0.4667\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8363 - accuracy: 0.7059 - val_loss: 1.6899 - val_accuracy: 0.4667\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8450 - accuracy: 0.7093 - val_loss: 1.7038 - val_accuracy: 0.4633\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8796 - accuracy: 0.6894 - val_loss: 1.7005 - val_accuracy: 0.4667\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7995 - accuracy: 0.7261 - val_loss: 1.6947 - val_accuracy: 0.4667\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.7055 - val_loss: 1.6915 - val_accuracy: 0.4600\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8327 - accuracy: 0.7184 - val_loss: 1.7040 - val_accuracy: 0.4633\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7646 - accuracy: 0.7531 - val_loss: 1.6844 - val_accuracy: 0.4667\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8118 - accuracy: 0.7270 - val_loss: 1.6997 - val_accuracy: 0.4700\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8118 - accuracy: 0.7111 - val_loss: 1.6899 - val_accuracy: 0.4600\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7907 - accuracy: 0.7162 - val_loss: 1.7108 - val_accuracy: 0.4700\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.7073 - val_loss: 1.7104 - val_accuracy: 0.4633\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7968 - accuracy: 0.7271 - val_loss: 1.7130 - val_accuracy: 0.4667\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8611 - accuracy: 0.7108 - val_loss: 1.6952 - val_accuracy: 0.4567\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7967 - accuracy: 0.7109 - val_loss: 1.6990 - val_accuracy: 0.4567\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7948 - accuracy: 0.6915 - val_loss: 1.7037 - val_accuracy: 0.4533\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7960 - accuracy: 0.7313 - val_loss: 1.7042 - val_accuracy: 0.4667\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8185 - accuracy: 0.7102 - val_loss: 1.7139 - val_accuracy: 0.4633\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8665 - accuracy: 0.6747 - val_loss: 1.7228 - val_accuracy: 0.4633\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8473 - accuracy: 0.7177 - val_loss: 1.7285 - val_accuracy: 0.4600\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8225 - accuracy: 0.7221 - val_loss: 1.7261 - val_accuracy: 0.4633\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8278 - accuracy: 0.6858 - val_loss: 1.7105 - val_accuracy: 0.4567\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.7273 - val_loss: 1.7286 - val_accuracy: 0.4700\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8097 - accuracy: 0.7056 - val_loss: 1.7271 - val_accuracy: 0.4667\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.7431 - val_loss: 1.7202 - val_accuracy: 0.4567\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.7086 - val_loss: 1.7199 - val_accuracy: 0.4667\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8419 - accuracy: 0.7083 - val_loss: 1.7187 - val_accuracy: 0.4667\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8198 - accuracy: 0.7099 - val_loss: 1.7275 - val_accuracy: 0.4600\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8385 - accuracy: 0.7232 - val_loss: 1.7343 - val_accuracy: 0.4633\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 989us/step - loss: 0.7315 - accuracy: 0.7542 - val_loss: 1.7218 - val_accuracy: 0.4600\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.8180 - accuracy: 0.6897 - val_loss: 1.7391 - val_accuracy: 0.4633\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7995 - accuracy: 0.7425 - val_loss: 1.7240 - val_accuracy: 0.4600\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7891 - accuracy: 0.7116 - val_loss: 1.7450 - val_accuracy: 0.4667\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.7300 - val_loss: 1.7545 - val_accuracy: 0.4667\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7909 - accuracy: 0.7267 - val_loss: 1.7481 - val_accuracy: 0.4700\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7713 - accuracy: 0.7172 - val_loss: 1.7393 - val_accuracy: 0.4667\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.7109 - val_loss: 1.7494 - val_accuracy: 0.4667\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8085 - accuracy: 0.7414 - val_loss: 1.7523 - val_accuracy: 0.4733\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.7093 - val_loss: 1.7497 - val_accuracy: 0.4667\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7788 - accuracy: 0.7111 - val_loss: 1.7378 - val_accuracy: 0.4600\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7861 - accuracy: 0.7163 - val_loss: 1.7534 - val_accuracy: 0.4667\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8692 - accuracy: 0.6623 - val_loss: 1.7466 - val_accuracy: 0.4600\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8142 - accuracy: 0.7294 - val_loss: 1.7576 - val_accuracy: 0.4700\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.7319 - val_loss: 1.7493 - val_accuracy: 0.4600\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7704 - accuracy: 0.7209 - val_loss: 1.7594 - val_accuracy: 0.4667\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7774 - accuracy: 0.7337 - val_loss: 1.7444 - val_accuracy: 0.4533\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7642 - accuracy: 0.7243 - val_loss: 1.7565 - val_accuracy: 0.4633\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.7190 - val_loss: 1.7681 - val_accuracy: 0.4633\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8079 - accuracy: 0.7104 - val_loss: 1.7677 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7873 - accuracy: 0.7331 - val_loss: 1.7583 - val_accuracy: 0.4600\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7922 - accuracy: 0.7272 - val_loss: 1.7586 - val_accuracy: 0.4567\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7840 - accuracy: 0.7122 - val_loss: 1.7746 - val_accuracy: 0.4633\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8171 - accuracy: 0.7107 - val_loss: 1.7821 - val_accuracy: 0.4667\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8197 - accuracy: 0.7125 - val_loss: 1.7630 - val_accuracy: 0.4667\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.7306 - val_loss: 1.7703 - val_accuracy: 0.4667\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8169 - accuracy: 0.7072 - val_loss: 1.7845 - val_accuracy: 0.4733\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8207 - accuracy: 0.6937 - val_loss: 1.7714 - val_accuracy: 0.4600\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7989 - accuracy: 0.7105 - val_loss: 1.7755 - val_accuracy: 0.4567\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7714 - accuracy: 0.7182 - val_loss: 1.7720 - val_accuracy: 0.4667\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8230 - accuracy: 0.7230 - val_loss: 1.7757 - val_accuracy: 0.4600\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8039 - accuracy: 0.7300 - val_loss: 1.7857 - val_accuracy: 0.4700\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8289 - accuracy: 0.7128 - val_loss: 1.7688 - val_accuracy: 0.4600\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7986 - accuracy: 0.7330 - val_loss: 1.7952 - val_accuracy: 0.4667\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7742 - accuracy: 0.7235 - val_loss: 1.8015 - val_accuracy: 0.4667\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8071 - accuracy: 0.7153 - val_loss: 1.8068 - val_accuracy: 0.4733\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.7027 - val_loss: 1.7875 - val_accuracy: 0.4700\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7671 - accuracy: 0.7207 - val_loss: 1.7794 - val_accuracy: 0.4667\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8300 - accuracy: 0.7187 - val_loss: 1.7851 - val_accuracy: 0.4633\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8050 - accuracy: 0.7132 - val_loss: 1.7805 - val_accuracy: 0.4633\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7858 - accuracy: 0.7081 - val_loss: 1.8007 - val_accuracy: 0.4667\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.7196 - val_loss: 1.7884 - val_accuracy: 0.4667\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8159 - accuracy: 0.6979 - val_loss: 1.7920 - val_accuracy: 0.4733\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 0.7957 - accuracy: 0.7136 - val_loss: 1.7891 - val_accuracy: 0.4633\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.7304 - val_loss: 1.8056 - val_accuracy: 0.4633\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7676 - accuracy: 0.7508 - val_loss: 1.7973 - val_accuracy: 0.4633\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7599 - accuracy: 0.7471 - val_loss: 1.7927 - val_accuracy: 0.4667\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7986 - accuracy: 0.7261 - val_loss: 1.8124 - val_accuracy: 0.4667\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.7391 - val_loss: 1.8092 - val_accuracy: 0.4633\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7765 - accuracy: 0.7207 - val_loss: 1.8159 - val_accuracy: 0.4667\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7690 - accuracy: 0.7120 - val_loss: 1.7879 - val_accuracy: 0.4633\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7836 - accuracy: 0.7288 - val_loss: 1.7899 - val_accuracy: 0.4667\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7781 - accuracy: 0.7167 - val_loss: 1.8291 - val_accuracy: 0.4767\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8018 - accuracy: 0.7143 - val_loss: 1.8085 - val_accuracy: 0.4667\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7722 - accuracy: 0.7228 - val_loss: 1.8387 - val_accuracy: 0.4800\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7719 - accuracy: 0.7251 - val_loss: 1.8086 - val_accuracy: 0.4667\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7609 - accuracy: 0.7391 - val_loss: 1.8167 - val_accuracy: 0.4633\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7877 - accuracy: 0.7313 - val_loss: 1.8251 - val_accuracy: 0.4733\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8357 - accuracy: 0.7063 - val_loss: 1.8317 - val_accuracy: 0.4600\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7791 - accuracy: 0.7016 - val_loss: 1.8258 - val_accuracy: 0.4567\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7901 - accuracy: 0.7188 - val_loss: 1.8010 - val_accuracy: 0.4633\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.7349 - val_loss: 1.8349 - val_accuracy: 0.4633\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.6706 - accuracy: 0.70 - 0s 1ms/step - loss: 0.7550 - accuracy: 0.7300 - val_loss: 1.8473 - val_accuracy: 0.4633\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7783 - accuracy: 0.7325 - val_loss: 1.7981 - val_accuracy: 0.4667\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7756 - accuracy: 0.7482 - val_loss: 1.8253 - val_accuracy: 0.4667\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.7431 - val_loss: 1.8299 - val_accuracy: 0.4667\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7763 - accuracy: 0.7188 - val_loss: 1.8497 - val_accuracy: 0.4767\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7763 - accuracy: 0.7170 - val_loss: 1.8319 - val_accuracy: 0.4667\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7454 - accuracy: 0.7419 - val_loss: 1.8069 - val_accuracy: 0.4600\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 984us/step - loss: 0.7662 - accuracy: 0.7328 - val_loss: 1.8370 - val_accuracy: 0.4700\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 993us/step - loss: 0.7577 - accuracy: 0.7352 - val_loss: 1.8401 - val_accuracy: 0.4700\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7878 - accuracy: 0.7103 - val_loss: 1.8348 - val_accuracy: 0.4733\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8128 - accuracy: 0.7136 - val_loss: 1.8475 - val_accuracy: 0.4633\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7603 - accuracy: 0.7370 - val_loss: 1.8404 - val_accuracy: 0.4733\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7893 - accuracy: 0.7047 - val_loss: 1.8474 - val_accuracy: 0.4733\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.7505 - val_loss: 1.8372 - val_accuracy: 0.4667\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7498 - accuracy: 0.7314 - val_loss: 1.8221 - val_accuracy: 0.4633\n",
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7665 - accuracy: 0.7402 - val_loss: 1.8470 - val_accuracy: 0.4700\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7565 - accuracy: 0.7393 - val_loss: 1.8419 - val_accuracy: 0.4700\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7868 - accuracy: 0.7325 - val_loss: 1.8374 - val_accuracy: 0.4633\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.7729 - val_loss: 1.8526 - val_accuracy: 0.4667\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.7608 - val_loss: 1.8522 - val_accuracy: 0.4667\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 950us/step - loss: 0.7654 - accuracy: 0.7393 - val_loss: 1.8386 - val_accuracy: 0.4667\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8190 - accuracy: 0.6889 - val_loss: 1.8676 - val_accuracy: 0.4667\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7765 - accuracy: 0.7151 - val_loss: 1.8389 - val_accuracy: 0.4633\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8232 - accuracy: 0.7123 - val_loss: 1.8368 - val_accuracy: 0.4600\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.7385 - val_loss: 1.8582 - val_accuracy: 0.4667\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.7503 - val_loss: 1.8591 - val_accuracy: 0.4667\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7930 - accuracy: 0.7216 - val_loss: 1.8554 - val_accuracy: 0.4667\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7503 - accuracy: 0.7243 - val_loss: 1.8829 - val_accuracy: 0.4567\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.7159 - val_loss: 1.8777 - val_accuracy: 0.4633\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.7372 - val_loss: 1.8547 - val_accuracy: 0.4533\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.7420 - val_loss: 1.8697 - val_accuracy: 0.4600\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.7433 - val_loss: 1.8622 - val_accuracy: 0.4667\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7715 - accuracy: 0.7230 - val_loss: 1.8654 - val_accuracy: 0.4700\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.7443 - val_loss: 1.8623 - val_accuracy: 0.4667\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.7107 - val_loss: 1.8580 - val_accuracy: 0.4567\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.7437 - val_loss: 1.8684 - val_accuracy: 0.4667\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.7533 - val_loss: 1.8692 - val_accuracy: 0.4600\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.7489 - val_loss: 1.8748 - val_accuracy: 0.4600\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7600 - accuracy: 0.7489 - val_loss: 1.8536 - val_accuracy: 0.4633\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.7529 - val_loss: 1.8874 - val_accuracy: 0.4633\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.7564 - val_loss: 1.8641 - val_accuracy: 0.4633\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7576 - accuracy: 0.7238 - val_loss: 1.8997 - val_accuracy: 0.4533\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7552 - accuracy: 0.7531 - val_loss: 1.8818 - val_accuracy: 0.4700\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7914 - accuracy: 0.7369 - val_loss: 1.8922 - val_accuracy: 0.4633\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.7585 - val_loss: 1.8870 - val_accuracy: 0.4633\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.7533 - val_loss: 1.8972 - val_accuracy: 0.4600\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8033 - accuracy: 0.7145 - val_loss: 1.8981 - val_accuracy: 0.4567\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.7378 - val_loss: 1.8962 - val_accuracy: 0.4667\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.7503 - val_loss: 1.8851 - val_accuracy: 0.4667\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 967us/step - loss: 0.7114 - accuracy: 0.7456 - val_loss: 1.8954 - val_accuracy: 0.4633\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7559 - accuracy: 0.7405 - val_loss: 1.9013 - val_accuracy: 0.4633\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.7414 - val_loss: 1.8980 - val_accuracy: 0.4633\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.7317 - val_loss: 1.8954 - val_accuracy: 0.4633\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7322 - accuracy: 0.7154 - val_loss: 1.9154 - val_accuracy: 0.4700\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.7420 - val_loss: 1.9057 - val_accuracy: 0.4667\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7811 - accuracy: 0.7366 - val_loss: 1.9110 - val_accuracy: 0.4567\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.7312 - val_loss: 1.8899 - val_accuracy: 0.4700\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.7172 - val_loss: 1.9106 - val_accuracy: 0.4633\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.7334 - val_loss: 1.8891 - val_accuracy: 0.4667\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.7415 - val_loss: 1.8926 - val_accuracy: 0.4633\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 978us/step - loss: 0.7889 - accuracy: 0.7013 - val_loss: 1.9211 - val_accuracy: 0.4600\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8096 - accuracy: 0.7248 - val_loss: 1.9277 - val_accuracy: 0.4567\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.7365 - val_loss: 1.9337 - val_accuracy: 0.4633\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7697 - accuracy: 0.7289 - val_loss: 1.8968 - val_accuracy: 0.4633\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8298 - accuracy: 0.6970 - val_loss: 1.9163 - val_accuracy: 0.4567\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7708 - accuracy: 0.7366 - val_loss: 1.9240 - val_accuracy: 0.4633\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.7436 - val_loss: 1.9083 - val_accuracy: 0.4633\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.7459 - val_loss: 1.9147 - val_accuracy: 0.4700\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.7407 - val_loss: 1.9195 - val_accuracy: 0.4633\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.7385 - val_loss: 1.9346 - val_accuracy: 0.4633\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7437 - accuracy: 0.7398 - val_loss: 1.9232 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.7375 - val_loss: 1.9555 - val_accuracy: 0.4600\n",
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7712 - accuracy: 0.7293 - val_loss: 1.9299 - val_accuracy: 0.4567\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.7258 - val_loss: 1.9373 - val_accuracy: 0.4667\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.7408 - val_loss: 1.9346 - val_accuracy: 0.4700\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 0.7268 - val_loss: 1.9419 - val_accuracy: 0.4567\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7302 - accuracy: 0.7421 - val_loss: 1.9286 - val_accuracy: 0.4667\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7536 - accuracy: 0.7375 - val_loss: 1.9306 - val_accuracy: 0.4533\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7117 - accuracy: 0.7666 - val_loss: 1.9341 - val_accuracy: 0.4533\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.7140 - val_loss: 1.9444 - val_accuracy: 0.4533\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.7685 - val_loss: 1.9283 - val_accuracy: 0.4700\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.7305 - val_loss: 1.9470 - val_accuracy: 0.4567\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 988us/step - loss: 0.7693 - accuracy: 0.7222 - val_loss: 1.9492 - val_accuracy: 0.4600\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.7397 - val_loss: 1.9321 - val_accuracy: 0.4533\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7650 - accuracy: 0.7336 - val_loss: 1.9424 - val_accuracy: 0.4500\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.7550 - val_loss: 1.9316 - val_accuracy: 0.4633\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.7498 - val_loss: 1.9526 - val_accuracy: 0.4533\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.7234 - val_loss: 1.9445 - val_accuracy: 0.4700\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.7505 - val_loss: 1.9421 - val_accuracy: 0.4633\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.7253 - val_loss: 1.9497 - val_accuracy: 0.4600\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.7404 - val_loss: 1.9626 - val_accuracy: 0.4533\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7654 - accuracy: 0.7171 - val_loss: 1.9468 - val_accuracy: 0.4533\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.7358 - val_loss: 1.9816 - val_accuracy: 0.4633\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7724 - accuracy: 0.7207 - val_loss: 1.9613 - val_accuracy: 0.4600\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.7562 - val_loss: 1.9732 - val_accuracy: 0.4533\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.7697 - val_loss: 1.9772 - val_accuracy: 0.4600\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.7473 - val_loss: 1.9707 - val_accuracy: 0.4600\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.7145 - accuracy: 0.7592 - val_loss: 1.9444 - val_accuracy: 0.4667\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.7161 - val_loss: 1.9975 - val_accuracy: 0.4633\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7666 - accuracy: 0.7336 - val_loss: 1.9750 - val_accuracy: 0.4600\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.7775 - val_loss: 1.9794 - val_accuracy: 0.4500\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7431 - accuracy: 0.7476 - val_loss: 1.9831 - val_accuracy: 0.4600\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8189 - accuracy: 0.7187 - val_loss: 1.9919 - val_accuracy: 0.4633\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.7307 - val_loss: 1.9781 - val_accuracy: 0.4567\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.7648 - val_loss: 1.9599 - val_accuracy: 0.4567\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.7378 - val_loss: 1.9645 - val_accuracy: 0.4633\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7694 - accuracy: 0.7338 - val_loss: 1.9912 - val_accuracy: 0.4567\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.7315 - val_loss: 1.9757 - val_accuracy: 0.4633\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.7500 - val_loss: 1.9766 - val_accuracy: 0.4600\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8170 - accuracy: 0.7302 - val_loss: 1.9838 - val_accuracy: 0.4600\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.7460 - val_loss: 1.9864 - val_accuracy: 0.4600\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.7522 - val_loss: 1.9672 - val_accuracy: 0.4600\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.7407 - val_loss: 1.9794 - val_accuracy: 0.4567\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.7291 - val_loss: 1.9929 - val_accuracy: 0.4533\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.7565 - val_loss: 1.9823 - val_accuracy: 0.4567\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.7411 - val_loss: 1.9829 - val_accuracy: 0.4600\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.7514 - val_loss: 1.9912 - val_accuracy: 0.4500\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.7260 - val_loss: 1.9894 - val_accuracy: 0.4533\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.7387 - val_loss: 1.9833 - val_accuracy: 0.4600\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7458 - accuracy: 0.7216 - val_loss: 2.0157 - val_accuracy: 0.4600\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7477 - val_loss: 2.0153 - val_accuracy: 0.4600\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.7434 - val_loss: 2.0127 - val_accuracy: 0.4600\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7538 - accuracy: 0.7452 - val_loss: 1.9981 - val_accuracy: 0.4467\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.7417 - val_loss: 1.9919 - val_accuracy: 0.4567\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.7208 - val_loss: 2.0159 - val_accuracy: 0.4600\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.7564 - val_loss: 1.9961 - val_accuracy: 0.4500\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.7365 - val_loss: 2.0175 - val_accuracy: 0.4567\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.7289 - val_loss: 2.0108 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.7573 - val_loss: 1.9916 - val_accuracy: 0.4500\n",
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7584 - accuracy: 0.7469 - val_loss: 2.0232 - val_accuracy: 0.4567\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.7717 - val_loss: 1.9964 - val_accuracy: 0.4500\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.7710 - val_loss: 2.0137 - val_accuracy: 0.4533\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.7387 - val_loss: 2.0198 - val_accuracy: 0.4567\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.7638 - val_loss: 2.0247 - val_accuracy: 0.4567\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7420 - accuracy: 0.7372 - val_loss: 2.0249 - val_accuracy: 0.4533\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.7192 - val_loss: 2.0346 - val_accuracy: 0.4500\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.7478 - val_loss: 2.0218 - val_accuracy: 0.4600\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.7622 - val_loss: 2.0521 - val_accuracy: 0.4567\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 0.7209 - val_loss: 2.0270 - val_accuracy: 0.4500\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.7496 - val_loss: 2.0174 - val_accuracy: 0.4567\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7795 - accuracy: 0.7222 - val_loss: 2.0337 - val_accuracy: 0.4567\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.7459 - val_loss: 2.0433 - val_accuracy: 0.4600\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7980 - accuracy: 0.7573 - val_loss: 2.0443 - val_accuracy: 0.4600\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7479 - accuracy: 0.7241 - val_loss: 2.0448 - val_accuracy: 0.4600\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.7587 - val_loss: 2.0329 - val_accuracy: 0.4567\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.7514 - val_loss: 2.0085 - val_accuracy: 0.4433\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.7664 - val_loss: 2.0374 - val_accuracy: 0.4500\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.7372 - val_loss: 2.0385 - val_accuracy: 0.4567\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7273 - accuracy: 0.7428 - val_loss: 2.0347 - val_accuracy: 0.4567\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.7403 - val_loss: 2.0373 - val_accuracy: 0.4533\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.7682 - val_loss: 2.0434 - val_accuracy: 0.4633\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.7446 - val_loss: 2.0486 - val_accuracy: 0.4600\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.7562 - val_loss: 2.0662 - val_accuracy: 0.4533\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.7646 - val_loss: 2.0451 - val_accuracy: 0.4533\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.7452 - val_loss: 2.0538 - val_accuracy: 0.4567\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.7686 - val_loss: 2.0358 - val_accuracy: 0.4433\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.7638 - val_loss: 2.0530 - val_accuracy: 0.4533\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7578 - accuracy: 0.7546 - val_loss: 2.0465 - val_accuracy: 0.4500\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7638 - accuracy: 0.7422 - val_loss: 2.0591 - val_accuracy: 0.4533\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.7511 - val_loss: 2.0512 - val_accuracy: 0.4500\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.7464 - val_loss: 2.0415 - val_accuracy: 0.4433\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.7534 - val_loss: 2.0513 - val_accuracy: 0.4533\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.7434 - val_loss: 2.0574 - val_accuracy: 0.4467\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7677 - accuracy: 0.7587 - val_loss: 2.0518 - val_accuracy: 0.4500\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.7524 - val_loss: 2.0565 - val_accuracy: 0.4533\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.7358 - val_loss: 2.0635 - val_accuracy: 0.4467\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.7719 - accuracy: 0.7330 - val_loss: 2.0627 - val_accuracy: 0.4533\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7693 - accuracy: 0.7526 - val_loss: 2.0863 - val_accuracy: 0.4600\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.7581 - val_loss: 2.0798 - val_accuracy: 0.4500\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.7656 - val_loss: 2.0669 - val_accuracy: 0.4533\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.7499 - val_loss: 2.0699 - val_accuracy: 0.4533\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.7343 - val_loss: 2.0877 - val_accuracy: 0.4500\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.7464 - val_loss: 2.0686 - val_accuracy: 0.4500\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.7460 - val_loss: 2.0951 - val_accuracy: 0.4533\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.7648 - val_loss: 2.0849 - val_accuracy: 0.4533\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.7360 - val_loss: 2.0869 - val_accuracy: 0.4600\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7237 - accuracy: 0.7383 - val_loss: 2.0995 - val_accuracy: 0.4567\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.7815 - val_loss: 2.0864 - val_accuracy: 0.4500\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.7620 - val_loss: 2.0689 - val_accuracy: 0.4500\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.7527 - val_loss: 2.0795 - val_accuracy: 0.4467\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.7485 - val_loss: 2.1134 - val_accuracy: 0.4567\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.7752 - val_loss: 2.0852 - val_accuracy: 0.4567\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.7679 - val_loss: 2.0868 - val_accuracy: 0.4533\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.6895 - accuracy: 0.7810 - val_loss: 2.0874 - val_accuracy: 0.4467\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.7367 - val_loss: 2.0886 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.7449 - val_loss: 2.1098 - val_accuracy: 0.4567\n",
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.7715 - val_loss: 2.0834 - val_accuracy: 0.4500\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.7795 - val_loss: 2.0953 - val_accuracy: 0.4433\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.7493 - val_loss: 2.1074 - val_accuracy: 0.4500\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7437 - accuracy: 0.7321 - val_loss: 2.1102 - val_accuracy: 0.4533\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.7533 - val_loss: 2.1144 - val_accuracy: 0.4500\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.7608 - val_loss: 2.1050 - val_accuracy: 0.4533\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.7479 - val_loss: 2.0999 - val_accuracy: 0.4467\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.7550 - val_loss: 2.0922 - val_accuracy: 0.4433\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.7780 - val_loss: 2.1070 - val_accuracy: 0.4467\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.7305 - val_loss: 2.1165 - val_accuracy: 0.4467\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.7786 - val_loss: 2.1053 - val_accuracy: 0.4467\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 989us/step - loss: 0.7329 - accuracy: 0.7382 - val_loss: 2.1229 - val_accuracy: 0.4500\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.7536 - val_loss: 2.1107 - val_accuracy: 0.4433\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.7747 - val_loss: 2.1120 - val_accuracy: 0.4467\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.7748 - val_loss: 2.1377 - val_accuracy: 0.4533\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.7577 - val_loss: 2.1178 - val_accuracy: 0.4533\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.7639 - val_loss: 2.1154 - val_accuracy: 0.4500\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.7318 - val_loss: 2.1386 - val_accuracy: 0.4533\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.7573 - val_loss: 2.1462 - val_accuracy: 0.4500\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.7539 - val_loss: 2.1444 - val_accuracy: 0.4600\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.7522 - val_loss: 2.1281 - val_accuracy: 0.4533\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.7615 - val_loss: 2.1384 - val_accuracy: 0.4500\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7671 - accuracy: 0.7566 - val_loss: 2.1222 - val_accuracy: 0.4467\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6666 - accuracy: 0.7741 - val_loss: 2.1445 - val_accuracy: 0.4533\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7393 - val_loss: 2.1405 - val_accuracy: 0.4467\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.7713 - val_loss: 2.1447 - val_accuracy: 0.4567\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.7716 - val_loss: 2.1449 - val_accuracy: 0.4533\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.7730 - val_loss: 2.1349 - val_accuracy: 0.4500\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.7489 - val_loss: 2.1394 - val_accuracy: 0.4467\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.7755 - val_loss: 2.1564 - val_accuracy: 0.4533\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.7553 - val_loss: 2.1605 - val_accuracy: 0.4500\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.7528 - val_loss: 2.1524 - val_accuracy: 0.4433\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.7713 - val_loss: 2.1405 - val_accuracy: 0.4500\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 964us/step - loss: 0.6756 - accuracy: 0.7749 - val_loss: 2.1313 - val_accuracy: 0.4433\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.7581 - val_loss: 2.1598 - val_accuracy: 0.4500\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.7425 - val_loss: 2.1422 - val_accuracy: 0.4467\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.7384 - val_loss: 2.1501 - val_accuracy: 0.4467\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.7462 - val_loss: 2.1263 - val_accuracy: 0.4400\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.7653 - val_loss: 2.1623 - val_accuracy: 0.4467\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.7532 - val_loss: 2.1662 - val_accuracy: 0.4467\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.7532 - val_loss: 2.1835 - val_accuracy: 0.4500\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.7554 - val_loss: 2.1538 - val_accuracy: 0.4467\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.7643 - val_loss: 2.1722 - val_accuracy: 0.4467\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.7506 - val_loss: 2.1576 - val_accuracy: 0.4500\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7765 - val_loss: 2.1547 - val_accuracy: 0.4467\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.7597 - val_loss: 2.1676 - val_accuracy: 0.4400\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.7914 - val_loss: 2.1751 - val_accuracy: 0.4433\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7515 - val_loss: 2.1893 - val_accuracy: 0.4467\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.7627 - val_loss: 2.1710 - val_accuracy: 0.4533\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.7710 - val_loss: 2.1908 - val_accuracy: 0.4433\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.7819 - val_loss: 2.1669 - val_accuracy: 0.4500\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.7735 - val_loss: 2.1820 - val_accuracy: 0.4433\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.7776 - val_loss: 2.1810 - val_accuracy: 0.4433\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.7882 - val_loss: 2.1858 - val_accuracy: 0.4467\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.7730 - val_loss: 2.1832 - val_accuracy: 0.4467\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.7438 - val_loss: 2.1770 - val_accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.7439 - val_loss: 2.1694 - val_accuracy: 0.4433\n",
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.7788 - val_loss: 2.1900 - val_accuracy: 0.4500\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.7604 - val_loss: 2.2046 - val_accuracy: 0.4433\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.7602 - val_loss: 2.1865 - val_accuracy: 0.4467\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.7728 - val_loss: 2.1974 - val_accuracy: 0.4467\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.7690 - val_loss: 2.1753 - val_accuracy: 0.4433\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.7575 - val_loss: 2.1822 - val_accuracy: 0.4433\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.7896 - val_loss: 2.1870 - val_accuracy: 0.4433\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.7443 - val_loss: 2.2058 - val_accuracy: 0.4433\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.7550 - val_loss: 2.1842 - val_accuracy: 0.4467\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7458 - accuracy: 0.7404 - val_loss: 2.2045 - val_accuracy: 0.4500\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.7961 - val_loss: 2.1846 - val_accuracy: 0.4433\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.7425 - val_loss: 2.1926 - val_accuracy: 0.4433\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.7496 - val_loss: 2.2049 - val_accuracy: 0.4433\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.7919 - val_loss: 2.1990 - val_accuracy: 0.4400\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7447 - val_loss: 2.1787 - val_accuracy: 0.4500\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.6912 - accuracy: 0.7570 - val_loss: 2.2013 - val_accuracy: 0.4433\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 0.7093 - accuracy: 0.7597 - val_loss: 2.2099 - val_accuracy: 0.4500\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 952us/step - loss: 0.6549 - accuracy: 0.7669 - val_loss: 2.2010 - val_accuracy: 0.4467\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.6801 - accuracy: 0.7660 - val_loss: 2.2067 - val_accuracy: 0.4400\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 948us/step - loss: 0.6817 - accuracy: 0.7667 - val_loss: 2.2077 - val_accuracy: 0.4400\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.7719 - val_loss: 2.2132 - val_accuracy: 0.4333\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.7498 - val_loss: 2.2116 - val_accuracy: 0.4400\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.7980 - val_loss: 2.2143 - val_accuracy: 0.4400\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.7784 - val_loss: 2.2117 - val_accuracy: 0.4400\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.7648 - val_loss: 2.2195 - val_accuracy: 0.4433\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.7585 - val_loss: 2.2319 - val_accuracy: 0.4400\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.7602 - val_loss: 2.2325 - val_accuracy: 0.4433\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.7908 - val_loss: 2.2329 - val_accuracy: 0.4433\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.7828 - val_loss: 2.2152 - val_accuracy: 0.4400\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.7752 - val_loss: 2.2216 - val_accuracy: 0.4367\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.7602 - val_loss: 2.2267 - val_accuracy: 0.4467\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.7605 - val_loss: 2.2285 - val_accuracy: 0.4467\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.7963 - val_loss: 2.2307 - val_accuracy: 0.4333\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.7736 - val_loss: 2.2544 - val_accuracy: 0.4400\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.7562 - val_loss: 2.2277 - val_accuracy: 0.4433\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.7644 - val_loss: 2.2336 - val_accuracy: 0.4433\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.7796 - val_loss: 2.2377 - val_accuracy: 0.4333\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7698 - val_loss: 2.2348 - val_accuracy: 0.4467\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.7717 - val_loss: 2.2408 - val_accuracy: 0.4400\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.7792 - val_loss: 2.2483 - val_accuracy: 0.4433\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.7608 - val_loss: 2.2426 - val_accuracy: 0.4367\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.7817 - val_loss: 2.2611 - val_accuracy: 0.4467\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.7452 - val_loss: 2.2733 - val_accuracy: 0.4400\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.7750 - val_loss: 2.2586 - val_accuracy: 0.4400\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.7457 - val_loss: 2.2461 - val_accuracy: 0.4367\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.7614 - val_loss: 2.2637 - val_accuracy: 0.4300\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.7956 - val_loss: 2.2630 - val_accuracy: 0.4333\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.7432 - val_loss: 2.2560 - val_accuracy: 0.4367\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.7646 - val_loss: 2.2699 - val_accuracy: 0.4400\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.7799 - val_loss: 2.2316 - val_accuracy: 0.4467\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.7863 - val_loss: 2.2515 - val_accuracy: 0.4333\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.7841 - val_loss: 2.2340 - val_accuracy: 0.4433\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.7339 - val_loss: 2.2451 - val_accuracy: 0.4400\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.7326 - val_loss: 2.2567 - val_accuracy: 0.4467\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.7657 - val_loss: 2.2762 - val_accuracy: 0.4500\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.7375 - val_loss: 2.2728 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.7681 - val_loss: 2.2676 - val_accuracy: 0.4433\n",
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.7846 - val_loss: 2.2623 - val_accuracy: 0.4400\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.7525 - val_loss: 2.2674 - val_accuracy: 0.4367\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.7694 - val_loss: 2.2850 - val_accuracy: 0.4467\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.7444 - val_loss: 2.2573 - val_accuracy: 0.4467\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.7598 - val_loss: 2.2673 - val_accuracy: 0.4433\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.7411 - val_loss: 2.2873 - val_accuracy: 0.4500\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.7910 - val_loss: 2.2794 - val_accuracy: 0.4333\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.7727 - val_loss: 2.2632 - val_accuracy: 0.4467\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.7576 - val_loss: 2.3004 - val_accuracy: 0.4433\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.7662 - val_loss: 2.2689 - val_accuracy: 0.4467\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.7798 - val_loss: 2.3047 - val_accuracy: 0.4400\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.7690 - val_loss: 2.3000 - val_accuracy: 0.4433\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.7723 - val_loss: 2.3031 - val_accuracy: 0.4433\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.7769 - val_loss: 2.2823 - val_accuracy: 0.4400\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.7484 - val_loss: 2.2828 - val_accuracy: 0.4400\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.7753 - val_loss: 2.3001 - val_accuracy: 0.4500\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.7796 - val_loss: 2.2975 - val_accuracy: 0.4400\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.7537 - val_loss: 2.2940 - val_accuracy: 0.4500\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.7760 - val_loss: 2.2846 - val_accuracy: 0.4500\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.7415 - val_loss: 2.3080 - val_accuracy: 0.4400\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.7605 - val_loss: 2.3182 - val_accuracy: 0.4433\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.7815 - val_loss: 2.2932 - val_accuracy: 0.4433\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.7699 - val_loss: 2.3259 - val_accuracy: 0.4500\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.7625 - val_loss: 2.3116 - val_accuracy: 0.4367\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.7726 - val_loss: 2.3067 - val_accuracy: 0.4400\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.7700 - val_loss: 2.3032 - val_accuracy: 0.4400\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.7672 - val_loss: 2.2916 - val_accuracy: 0.4500\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.7776 - val_loss: 2.3065 - val_accuracy: 0.4500\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.7774 - val_loss: 2.3214 - val_accuracy: 0.4500\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.8059 - val_loss: 2.3234 - val_accuracy: 0.4467\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.7495 - val_loss: 2.3315 - val_accuracy: 0.4433\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.7859 - val_loss: 2.3090 - val_accuracy: 0.4467\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7141 - accuracy: 0.7524 - val_loss: 2.3324 - val_accuracy: 0.4433\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.7937 - val_loss: 2.3296 - val_accuracy: 0.4467\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.7472 - val_loss: 2.3207 - val_accuracy: 0.4367\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.7749 - val_loss: 2.3191 - val_accuracy: 0.4467\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 959us/step - loss: 0.6415 - accuracy: 0.8083 - val_loss: 2.3369 - val_accuracy: 0.4433\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.7849 - val_loss: 2.3232 - val_accuracy: 0.4433\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 999us/step - loss: 0.6126 - accuracy: 0.7952 - val_loss: 2.3057 - val_accuracy: 0.4433\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.7695 - val_loss: 2.3316 - val_accuracy: 0.4400\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.6688 - accuracy: 0.7748 - val_loss: 2.3171 - val_accuracy: 0.4467\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.7885 - val_loss: 2.3294 - val_accuracy: 0.4400\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 0.6661 - accuracy: 0.7543 - val_loss: 2.3107 - val_accuracy: 0.4433\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.7421 - val_loss: 2.3449 - val_accuracy: 0.4433\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.7752 - val_loss: 2.3344 - val_accuracy: 0.4467\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.7594 - val_loss: 2.3430 - val_accuracy: 0.4433\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.7832 - val_loss: 2.3371 - val_accuracy: 0.4500\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.7850 - val_loss: 2.3387 - val_accuracy: 0.4467\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.7903 - val_loss: 2.3441 - val_accuracy: 0.4400\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.7500 - val_loss: 2.3690 - val_accuracy: 0.4433\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7676 - val_loss: 2.3364 - val_accuracy: 0.4500\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.8006 - val_loss: 2.3600 - val_accuracy: 0.4400\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.7947 - val_loss: 2.3366 - val_accuracy: 0.4467\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 968us/step - loss: 0.6926 - accuracy: 0.7572 - val_loss: 2.3594 - val_accuracy: 0.4433\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.7775 - val_loss: 2.3603 - val_accuracy: 0.4467\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7705 - val_loss: 2.3577 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 926us/step - loss: 0.7064 - accuracy: 0.7757 - val_loss: 2.3528 - val_accuracy: 0.4433\n",
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.6505 - accuracy: 0.7798 - val_loss: 2.3857 - val_accuracy: 0.4500\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.7932 - val_loss: 2.3379 - val_accuracy: 0.4433\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.7777 - val_loss: 2.3505 - val_accuracy: 0.4500\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.7790 - val_loss: 2.3643 - val_accuracy: 0.4500\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.7541 - val_loss: 2.3587 - val_accuracy: 0.4500\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.7846 - val_loss: 2.3580 - val_accuracy: 0.4433\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.7878 - val_loss: 2.3678 - val_accuracy: 0.4500\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.7953 - val_loss: 2.3616 - val_accuracy: 0.4467\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.7511 - val_loss: 2.3712 - val_accuracy: 0.4500\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.7596 - val_loss: 2.3740 - val_accuracy: 0.4500\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.7815 - val_loss: 2.3855 - val_accuracy: 0.4467\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.7607 - val_loss: 2.3516 - val_accuracy: 0.4467\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.7786 - val_loss: 2.3777 - val_accuracy: 0.4467\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7654 - val_loss: 2.3722 - val_accuracy: 0.4500\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.7373 - val_loss: 2.3919 - val_accuracy: 0.4600\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.7841 - val_loss: 2.3802 - val_accuracy: 0.4467\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.7712 - val_loss: 2.3785 - val_accuracy: 0.4433\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.7750 - val_loss: 2.3600 - val_accuracy: 0.4433\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.7710 - val_loss: 2.3824 - val_accuracy: 0.4533\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 967us/step - loss: 0.6797 - accuracy: 0.7484 - val_loss: 2.3708 - val_accuracy: 0.4467\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.7828 - val_loss: 2.3681 - val_accuracy: 0.4400\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.7508 - val_loss: 2.4060 - val_accuracy: 0.4400\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.7570 - val_loss: 2.3927 - val_accuracy: 0.4467\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.7773 - val_loss: 2.4177 - val_accuracy: 0.4400\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.7447 - val_loss: 2.3983 - val_accuracy: 0.4500\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.7910 - val_loss: 2.3877 - val_accuracy: 0.4500\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.7955 - val_loss: 2.3984 - val_accuracy: 0.4500\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.7652 - val_loss: 2.3899 - val_accuracy: 0.4500\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.7741 - val_loss: 2.4061 - val_accuracy: 0.4433\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.7862 - val_loss: 2.4187 - val_accuracy: 0.4433\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.7779 - val_loss: 2.4217 - val_accuracy: 0.4400\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.7941 - val_loss: 2.3886 - val_accuracy: 0.4500\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.7994 - val_loss: 2.3903 - val_accuracy: 0.4500\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.7701 - val_loss: 2.4005 - val_accuracy: 0.4533\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.7644 - val_loss: 2.4039 - val_accuracy: 0.4500\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.7806 - val_loss: 2.3990 - val_accuracy: 0.4533\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.7738 - val_loss: 2.4102 - val_accuracy: 0.4533\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.7691 - val_loss: 2.4156 - val_accuracy: 0.4500\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.7903 - val_loss: 2.4070 - val_accuracy: 0.4467\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.7781 - val_loss: 2.3987 - val_accuracy: 0.4467\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.7787 - val_loss: 2.4123 - val_accuracy: 0.4500\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.7692 - val_loss: 2.4132 - val_accuracy: 0.4533\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.7884 - val_loss: 2.4231 - val_accuracy: 0.4467\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.7770 - val_loss: 2.4104 - val_accuracy: 0.4433\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.7483 - val_loss: 2.4185 - val_accuracy: 0.4400\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.7641 - val_loss: 2.4031 - val_accuracy: 0.4400\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.7847 - val_loss: 2.4217 - val_accuracy: 0.4533\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.7955 - val_loss: 2.4267 - val_accuracy: 0.4500\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.7436 - val_loss: 2.4502 - val_accuracy: 0.4467\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.7954 - val_loss: 2.4341 - val_accuracy: 0.4400\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.7757 - val_loss: 2.4336 - val_accuracy: 0.4467\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.7929 - val_loss: 2.4494 - val_accuracy: 0.4433\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.7713 - val_loss: 2.4081 - val_accuracy: 0.4400\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7736 - val_loss: 2.4379 - val_accuracy: 0.4433\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.7611 - val_loss: 2.4277 - val_accuracy: 0.4433\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7670 - val_loss: 2.4314 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7862 - val_loss: 2.4616 - val_accuracy: 0.4433\n",
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7699 - val_loss: 2.4516 - val_accuracy: 0.4467\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.7846 - val_loss: 2.4382 - val_accuracy: 0.4500\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.7874 - val_loss: 2.4622 - val_accuracy: 0.4433\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.7813 - val_loss: 2.4358 - val_accuracy: 0.4433\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6113 - accuracy: 0.7728 - val_loss: 2.4294 - val_accuracy: 0.4400\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.7854 - val_loss: 2.4837 - val_accuracy: 0.4333\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.7967 - val_loss: 2.4485 - val_accuracy: 0.4500\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.7709 - val_loss: 2.4614 - val_accuracy: 0.4433\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.7735 - val_loss: 2.4227 - val_accuracy: 0.4400\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6421 - accuracy: 0.7812 - val_loss: 2.4626 - val_accuracy: 0.4467\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 996us/step - loss: 0.6333 - accuracy: 0.7896 - val_loss: 2.4473 - val_accuracy: 0.4400\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.7414 - val_loss: 2.4827 - val_accuracy: 0.4400\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.7744 - val_loss: 2.4529 - val_accuracy: 0.4433\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.7944 - val_loss: 2.4602 - val_accuracy: 0.4467\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.7706 - val_loss: 2.4389 - val_accuracy: 0.4333\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.7908 - val_loss: 2.4781 - val_accuracy: 0.4433\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.7641 - val_loss: 2.4758 - val_accuracy: 0.4433\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 0.6234 - accuracy: 0.7805 - val_loss: 2.4751 - val_accuracy: 0.4367\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.8082 - val_loss: 2.4655 - val_accuracy: 0.4500\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.7698 - val_loss: 2.4683 - val_accuracy: 0.4500\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.7783 - val_loss: 2.4856 - val_accuracy: 0.4467\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.7897 - val_loss: 2.4731 - val_accuracy: 0.4500\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.7821 - val_loss: 2.4779 - val_accuracy: 0.4433\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.8108 - val_loss: 2.4709 - val_accuracy: 0.4467\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.7823 - val_loss: 2.4625 - val_accuracy: 0.4433\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.8055 - val_loss: 2.4705 - val_accuracy: 0.4433\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.7843 - val_loss: 2.4689 - val_accuracy: 0.4433\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.7858 - val_loss: 2.4909 - val_accuracy: 0.4467\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.7985 - val_loss: 2.4469 - val_accuracy: 0.4433\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.7909 - val_loss: 2.4755 - val_accuracy: 0.4433\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.7752 - val_loss: 2.4651 - val_accuracy: 0.4367\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.7805 - val_loss: 2.4789 - val_accuracy: 0.4467\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.7803 - val_loss: 2.4857 - val_accuracy: 0.4467\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.7584 - val_loss: 2.4920 - val_accuracy: 0.4467\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.7955 - val_loss: 2.4845 - val_accuracy: 0.4467\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.7793 - val_loss: 2.4829 - val_accuracy: 0.4467\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.6421 - accuracy: 0.7919 - val_loss: 2.5083 - val_accuracy: 0.4433\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.7741 - val_loss: 2.5106 - val_accuracy: 0.4433\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.7691 - val_loss: 2.5145 - val_accuracy: 0.4433\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.7829 - val_loss: 2.4759 - val_accuracy: 0.4433\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6204 - accuracy: 0.7805 - val_loss: 2.4969 - val_accuracy: 0.4400\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.8166 - val_loss: 2.5121 - val_accuracy: 0.4467\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.7852 - val_loss: 2.5045 - val_accuracy: 0.4400\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.7933 - val_loss: 2.4940 - val_accuracy: 0.4367\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 968us/step - loss: 0.6719 - accuracy: 0.7808 - val_loss: 2.5004 - val_accuracy: 0.4433\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.6501 - accuracy: 0.7823 - val_loss: 2.4958 - val_accuracy: 0.4400\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 976us/step - loss: 0.6464 - accuracy: 0.7942 - val_loss: 2.4976 - val_accuracy: 0.4400\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5957 - accuracy: 0.8148 - val_loss: 2.5276 - val_accuracy: 0.4400\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 961us/step - loss: 0.6832 - accuracy: 0.7944 - val_loss: 2.5144 - val_accuracy: 0.4467\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.7761 - val_loss: 2.5075 - val_accuracy: 0.4400\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.7560 - val_loss: 2.4962 - val_accuracy: 0.4467\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.7573 - val_loss: 2.5240 - val_accuracy: 0.4433\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.7838 - val_loss: 2.5343 - val_accuracy: 0.4400\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.7638 - val_loss: 2.5221 - val_accuracy: 0.4400\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.7814 - val_loss: 2.5387 - val_accuracy: 0.4433\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.8027 - val_loss: 2.5174 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.7794 - val_loss: 2.5295 - val_accuracy: 0.4400\n",
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.8055 - val_loss: 2.5271 - val_accuracy: 0.4400\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.7995 - val_loss: 2.5269 - val_accuracy: 0.4400\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.7811 - val_loss: 2.5170 - val_accuracy: 0.4333\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.7788 - val_loss: 2.5550 - val_accuracy: 0.4433\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.7950 - val_loss: 2.5474 - val_accuracy: 0.4433\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.7754 - val_loss: 2.5218 - val_accuracy: 0.4433\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.7927 - val_loss: 2.5357 - val_accuracy: 0.4433\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.8002 - val_loss: 2.5380 - val_accuracy: 0.4367\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.7966 - val_loss: 2.5272 - val_accuracy: 0.4433\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.7820 - val_loss: 2.5420 - val_accuracy: 0.4400\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.7727 - val_loss: 2.5433 - val_accuracy: 0.4433\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.7682 - val_loss: 2.5451 - val_accuracy: 0.4400\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.7968 - val_loss: 2.5227 - val_accuracy: 0.4433\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.7733 - val_loss: 2.5521 - val_accuracy: 0.4400\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.7642 - val_loss: 2.5328 - val_accuracy: 0.4400\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.7751 - val_loss: 2.5512 - val_accuracy: 0.4367\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.7811 - val_loss: 2.5173 - val_accuracy: 0.4433\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.7977 - val_loss: 2.5399 - val_accuracy: 0.4467\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.8158 - val_loss: 2.5470 - val_accuracy: 0.4400\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.7923 - val_loss: 2.5752 - val_accuracy: 0.4433\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7794 - val_loss: 2.5681 - val_accuracy: 0.4400\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.7688 - val_loss: 2.5553 - val_accuracy: 0.4400\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.7886 - val_loss: 2.5530 - val_accuracy: 0.4400\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.7892 - val_loss: 2.5587 - val_accuracy: 0.4433\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.7896 - val_loss: 2.5578 - val_accuracy: 0.4433\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.7671 - val_loss: 2.5603 - val_accuracy: 0.4367\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.7731 - val_loss: 2.5741 - val_accuracy: 0.4400\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.7769 - val_loss: 2.5696 - val_accuracy: 0.4333\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.7789 - val_loss: 2.5644 - val_accuracy: 0.4400\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.7740 - val_loss: 2.5789 - val_accuracy: 0.4400\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7960 - val_loss: 2.5775 - val_accuracy: 0.4400\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.7986 - val_loss: 2.5624 - val_accuracy: 0.4433\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.7962 - val_loss: 2.5624 - val_accuracy: 0.4433\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.7730 - val_loss: 2.5723 - val_accuracy: 0.4367\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.7886 - val_loss: 2.5724 - val_accuracy: 0.4400\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.7895 - val_loss: 2.5689 - val_accuracy: 0.4367\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.8008 - val_loss: 2.5658 - val_accuracy: 0.4367\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 918us/step - loss: 0.6440 - accuracy: 0.7683 - val_loss: 2.5599 - val_accuracy: 0.4400\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.7950 - val_loss: 2.5699 - val_accuracy: 0.4400\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.7973 - val_loss: 2.5734 - val_accuracy: 0.4400\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.7889 - val_loss: 2.5807 - val_accuracy: 0.4467\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.7830 - val_loss: 2.5982 - val_accuracy: 0.4333\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.8021 - val_loss: 2.5787 - val_accuracy: 0.4467\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.7830 - val_loss: 2.5734 - val_accuracy: 0.4467\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.7884 - val_loss: 2.5658 - val_accuracy: 0.4367\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.8100 - val_loss: 2.5963 - val_accuracy: 0.4367\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.8132 - val_loss: 2.5851 - val_accuracy: 0.4367\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 0.6398 - accuracy: 0.7770 - val_loss: 2.5813 - val_accuracy: 0.4367\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.7919 - val_loss: 2.5907 - val_accuracy: 0.4433\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.7834 - val_loss: 2.5863 - val_accuracy: 0.4433\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.7926 - val_loss: 2.5820 - val_accuracy: 0.4400\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.8077 - val_loss: 2.5999 - val_accuracy: 0.4400\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.7878 - val_loss: 2.6027 - val_accuracy: 0.4400\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.8110 - val_loss: 2.6080 - val_accuracy: 0.4433\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7910 - val_loss: 2.6115 - val_accuracy: 0.4433\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.7819 - val_loss: 2.6033 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.8169 - val_loss: 2.5815 - val_accuracy: 0.4400\n",
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.8059 - val_loss: 2.5997 - val_accuracy: 0.4433\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7908 - val_loss: 2.6018 - val_accuracy: 0.4433\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.8126 - val_loss: 2.5861 - val_accuracy: 0.4367\n",
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.7871 - val_loss: 2.6002 - val_accuracy: 0.4400\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.7801 - val_loss: 2.5872 - val_accuracy: 0.4367\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.7836 - val_loss: 2.6041 - val_accuracy: 0.4400\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.8008 - val_loss: 2.6206 - val_accuracy: 0.4400\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.7721 - val_loss: 2.6176 - val_accuracy: 0.4367\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.7752 - val_loss: 2.6445 - val_accuracy: 0.4367\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.7807 - val_loss: 2.6162 - val_accuracy: 0.4400\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.8027 - val_loss: 2.6449 - val_accuracy: 0.4367\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.7723 - val_loss: 2.6136 - val_accuracy: 0.4367\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.7914 - val_loss: 2.6139 - val_accuracy: 0.4333\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.7784 - val_loss: 2.6092 - val_accuracy: 0.4400\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.7989 - val_loss: 2.6228 - val_accuracy: 0.4367\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.7878 - val_loss: 2.6190 - val_accuracy: 0.4433\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7863 - val_loss: 2.6156 - val_accuracy: 0.4400\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.8092 - val_loss: 2.6274 - val_accuracy: 0.4400\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7961 - val_loss: 2.6301 - val_accuracy: 0.4333\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.7936 - val_loss: 2.6293 - val_accuracy: 0.4400\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.7717 - val_loss: 2.6177 - val_accuracy: 0.4333\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.8093 - val_loss: 2.6282 - val_accuracy: 0.4333\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.7654 - val_loss: 2.6513 - val_accuracy: 0.4367\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.7966 - val_loss: 2.6357 - val_accuracy: 0.4400\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.8041 - val_loss: 2.6183 - val_accuracy: 0.4333\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.8200 - val_loss: 2.6443 - val_accuracy: 0.4367\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.7814 - val_loss: 2.6365 - val_accuracy: 0.4333\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.8128 - val_loss: 2.6534 - val_accuracy: 0.4400\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.7761 - val_loss: 2.6317 - val_accuracy: 0.4367\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 993us/step - loss: 0.6317 - accuracy: 0.7850 - val_loss: 2.6516 - val_accuracy: 0.4400\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.7833 - val_loss: 2.6755 - val_accuracy: 0.4400\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, \n",
    "                validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 셋\n",
    "# 훈련셋, 검증 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# 훈련셋과 검증셋 분리(X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32') / 255.0\n",
    "X_val   = X_val.reshape(10000,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴\n",
    "train_rand_idxs = np.random.choice(50000,700)\n",
    "val_rand_idxs   = np.random.choice(10000,300)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val   = utils.to_categorical(Y_val)\n",
    "Y_test  = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "custom_hist = CustomHistory()\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, \n",
    "                validation_data=(X_val, Y_val), verbose=0,\n",
    "                callbacks=[custom_hist])\n",
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25f29198ac0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습과정 표시하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'], 'g', label=\"val loss\")\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'r', label=\"val accuracy\")\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 887us/step - loss: 2.9332 - accuracy: 0.4307\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 2.9332408905029297\n",
      "accuracy : 0.43070000410079956\n"
     ]
    }
   ],
   "source": [
    "print(\"loss :\", loss_and_metrics[0])\n",
    "print(\"accuracy :\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 모델 저장 및 로드하기\n",
    "model.save(\"model/mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('model/mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2833b6aebb0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model2.predict(X_val[0].reshape(1,784))\n",
    "result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(X_val[0].reshape(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:2.3011484146118164, val_loss:2.2869575023651123\n",
      "epoch:10, loss:1.8595068454742432, val_loss:1.9311376810073853\n",
      "epoch:20, loss:1.6604671478271484, val_loss:1.7424495220184326\n",
      "epoch:30, loss:1.5324047803878784, val_loss:1.6208696365356445\n",
      "epoch:40, loss:1.4231899976730347, val_loss:1.532474398612976\n",
      "epoch:50, loss:1.3159031867980957, val_loss:1.4617552757263184\n",
      "epoch:60, loss:1.2352374792099, val_loss:1.4218436479568481\n",
      "epoch:70, loss:1.1778897047042847, val_loss:1.385698676109314\n",
      "epoch:80, loss:1.13136887550354, val_loss:1.3508617877960205\n",
      "epoch:90, loss:1.0970778465270996, val_loss:1.3425209522247314\n",
      "epoch:100, loss:1.0708743333816528, val_loss:1.3538572788238525\n",
      "epoch:110, loss:1.04436194896698, val_loss:1.3461848497390747\n",
      "epoch:120, loss:1.0220510959625244, val_loss:1.346843957901001\n",
      "epoch:130, loss:1.0025478601455688, val_loss:1.353682041168213\n",
      "epoch:140, loss:0.9835902452468872, val_loss:1.3761621713638306\n",
      "epoch:150, loss:0.9662500023841858, val_loss:1.3807365894317627\n",
      "epoch:160, loss:0.9510505199432373, val_loss:1.3822684288024902\n",
      "epoch:170, loss:0.9348788261413574, val_loss:1.4036387205123901\n",
      "epoch:180, loss:0.9216784834861755, val_loss:1.4041682481765747\n",
      "epoch:190, loss:0.9045737385749817, val_loss:1.4008175134658813\n",
      "epoch:200, loss:0.8928504586219788, val_loss:1.4189457893371582\n",
      "epoch:210, loss:0.8790296912193298, val_loss:1.4268784523010254\n",
      "epoch:220, loss:0.8650474548339844, val_loss:1.4327645301818848\n",
      "epoch:230, loss:0.8574169278144836, val_loss:1.4458788633346558\n",
      "epoch:240, loss:0.8426201343536377, val_loss:1.4590500593185425\n",
      "epoch:250, loss:0.8319013118743896, val_loss:1.46694016456604\n",
      "epoch:260, loss:0.8233743906021118, val_loss:1.4922877550125122\n",
      "epoch:270, loss:0.8150802254676819, val_loss:1.4984525442123413\n",
      "epoch:280, loss:0.8055007457733154, val_loss:1.492310643196106\n",
      "epoch:290, loss:0.7988296151161194, val_loss:1.5096255540847778\n",
      "epoch:300, loss:0.7917072176933289, val_loss:1.506112813949585\n",
      "epoch:310, loss:0.7827547788619995, val_loss:1.5263464450836182\n",
      "epoch:320, loss:0.7710956931114197, val_loss:1.5339573621749878\n",
      "epoch:330, loss:0.7661680579185486, val_loss:1.5452661514282227\n",
      "epoch:340, loss:0.7590644359588623, val_loss:1.538528561592102\n",
      "epoch:350, loss:0.7566076517105103, val_loss:1.5527386665344238\n",
      "epoch:360, loss:0.742731511592865, val_loss:1.5654041767120361\n",
      "epoch:370, loss:0.7388870716094971, val_loss:1.5727899074554443\n",
      "epoch:380, loss:0.7299961447715759, val_loss:1.5873069763183594\n",
      "epoch:390, loss:0.7269472479820251, val_loss:1.5936988592147827\n",
      "epoch:400, loss:0.720298171043396, val_loss:1.6087546348571777\n",
      "epoch:410, loss:0.7141453623771667, val_loss:1.604607105255127\n",
      "epoch:420, loss:0.7108189463615417, val_loss:1.632843017578125\n",
      "epoch:430, loss:0.7047579288482666, val_loss:1.6439425945281982\n",
      "epoch:440, loss:0.6988510489463806, val_loss:1.6363022327423096\n",
      "epoch:450, loss:0.6941307783126831, val_loss:1.6481823921203613\n",
      "epoch:460, loss:0.6872080564498901, val_loss:1.6580480337142944\n",
      "epoch:470, loss:0.6847314834594727, val_loss:1.6598576307296753\n",
      "epoch:480, loss:0.6760976910591125, val_loss:1.7004923820495605\n",
      "epoch:490, loss:0.6719304919242859, val_loss:1.6902203559875488\n",
      "epoch:500, loss:0.6675830483436584, val_loss:1.6879608631134033\n",
      "epoch:510, loss:0.6612439155578613, val_loss:1.711296558380127\n",
      "epoch:520, loss:0.6610800623893738, val_loss:1.7256006002426147\n",
      "epoch:530, loss:0.6562165021896362, val_loss:1.73737633228302\n",
      "epoch:540, loss:0.6489505767822266, val_loss:1.7489157915115356\n",
      "epoch:550, loss:0.6453288197517395, val_loss:1.7827519178390503\n",
      "epoch:560, loss:0.6433308720588684, val_loss:1.771691918373108\n",
      "epoch:570, loss:0.6362283229827881, val_loss:1.7807329893112183\n",
      "epoch:580, loss:0.635621190071106, val_loss:1.789412260055542\n",
      "epoch:590, loss:0.6311948299407959, val_loss:1.7989113330841064\n",
      "epoch:600, loss:0.627069890499115, val_loss:1.797857642173767\n",
      "epoch:610, loss:0.6234152913093567, val_loss:1.829359769821167\n",
      "epoch:620, loss:0.6196569204330444, val_loss:1.849938154220581\n",
      "epoch:630, loss:0.6162551045417786, val_loss:1.8469860553741455\n",
      "epoch:640, loss:0.6097078323364258, val_loss:1.8563908338546753\n",
      "epoch:650, loss:0.6045719981193542, val_loss:1.8837666511535645\n",
      "epoch:660, loss:0.6023809909820557, val_loss:1.896064281463623\n",
      "epoch:670, loss:0.601421058177948, val_loss:1.9004793167114258\n",
      "epoch:680, loss:0.5985798239707947, val_loss:1.9043259620666504\n",
      "epoch:690, loss:0.5947837829589844, val_loss:1.9458807706832886\n",
      "epoch:700, loss:0.5911505818367004, val_loss:1.9486509561538696\n",
      "epoch:710, loss:0.5860466957092285, val_loss:1.9596730470657349\n",
      "epoch:720, loss:0.586765468120575, val_loss:1.9705625772476196\n",
      "epoch:730, loss:0.5824757814407349, val_loss:1.9689823389053345\n",
      "epoch:740, loss:0.578284740447998, val_loss:1.9954862594604492\n",
      "epoch:750, loss:0.5729471445083618, val_loss:2.011652708053589\n",
      "epoch:760, loss:0.5707154273986816, val_loss:2.0141358375549316\n",
      "epoch:770, loss:0.5689420700073242, val_loss:2.0357725620269775\n",
      "epoch:780, loss:0.563057541847229, val_loss:2.025007724761963\n",
      "epoch:790, loss:0.5611072182655334, val_loss:2.0395777225494385\n",
      "epoch:800, loss:0.5587842464447021, val_loss:2.049077033996582\n",
      "epoch:810, loss:0.5595395565032959, val_loss:2.0620596408843994\n",
      "epoch:820, loss:0.5530164241790771, val_loss:2.090686559677124\n",
      "epoch:830, loss:0.55022132396698, val_loss:2.0876777172088623\n",
      "epoch:840, loss:0.5489674806594849, val_loss:2.1059279441833496\n",
      "epoch:850, loss:0.5461058020591736, val_loss:2.130476951599121\n",
      "epoch:860, loss:0.5412980318069458, val_loss:2.1392834186553955\n",
      "epoch:870, loss:0.5407483577728271, val_loss:2.1737043857574463\n",
      "epoch:880, loss:0.5370725393295288, val_loss:2.1638803482055664\n",
      "epoch:890, loss:0.5333620309829712, val_loss:2.1875486373901367\n",
      "epoch:900, loss:0.5300580859184265, val_loss:2.170523166656494\n",
      "epoch:910, loss:0.5293245315551758, val_loss:2.1988861560821533\n",
      "epoch:920, loss:0.5249964594841003, val_loss:2.2283287048339844\n",
      "epoch:930, loss:0.5214865803718567, val_loss:2.2359232902526855\n",
      "epoch:940, loss:0.5203235149383545, val_loss:2.2452330589294434\n",
      "epoch:950, loss:0.5191369652748108, val_loss:2.249032974243164\n",
      "epoch:960, loss:0.5189000964164734, val_loss:2.2521965503692627\n",
      "epoch:970, loss:0.5134404897689819, val_loss:2.2876040935516357\n",
      "epoch:980, loss:0.510184109210968, val_loss:2.2921745777130127\n",
      "epoch:990, loss:0.509215772151947, val_loss:2.3256094455718994\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "class CustomHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        if self.epoch % 10 == 0:\n",
    "            print(\"epoch:{}, loss:{}, val_loss:{}\".format(self.epoch, \n",
    "                                            logs.get('loss'), logs.get('val_loss')))\n",
    "        self.epoch += 1\n",
    "# 1. 데이터 셋\n",
    "# 훈련셋, 검증 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# 훈련셋과 검증셋 분리(X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32') / 255.0\n",
    "X_val   = X_val.reshape(10000,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴\n",
    "train_rand_idxs = np.random.choice(50000,700)\n",
    "val_rand_idxs   = np.random.choice(10000,300)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val   = utils.to_categorical(Y_val)\n",
    "Y_test  = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "custom_hist = CustomHistory()\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, \n",
    "                validation_data=(X_val, Y_val), verbose=0,\n",
    "                callbacks=[custom_hist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Early Stopping\n",
    "- val_loss 값이 늘어나면 epoch를 다 수행하지 않고 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2.3065 - accuracy: 0.0718 - val_loss: 2.2712 - val_accuracy: 0.1367\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2443 - accuracy: 0.1627 - val_loss: 2.2133 - val_accuracy: 0.1333\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1865 - accuracy: 0.1915 - val_loss: 2.1753 - val_accuracy: 0.1500\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1502 - accuracy: 0.1900 - val_loss: 2.1475 - val_accuracy: 0.1500\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1018 - accuracy: 0.2345 - val_loss: 2.1274 - val_accuracy: 0.1900\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 2.0908 - accuracy: 0.2869 - val_loss: 2.1080 - val_accuracy: 0.2267\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0893 - accuracy: 0.2665 - val_loss: 2.0916 - val_accuracy: 0.2267\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0773 - accuracy: 0.2923 - val_loss: 2.0734 - val_accuracy: 0.2267\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0508 - accuracy: 0.3018 - val_loss: 2.0541 - val_accuracy: 0.2333\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9938 - accuracy: 0.3070 - val_loss: 2.0337 - val_accuracy: 0.2300\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9630 - accuracy: 0.3228 - val_loss: 2.0143 - val_accuracy: 0.2400\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9786 - accuracy: 0.2853 - val_loss: 1.9895 - val_accuracy: 0.2400\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9091 - accuracy: 0.2906 - val_loss: 1.9694 - val_accuracy: 0.2400\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8956 - accuracy: 0.3022 - val_loss: 1.9424 - val_accuracy: 0.2367\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8167 - accuracy: 0.3198 - val_loss: 1.9242 - val_accuracy: 0.2400\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8476 - accuracy: 0.3130 - val_loss: 1.9057 - val_accuracy: 0.2400\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 948us/step - loss: 1.8265 - accuracy: 0.2885 - val_loss: 1.8895 - val_accuracy: 0.2433\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8189 - accuracy: 0.2972 - val_loss: 1.8744 - val_accuracy: 0.2433\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 1.7803 - accuracy: 0.3219 - val_loss: 1.8613 - val_accuracy: 0.2467\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7495 - accuracy: 0.3336 - val_loss: 1.8462 - val_accuracy: 0.2467\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 1.8080 - accuracy: 0.3088 - val_loss: 1.8346 - val_accuracy: 0.2567\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7593 - accuracy: 0.3108 - val_loss: 1.8302 - val_accuracy: 0.2600\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7408 - accuracy: 0.3386 - val_loss: 1.8134 - val_accuracy: 0.2600\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7134 - accuracy: 0.3557 - val_loss: 1.8089 - val_accuracy: 0.2633\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7609 - accuracy: 0.3557 - val_loss: 1.7945 - val_accuracy: 0.2667\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7020 - accuracy: 0.3669 - val_loss: 1.7858 - val_accuracy: 0.2700\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6788 - accuracy: 0.3525 - val_loss: 1.7826 - val_accuracy: 0.2700\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6601 - accuracy: 0.3657 - val_loss: 1.7650 - val_accuracy: 0.2733\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6253 - accuracy: 0.3705 - val_loss: 1.7586 - val_accuracy: 0.2867\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6774 - accuracy: 0.3514 - val_loss: 1.7477 - val_accuracy: 0.2833\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6163 - accuracy: 0.3736 - val_loss: 1.7326 - val_accuracy: 0.2900\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6527 - accuracy: 0.3842 - val_loss: 1.7197 - val_accuracy: 0.2867\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5974 - accuracy: 0.3902 - val_loss: 1.7129 - val_accuracy: 0.2900\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6225 - accuracy: 0.3721 - val_loss: 1.7001 - val_accuracy: 0.3033\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5911 - accuracy: 0.4086 - val_loss: 1.6792 - val_accuracy: 0.3000\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5616 - accuracy: 0.4003 - val_loss: 1.6686 - val_accuracy: 0.3100\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5898 - accuracy: 0.3789 - val_loss: 1.6560 - val_accuracy: 0.3700\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5658 - accuracy: 0.3983 - val_loss: 1.6403 - val_accuracy: 0.3800\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4758 - accuracy: 0.4739 - val_loss: 1.6335 - val_accuracy: 0.3900\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 993us/step - loss: 1.5193 - accuracy: 0.4220 - val_loss: 1.6193 - val_accuracy: 0.3767\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 991us/step - loss: 1.5399 - accuracy: 0.4114 - val_loss: 1.6097 - val_accuracy: 0.3733\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4895 - accuracy: 0.4375 - val_loss: 1.6041 - val_accuracy: 0.3833\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4780 - accuracy: 0.4517 - val_loss: 1.5930 - val_accuracy: 0.3800\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4480 - accuracy: 0.4784 - val_loss: 1.5852 - val_accuracy: 0.4100\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4982 - accuracy: 0.4338 - val_loss: 1.5750 - val_accuracy: 0.3833\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4429 - accuracy: 0.4743 - val_loss: 1.5709 - val_accuracy: 0.3967\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4174 - accuracy: 0.4713 - val_loss: 1.5682 - val_accuracy: 0.4000\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4748 - accuracy: 0.4531 - val_loss: 1.5582 - val_accuracy: 0.3933\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3848 - accuracy: 0.5042 - val_loss: 1.5553 - val_accuracy: 0.3900\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4420 - accuracy: 0.4420 - val_loss: 1.5470 - val_accuracy: 0.3900\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3592 - accuracy: 0.5111 - val_loss: 1.5337 - val_accuracy: 0.4033\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3931 - accuracy: 0.4753 - val_loss: 1.5439 - val_accuracy: 0.4167\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3606 - accuracy: 0.4983 - val_loss: 1.5289 - val_accuracy: 0.4300\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3824 - accuracy: 0.4828 - val_loss: 1.5248 - val_accuracy: 0.4100\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3684 - accuracy: 0.4851 - val_loss: 1.5217 - val_accuracy: 0.4267\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3830 - accuracy: 0.4694 - val_loss: 1.5236 - val_accuracy: 0.4433\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4059 - accuracy: 0.5043 - val_loss: 1.5141 - val_accuracy: 0.4233\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3513 - accuracy: 0.4965 - val_loss: 1.5110 - val_accuracy: 0.4167\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3683 - accuracy: 0.5134 - val_loss: 1.4955 - val_accuracy: 0.4333\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3713 - accuracy: 0.5067 - val_loss: 1.4969 - val_accuracy: 0.4167\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3725 - accuracy: 0.5253 - val_loss: 1.4922 - val_accuracy: 0.4267\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4009 - accuracy: 0.4974 - val_loss: 1.4940 - val_accuracy: 0.4300\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3456 - accuracy: 0.5151 - val_loss: 1.4851 - val_accuracy: 0.4333\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3296 - accuracy: 0.4971 - val_loss: 1.4892 - val_accuracy: 0.4333\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3195 - accuracy: 0.5149 - val_loss: 1.4781 - val_accuracy: 0.4333\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2916 - accuracy: 0.5056 - val_loss: 1.4688 - val_accuracy: 0.4567\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3192 - accuracy: 0.4993 - val_loss: 1.4694 - val_accuracy: 0.4433\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3009 - accuracy: 0.5121 - val_loss: 1.4703 - val_accuracy: 0.4333\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2551 - accuracy: 0.5433 - val_loss: 1.4585 - val_accuracy: 0.4367\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3007 - accuracy: 0.5280 - val_loss: 1.4741 - val_accuracy: 0.4400\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2890 - accuracy: 0.5173 - val_loss: 1.4602 - val_accuracy: 0.4600\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2964 - accuracy: 0.5139 - val_loss: 1.4623 - val_accuracy: 0.4533\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2419 - accuracy: 0.5269 - val_loss: 1.4528 - val_accuracy: 0.4533\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1000us/step - loss: 1.2218 - accuracy: 0.5380 - val_loss: 1.4578 - val_accuracy: 0.4667\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2831 - accuracy: 0.5282 - val_loss: 1.4473 - val_accuracy: 0.4467\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2562 - accuracy: 0.5276 - val_loss: 1.4475 - val_accuracy: 0.4533\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2638 - accuracy: 0.5613 - val_loss: 1.4491 - val_accuracy: 0.4500\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2375 - accuracy: 0.5385 - val_loss: 1.4447 - val_accuracy: 0.4700\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2755 - accuracy: 0.5208 - val_loss: 1.4526 - val_accuracy: 0.4500\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2624 - accuracy: 0.5290 - val_loss: 1.4466 - val_accuracy: 0.4567\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2370 - accuracy: 0.5393 - val_loss: 1.4437 - val_accuracy: 0.4567\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1928 - accuracy: 0.5819 - val_loss: 1.4409 - val_accuracy: 0.4533\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2532 - accuracy: 0.5413 - val_loss: 1.4439 - val_accuracy: 0.4600\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2030 - accuracy: 0.5890 - val_loss: 1.4318 - val_accuracy: 0.4600\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2199 - accuracy: 0.5368 - val_loss: 1.4410 - val_accuracy: 0.4533\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2488 - accuracy: 0.5360 - val_loss: 1.4425 - val_accuracy: 0.4667\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1855 - accuracy: 0.5455 - val_loss: 1.4343 - val_accuracy: 0.4600\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2090 - accuracy: 0.5606 - val_loss: 1.4284 - val_accuracy: 0.4600\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1741 - accuracy: 0.5348 - val_loss: 1.4440 - val_accuracy: 0.4533\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2102 - accuracy: 0.5746 - val_loss: 1.4168 - val_accuracy: 0.4867\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 968us/step - loss: 1.2044 - accuracy: 0.5674 - val_loss: 1.4218 - val_accuracy: 0.4733\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2182 - accuracy: 0.5548 - val_loss: 1.4252 - val_accuracy: 0.4733\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 996us/step - loss: 1.1939 - accuracy: 0.5332 - val_loss: 1.4203 - val_accuracy: 0.4667\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 1.1684 - accuracy: 0.5812 - val_loss: 1.4214 - val_accuracy: 0.4667\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1628 - accuracy: 0.5798 - val_loss: 1.4199 - val_accuracy: 0.4833\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1817 - accuracy: 0.5293 - val_loss: 1.4118 - val_accuracy: 0.4867\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1767 - accuracy: 0.5734 - val_loss: 1.4185 - val_accuracy: 0.4733\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1669 - accuracy: 0.5995 - val_loss: 1.4122 - val_accuracy: 0.4800\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1826 - accuracy: 0.5559 - val_loss: 1.4094 - val_accuracy: 0.4867\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1509 - accuracy: 0.5873 - val_loss: 1.4158 - val_accuracy: 0.4900\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2230 - accuracy: 0.5645 - val_loss: 1.4155 - val_accuracy: 0.4700\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1497 - accuracy: 0.5836 - val_loss: 1.4031 - val_accuracy: 0.4733\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 1.2005 - accuracy: 0.5416 - val_loss: 1.4086 - val_accuracy: 0.4600\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1767 - accuracy: 0.5513 - val_loss: 1.4057 - val_accuracy: 0.4900\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 1.1370 - accuracy: 0.5890 - val_loss: 1.4014 - val_accuracy: 0.5100\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1464 - accuracy: 0.5844 - val_loss: 1.4114 - val_accuracy: 0.4767\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 984us/step - loss: 1.1664 - accuracy: 0.5515 - val_loss: 1.4055 - val_accuracy: 0.4667\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1689 - accuracy: 0.5778 - val_loss: 1.4151 - val_accuracy: 0.4800\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1309 - accuracy: 0.5476 - val_loss: 1.3988 - val_accuracy: 0.4967\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0998 - accuracy: 0.5880 - val_loss: 1.4027 - val_accuracy: 0.4833\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 990us/step - loss: 1.1600 - accuracy: 0.5571 - val_loss: 1.4043 - val_accuracy: 0.4933\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 993us/step - loss: 1.1107 - accuracy: 0.5877 - val_loss: 1.3970 - val_accuracy: 0.4933\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1538 - accuracy: 0.5739 - val_loss: 1.3960 - val_accuracy: 0.4600\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1321 - accuracy: 0.5829 - val_loss: 1.4012 - val_accuracy: 0.4867\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1260 - accuracy: 0.6210 - val_loss: 1.3975 - val_accuracy: 0.4800\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1394 - accuracy: 0.5788 - val_loss: 1.4102 - val_accuracy: 0.4900\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1299 - accuracy: 0.5708 - val_loss: 1.4022 - val_accuracy: 0.4900\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1492 - accuracy: 0.5776 - val_loss: 1.3930 - val_accuracy: 0.4900\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1144 - accuracy: 0.6109 - val_loss: 1.4015 - val_accuracy: 0.4867\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1772 - accuracy: 0.5342 - val_loss: 1.3932 - val_accuracy: 0.4967\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1260 - accuracy: 0.5626 - val_loss: 1.4024 - val_accuracy: 0.4800\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1383 - accuracy: 0.5838 - val_loss: 1.3980 - val_accuracy: 0.4833\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0470 - accuracy: 0.5960 - val_loss: 1.3926 - val_accuracy: 0.4967\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0535 - accuracy: 0.6052 - val_loss: 1.3876 - val_accuracy: 0.5033\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0978 - accuracy: 0.5856 - val_loss: 1.4022 - val_accuracy: 0.4867\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1139 - accuracy: 0.5876 - val_loss: 1.4031 - val_accuracy: 0.4900\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1129 - accuracy: 0.5747 - val_loss: 1.3904 - val_accuracy: 0.4833\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0367 - accuracy: 0.6060 - val_loss: 1.3956 - val_accuracy: 0.4900\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0635 - accuracy: 0.6076 - val_loss: 1.3961 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1126 - accuracy: 0.5781 - val_loss: 1.3837 - val_accuracy: 0.4933\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0600 - accuracy: 0.6203 - val_loss: 1.3889 - val_accuracy: 0.4967\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1237 - accuracy: 0.5912 - val_loss: 1.4010 - val_accuracy: 0.5000\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0796 - accuracy: 0.6210 - val_loss: 1.3912 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0659 - accuracy: 0.6049 - val_loss: 1.3885 - val_accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0244 - accuracy: 0.6305 - val_loss: 1.3964 - val_accuracy: 0.5033\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0793 - accuracy: 0.6064 - val_loss: 1.3951 - val_accuracy: 0.4933\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0644 - accuracy: 0.5912 - val_loss: 1.3888 - val_accuracy: 0.4967\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0903 - accuracy: 0.6233 - val_loss: 1.3937 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0524 - accuracy: 0.5893 - val_loss: 1.3912 - val_accuracy: 0.5033\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0563 - accuracy: 0.5990 - val_loss: 1.3956 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.5958 - val_loss: 1.3876 - val_accuracy: 0.4933\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0585 - accuracy: 0.6032 - val_loss: 1.3939 - val_accuracy: 0.5033\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0640 - accuracy: 0.6123 - val_loss: 1.3894 - val_accuracy: 0.5067\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0317 - accuracy: 0.6330 - val_loss: 1.3921 - val_accuracy: 0.4900\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0173 - accuracy: 0.6420 - val_loss: 1.3947 - val_accuracy: 0.4967\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0327 - accuracy: 0.5917 - val_loss: 1.3859 - val_accuracy: 0.4900\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.6030 - val_loss: 1.3832 - val_accuracy: 0.5033\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0052 - accuracy: 0.6211 - val_loss: 1.3918 - val_accuracy: 0.5067\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0000 - accuracy: 0.6274 - val_loss: 1.3872 - val_accuracy: 0.5067\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0134 - accuracy: 0.6202 - val_loss: 1.3910 - val_accuracy: 0.5067\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0074 - accuracy: 0.6574 - val_loss: 1.3812 - val_accuracy: 0.5033\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.6396 - val_loss: 1.3880 - val_accuracy: 0.5067\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0196 - accuracy: 0.6097 - val_loss: 1.3938 - val_accuracy: 0.4967\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0543 - accuracy: 0.6063 - val_loss: 1.3932 - val_accuracy: 0.4967\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 970us/step - loss: 0.9904 - accuracy: 0.6387 - val_loss: 1.3914 - val_accuracy: 0.4900\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0583 - accuracy: 0.6319 - val_loss: 1.3925 - val_accuracy: 0.5033\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0477 - accuracy: 0.6276 - val_loss: 1.3887 - val_accuracy: 0.5067\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0287 - accuracy: 0.6280 - val_loss: 1.3842 - val_accuracy: 0.5033\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0086 - accuracy: 0.6397 - val_loss: 1.3867 - val_accuracy: 0.4967\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0180 - accuracy: 0.6158 - val_loss: 1.3780 - val_accuracy: 0.4900\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0283 - accuracy: 0.6114 - val_loss: 1.3873 - val_accuracy: 0.5033\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 995us/step - loss: 1.0532 - accuracy: 0.6299 - val_loss: 1.4056 - val_accuracy: 0.4900\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 1.0496 - accuracy: 0.5894 - val_loss: 1.3879 - val_accuracy: 0.5033\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0011 - accuracy: 0.6218 - val_loss: 1.3935 - val_accuracy: 0.4933\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9574 - accuracy: 0.6726 - val_loss: 1.3785 - val_accuracy: 0.5300\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0227 - accuracy: 0.6533 - val_loss: 1.4026 - val_accuracy: 0.5200\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0185 - accuracy: 0.6450 - val_loss: 1.3856 - val_accuracy: 0.5300\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9928 - accuracy: 0.6293 - val_loss: 1.3935 - val_accuracy: 0.5267\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0263 - accuracy: 0.6192 - val_loss: 1.4014 - val_accuracy: 0.5200\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9997 - accuracy: 0.6204 - val_loss: 1.3872 - val_accuracy: 0.5267\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9903 - accuracy: 0.6269 - val_loss: 1.4060 - val_accuracy: 0.5233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9969 - accuracy: 0.6743 - val_loss: 1.3900 - val_accuracy: 0.5267\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.9748 - accuracy: 0.6439 - val_loss: 1.3888 - val_accuracy: 0.5233\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9590 - accuracy: 0.6780 - val_loss: 1.3954 - val_accuracy: 0.5200\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0305 - accuracy: 0.6300 - val_loss: 1.3964 - val_accuracy: 0.5233\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0619 - accuracy: 0.6141 - val_loss: 1.3990 - val_accuracy: 0.5167\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9652 - accuracy: 0.6242 - val_loss: 1.4115 - val_accuracy: 0.5100\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0062 - accuracy: 0.6560 - val_loss: 1.3975 - val_accuracy: 0.5133\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 0.6710 - val_loss: 1.4010 - val_accuracy: 0.5167\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0088 - accuracy: 0.6523 - val_loss: 1.4125 - val_accuracy: 0.5200\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9518 - accuracy: 0.6401 - val_loss: 1.3954 - val_accuracy: 0.5300\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9638 - accuracy: 0.6738 - val_loss: 1.4040 - val_accuracy: 0.5200\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9986 - accuracy: 0.6580 - val_loss: 1.3957 - val_accuracy: 0.5200\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 991us/step - loss: 0.9965 - accuracy: 0.6293 - val_loss: 1.4088 - val_accuracy: 0.5233\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9881 - accuracy: 0.6548 - val_loss: 1.3940 - val_accuracy: 0.5200\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.9897 - accuracy: 0.6353 - val_loss: 1.3927 - val_accuracy: 0.5100\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9421 - accuracy: 0.6739 - val_loss: 1.4221 - val_accuracy: 0.5367\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9985 - accuracy: 0.6468 - val_loss: 1.4010 - val_accuracy: 0.5100\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9447 - accuracy: 0.6541 - val_loss: 1.3954 - val_accuracy: 0.5100\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9779 - accuracy: 0.6726 - val_loss: 1.3880 - val_accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist # mnist 데이터셋\n",
    "import tensorflow.keras.utils as utils # 원핫인코딩\n",
    "from tensorflow.keras.models import Sequential # 모델\n",
    "from tensorflow.keras.layers import Dense, Activation # model.add시\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "# 1. 데이터 셋\n",
    "# 훈련셋, 검증 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# 훈련셋과 검증셋 분리(X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32') / 255.0\n",
    "X_val   = X_val.reshape(10000,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴\n",
    "train_rand_idxs = np.random.choice(50000,700)\n",
    "val_rand_idxs   = np.random.choice(10000,300)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val   = utils.to_categorical(Y_val)\n",
    "Y_test  = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping() # 성급한 조기 종료\n",
    "early_stopping = EarlyStopping(patience=30) # patience 인자 수만큼 loss가 오를 수 있음\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, \n",
    "                validation_data=(X_val, Y_val), verbose=1,\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22f81e569a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.학습과정 표시하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'], 'g', label=\"val loss\")\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'r', label=\"val accuracy\")\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 920us/step - loss: 1.4417 - accuracy: 0.5227\n",
      "\n",
      "loss_and_metrics : [1.4417171478271484, 0.5227000117301941]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print()\n",
    "print('loss_and_metrics :', loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 모델 사용하기\n",
    "idx = np.random.choice(X_test.shape[0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat = X_test[idx]\n",
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 0, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(xhat)\n",
    "yhat = np.argmax(yhat, axis=1) # 예측치\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[idx], axis=1) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 실제값 : 2 \t예측값 : 7\n",
      "1 번째 실제값 : 1 \t예측값 : 1\n",
      "2 번째 실제값 : 0 \t예측값 : 0\n",
      "3 번째 실제값 : 8 \t예측값 : 8\n",
      "4 번째 실제값 : 0 \t예측값 : 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i,\"번째 실제값 :\", np.argmax(Y_test[idx[i]]), \"\\t예측값 :\",\n",
    "         yhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 모델 저장하기\n",
    "model.save('model/mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 1, 0, 8, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. 모델 재사용하기\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"model/mnist.h5\")\n",
    "model2.predict_classes(xhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 위 모델(DNN)의 accuracy 늘리기\n",
    "<ol>\n",
    "    <li> 데이터 확보</li>\n",
    "    <li> 레이어 </li>\n",
    "    <li> 활성화함수 : 은닉층에는 주로 relu, elu, \n",
    "        output lay에서는 sigmoid(이진분류), softmax(다중분류)</li>\n",
    "    <li> optimizer, epoch 등을 조정</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.3401 - accuracy: 0.8963 - val_loss: 0.1508 - val_accuracy: 0.9584\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.1203 - accuracy: 0.9656 - val_loss: 0.0982 - val_accuracy: 0.9732\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 0.0867 - accuracy: 0.9764 - val_loss: 0.1397 - val_accuracy: 0.9668\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0707 - accuracy: 0.9801 - val_loss: 0.0935 - val_accuracy: 0.9771\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0656 - accuracy: 0.9813 - val_loss: 0.1173 - val_accuracy: 0.9755\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 0.0539 - accuracy: 0.9856 - val_loss: 0.1404 - val_accuracy: 0.9722\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0461 - accuracy: 0.9873 - val_loss: 0.1200 - val_accuracy: 0.9795\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0445 - accuracy: 0.9889 - val_loss: 0.1114 - val_accuracy: 0.9779\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0395 - accuracy: 0.9905 - val_loss: 0.1339 - val_accuracy: 0.9759\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.1924 - val_accuracy: 0.9725\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.1737 - val_accuracy: 0.9760\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0338 - accuracy: 0.9923 - val_loss: 0.1586 - val_accuracy: 0.9789\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0357 - accuracy: 0.9919 - val_loss: 0.1364 - val_accuracy: 0.9781\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.1659 - val_accuracy: 0.9805\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0333 - accuracy: 0.9937 - val_loss: 0.1830 - val_accuracy: 0.9791\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0276 - accuracy: 0.9939 - val_loss: 0.1624 - val_accuracy: 0.9780\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.2169 - val_accuracy: 0.9741\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.1774 - val_accuracy: 0.9793\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0272 - accuracy: 0.9943 - val_loss: 0.2225 - val_accuracy: 0.9768\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0259 - accuracy: 0.9949 - val_loss: 0.2143 - val_accuracy: 0.9757\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0266 - accuracy: 0.9945 - val_loss: 0.1933 - val_accuracy: 0.9791\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0295 - accuracy: 0.9946 - val_loss: 0.1999 - val_accuracy: 0.9794\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0231 - accuracy: 0.9953 - val_loss: 0.2459 - val_accuracy: 0.9804\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 0.2328 - val_accuracy: 0.9801\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.1897 - val_accuracy: 0.9793\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0190 - accuracy: 0.9964 - val_loss: 0.1873 - val_accuracy: 0.9798\n",
      "Epoch 27/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0228 - accuracy: 0.9965 - val_loss: 0.2611 - val_accuracy: 0.9777\n",
      "Epoch 28/30\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.3046 - val_accuracy: 0.9788\n",
      "Epoch 29/30\n",
      "5000/5000 [==============================] - 123s 25ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.2505 - val_accuracy: 0.9767\n",
      "Epoch 30/30\n",
      "5000/5000 [==============================] - 124s 25ms/step - loss: 0.0292 - accuracy: 0.9958 - val_loss: 0.2439 - val_accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist # mnist 데이터셋\n",
    "import tensorflow.keras.utils as utils # 원핫인코딩\n",
    "from tensorflow.keras.models import Sequential # 모델\n",
    "from tensorflow.keras.layers import Dense, Activation # model.add시\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "# 1. 데이터 셋\n",
    "# 훈련셋, 검증 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# 훈련셋과 검증셋 분리(X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32') / 255.0\n",
    "X_val   = X_val.reshape(10000,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴\n",
    "# train_rand_idxs = np.random.choice(50000,700)\n",
    "# val_rand_idxs   = np.random.choice(10000,300)\n",
    "# X_train = X_train[train_rand_idxs]\n",
    "# Y_train = Y_train[train_rand_idxs]\n",
    "# X_val = X_val[val_rand_idxs]\n",
    "# Y_val = Y_val[val_rand_idxs]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train)\n",
    "Y_val   = utils.to_categorical(Y_val)\n",
    "Y_test  = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=612, input_dim=784, activation=\"relu\"))\n",
    "model.add(Dense(units=1024, activation=\"relu\"))\n",
    "model.add(Dense(units=256, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping() # 성급한 조기 종료\n",
    "early_stopping = EarlyStopping(patience=10) # patience 인자 수만큼 loss가 오를 수 있음\n",
    "hist = model.fit(X_train, Y_train, epochs=30, batch_size=10, \n",
    "                validation_data=(X_val, Y_val), verbose=1,\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x192c5708f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.학습과정 표시하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'], 'g', label=\"val loss\")\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'r', label=\"val accuracy\")\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 6, 7, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. 모델 사용\n",
    "idx = np.random.choice(X_test.shape[0],5)\n",
    "xhat = X_test[idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9797\n",
      "\n",
      "loss_and_metrics : [0.2893327474594116, 0.9797000288963318]\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print()\n",
    "print('loss_and_metrics :', loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 모델 저장\n",
    "model.save('model/mnist_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 저장된 모델 재사용\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"model/mnist.h5\")\n",
    "model2.predict_classes(xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
